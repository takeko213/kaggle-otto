{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_exps = [\"exp053_pl\", \"exp059\", \"exp062\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import pathlib\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cudf\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import line_notify\n",
    "import my_logger\n",
    "from noglobal import noglobal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Cfg:\n",
    "    loglevel = \"INFO\"\n",
    "    exp_name = \"ensemble001\"\n",
    "    run_inf = True\n",
    "    seed = 42\n",
    "    k = 20\n",
    "    cand_n = 15\n",
    "    negative_sample = 1\n",
    "    train_chunk_n_dict = {\"clicks\":2, \"carts\":1, \"orders\":1}\n",
    "    test_chunk_n = 5\n",
    "    type2id = {\"clicks\":0, \"carts\":1, \"orders\":2}\n",
    "    id2type = {0:\"clicks\", 1:\"carts\", 2:\"orders\"}\n",
    "    train_week = \"week3\"\n",
    "    valid_week = \"week4\"\n",
    "    valid_session_n = 100_000\n",
    "    input_dir = os.getenv('INPUT_DIR')\n",
    "    output_dir = os.getenv('OUTPUT_DIR')\n",
    "    prep_dir = os.getenv(\"PREP_DIR\")\n",
    "\n",
    "    clicks_params = {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 5.485903737168179, 'lambda_l2': 0.005594683492536064, 'num_leaves': 79, 'feature_fraction': 0.552, 'bagging_fraction': 0.9295272232672004, 'bagging_freq': 2, 'min_child_samples': 10}\n",
    "    carts_params = {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 8.709050252544463, 'lambda_l2': 0.06935262036337767, 'num_leaves': 252, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 5}\n",
    "    orders_params = {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 9.356310279757256, 'lambda_l2': 1.3120983078968551e-08, 'num_leaves': 174, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20}\n",
    "\n",
    "cfg = Cfg()\n",
    "os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name), exist_ok=True)\n",
    "os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name, \"cache\"), exist_ok=True)\n",
    "random.seed(cfg.seed)\n",
    "\n",
    "logger = my_logger.init_logger(cfg.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "def evaluate(clicks_labels, carts_labels, orders_labels, \n",
    "             clicks_preds, carts_preds, orders_preds, k=20):\n",
    "\n",
    "    num_clicks = 0\n",
    "    num_carts = 0\n",
    "    num_orders = 0\n",
    "    hit_clicks = 0\n",
    "    hit_carts = 0\n",
    "    hit_orders = 0\n",
    "\n",
    "    for i in range(len(clicks_labels)):\n",
    "        clicks_label = clicks_labels[i]\n",
    "        carts_label = carts_labels[i]\n",
    "        orders_label = orders_labels[i]\n",
    "        clicks_pred = clicks_preds[i]\n",
    "        carts_pred = carts_preds[i]\n",
    "        orders_pred = orders_preds[i]\n",
    "\n",
    "        if type(clicks_pred) == list:\n",
    "            clicks_pred = clicks_pred[:k]\n",
    "        else:\n",
    "            clicks_pred = []\n",
    "        if type(carts_pred) == list:\n",
    "            carts_pred = carts_pred[:k]\n",
    "        else:\n",
    "            carts_pred = []    \n",
    "        if type(orders_pred) == list:\n",
    "            orders_pred = orders_pred[:k]\n",
    "        else:\n",
    "            orders_pred = []\n",
    "\n",
    "        if not np.isnan(clicks_label):\n",
    "            num_clicks += 1\n",
    "            hit_clicks += int(clicks_label in clicks_pred)\n",
    "\n",
    "        if type(carts_label) == np.ndarray:\n",
    "            num_carts += min(len(carts_label), k)\n",
    "            hit_carts += len(set(carts_pred) & set(carts_label))\n",
    "            \n",
    "        if type(orders_label) == np.ndarray:\n",
    "            num_orders += min(len(orders_label), k)\n",
    "            hit_orders += len(set(orders_pred) & set(orders_label))\n",
    "\n",
    "\n",
    "    recall_clicks = hit_clicks / num_clicks\n",
    "    recall_carts = hit_carts / num_carts\n",
    "    recall_orders = hit_orders / num_orders\n",
    "    w_recall_clicks = recall_clicks * 0.10\n",
    "    w_recall_carts = recall_carts * 0.30\n",
    "    w_recall_orders = recall_orders * 0.60\n",
    "    score = w_recall_clicks + w_recall_carts + w_recall_orders\n",
    "\n",
    "    results = {}\n",
    "    results[\"num_clicks\"] = num_clicks\n",
    "    results[\"hit_clicks\"] = hit_clicks\n",
    "    results[\"num_carts\"] = num_carts\n",
    "    results[\"hit_carts\"] = hit_carts\n",
    "    results[\"num_orders\"] = num_orders\n",
    "    results[\"hit_orders\"] = hit_orders\n",
    "    results[\"recall_clicks\"] = format(recall_clicks, \".6f\")\n",
    "    results[\"recall_carts\"] = format(recall_carts, \".6f\")\n",
    "    results[\"recall_orders\"] = format(recall_orders, \".6f\")\n",
    "    results[\"w_recall_clicks\"] = format(w_recall_clicks, \".6f\")\n",
    "    results[\"w_recall_carts\"] = format(w_recall_carts, \".6f\")\n",
    "    results[\"w_recall_orders\"] = format(w_recall_orders, \".6f\")\n",
    "    results[\"score\"] = format(score, \".6f\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_blend(dt, W = [1,1,1,1], base= 3):   \n",
    "    REC = []\n",
    "    for i in range(len(W)):\n",
    "        REC.append(dt[f'labels{i}'].split())\n",
    "\n",
    "    res = {}\n",
    "    for M in range(len(REC)):\n",
    "        for n, v in enumerate(REC[M]):\n",
    "            if v in res:\n",
    "                res[v] += (W[M]/(n+base))\n",
    "            else:\n",
    "                res[v] = (W[M]/(n+base))\n",
    "    \n",
    "    res = list(dict(sorted(res.items(), key=lambda item: -item[1])).keys())\n",
    "    \n",
    "    return ' '.join(res[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_weight_search(type_, w_choice=[0, 1, 2, 3]):\n",
    "    best_weights = None\n",
    "    best_score = 0.0\n",
    "    labels = pd.read_parquet(cfg.output_dir + f\"{use_exps[0]}/cache/valid_labels.parquet\")\n",
    "    for ws in itertools.product(w_choice, repeat=len(use_exps)):\n",
    "        if sum(ws) == 0:\n",
    "            continue\n",
    "        weights = [w for w in ws]\n",
    "        for i, exp in enumerate(use_exps):\n",
    "            if i == 0:\n",
    "                vl_pred = pd.read_csv(cfg.output_dir + f\"{exp}/{type_}_vl_pred_df.csv\")\n",
    "                vl_pred.columns = ['session_type', 'labels0']\n",
    "            else:\n",
    "                vl_pred[f'labels{i}'] = pd.read_csv(cfg.output_dir + f\"{exp}/{type_}_vl_pred_df.csv\")['labels']\n",
    "        vl_pred['labels'] = vl_pred.apply(cust_blend, W = weights, axis=1)\n",
    "        vl_pred[\"labels\"] = vl_pred[\"labels\"].apply(lambda x: [int(a) for a in x.split()])\n",
    "\n",
    "        score = evaluate(labels[\"clicks_labels\"].tolist(),\n",
    "                         labels[\"carts_labels\"].tolist(),\n",
    "                         labels[\"orders_labels\"].tolist(),\n",
    "                         vl_pred[\"labels\"].tolist(),\n",
    "                         vl_pred[\"labels\"].tolist(),\n",
    "                         vl_pred[\"labels\"].tolist(),\n",
    "                        cfg.k)[f\"recall_{type_}\"]\n",
    "        score = float(score)\n",
    "\n",
    "        text = f\"{str(weights)} : {str(score)}\"\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_weights = weights \n",
    "            text = text + \" SCORE UPDATE!!\"\n",
    "            print(text)\n",
    "    return best_weights, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks\n",
      "[0, 0, 1] : 0.508534 SCORE UPDATE!!\n",
      "[0, 1, 1] : 0.508658 SCORE UPDATE!!\n",
      "[0, 1, 2] : 0.508874 SCORE UPDATE!!\n",
      "[1, 0, 3] : 0.50908 SCORE UPDATE!!\n",
      "[2, 1, 3] : 0.50909 SCORE UPDATE!!\n",
      "carts\n",
      "[0, 0, 1] : 0.357178 SCORE UPDATE!!\n",
      "[0, 1, 2] : 0.357201 SCORE UPDATE!!\n",
      "[0, 1, 3] : 0.357316 SCORE UPDATE!!\n",
      "[1, 0, 2] : 0.357849 SCORE UPDATE!!\n",
      "orders\n",
      "[0, 0, 1] : 0.593616 SCORE UPDATE!!\n",
      "[0, 1, 3] : 0.593965 SCORE UPDATE!!\n"
     ]
    }
   ],
   "source": [
    "best_weights_dict = {}\n",
    "best_score_dict = {}\n",
    "for type_ in [\"clicks\", \"carts\", \"orders\"]:\n",
    "    print(type_)\n",
    "    type_best_weights, type_best_score = best_weight_search(type_)\n",
    "    best_weights_dict[type_] = type_best_weights\n",
    "    best_score_dict[type_] = type_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp :  ['exp053_pl', 'exp059', 'exp062']\n",
      "best_weight :  {'clicks': [2, 1, 3], 'carts': [1, 0, 2], 'orders': [0, 1, 3]}\n",
      "best_score :  {'clicks': 0.50909, 'carts': 0.357849, 'orders': 0.593965}\n",
      "cv :  0.5146427\n"
     ]
    }
   ],
   "source": [
    "print(\"exp : \", use_exps)\n",
    "print(\"best_weight : \", best_weights_dict)\n",
    "print(\"best_score : \", best_score_dict)\n",
    "print(\"cv : \", best_score_dict[\"clicks\"]*0.1 + best_score_dict[\"carts\"]*0.3 + best_score_dict[\"orders\"]*0.6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks\n",
      "carts\n",
      "orders\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for type_ in [\"clicks\", \"carts\", \"orders\"]:\n",
    "    print(type_)\n",
    "    weights = best_weights_dict[type_]\n",
    "    for i, exp in enumerate(use_exps):\n",
    "        if i == 0:\n",
    "            type_sub = pd.read_csv(cfg.output_dir + f\"{exp}/t88_{exp}_sub_k30.csv\")\n",
    "            type_sub.columns = ['session_type', 'labels0']\n",
    "        else:\n",
    "            type_sub[f'labels{i}'] = pd.read_csv(cfg.output_dir + f\"{exp}/t88_{exp}_sub_k30.csv\")['labels']\n",
    "    type_sub = type_sub[type_sub[\"session_type\"].str.contains(type_)]\n",
    "    type_sub['labels'] = type_sub.apply(cust_blend, W = weights, axis=1)\n",
    "    dfs.append(type_sub[type_sub[\"session_type\"].str.contains(type_)])\n",
    "sub = pd.concat(dfs).sort_index()\n",
    "assert all(sub[\"session_type\"] == pd.read_csv(cfg.input_dir + f\"sample_submission.csv\")[\"session_type\"])\n",
    "sub.to_csv(cfg.output_dir + f\"{cfg.exp_name}/t88_{cfg.exp_name}_sub_k30.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
