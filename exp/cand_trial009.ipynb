{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cand_trial\n",
    "session終端 時間帯での全体freqでの候補追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import pathlib\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cudf\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import line_notify\n",
    "import my_logger\n",
    "from noglobal import noglobal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Cfg:\n",
    "    loglevel = \"INFO\"\n",
    "    exp_name = \"cand_trial009\"\n",
    "    seed = 42\n",
    "    k = 20\n",
    "    cand_n = 15\n",
    "    negative_sample = 1\n",
    "    train_chunk_n_dict = {\"clicks\":2, \"carts\":1, \"orders\":1}\n",
    "    test_chunk_n = 2\n",
    "    type2id = {\"clicks\":0, \"carts\":1, \"orders\":2}\n",
    "    id2type = {0:\"clicks\", 1:\"carts\", 2:\"orders\"}\n",
    "    train_week = \"week3\"\n",
    "    valid_week = \"week4\"\n",
    "    valid_session_n = 100_000\n",
    "    input_dir = os.getenv('INPUT_DIR')\n",
    "    output_dir = os.getenv('OUTPUT_DIR')\n",
    "    prep_dir = os.getenv(\"PREP_DIR\")\n",
    "\n",
    "    clicks_params = {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 5.485903737168179, 'lambda_l2': 0.005594683492536064, 'num_leaves': 79, 'feature_fraction': 0.552, 'bagging_fraction': 0.9295272232672004, 'bagging_freq': 2, 'min_child_samples': 10}\n",
    "    carts_params = {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 8.709050252544463, 'lambda_l2': 0.06935262036337767, 'num_leaves': 252, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 5}\n",
    "    orders_params = {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 9.356310279757256, 'lambda_l2': 1.3120983078968551e-08, 'num_leaves': 174, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20}\n",
    "\n",
    "cfg = Cfg()\n",
    "os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name), exist_ok=True)\n",
    "os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name, \"cache\"), exist_ok=True)\n",
    "random.seed(cfg.seed)\n",
    "\n",
    "logger = my_logger.init_logger(cfg.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def __init__(self):\n",
    "        self.cache_dir = (os.path.join(cfg.output_dir, cfg.exp_name, \"cache\"))\n",
    "        self.cache_dir_path = pathlib.Path(self.cache_dir)\n",
    "        self.caches = list(self.cache_dir_path.glob(\"*\"))\n",
    "\n",
    "    def update(self):\n",
    "        self.caches = list(self.cache_dir_path.glob(\"*\"))\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def get_abspath(self, filename):\n",
    "        return (os.path.join(self.cache_dir, filename))\n",
    "    \n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def exists(self, path):\n",
    "        self.update()\n",
    "        return len([str(c) for c in self.caches if path == str(c)]) > 0\n",
    "\n",
    "cache = Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "def evaluate(clicks_labels, carts_labels, orders_labels, \n",
    "             clicks_preds, carts_preds, orders_preds, k=20):\n",
    "\n",
    "    num_clicks = 0\n",
    "    num_carts = 0\n",
    "    num_orders = 0\n",
    "    hit_clicks = 0\n",
    "    hit_carts = 0\n",
    "    hit_orders = 0\n",
    "\n",
    "    for i in range(len(clicks_labels)):\n",
    "        clicks_label = clicks_labels[i]\n",
    "        carts_label = carts_labels[i]\n",
    "        orders_label = orders_labels[i]\n",
    "        clicks_pred = clicks_preds[i]\n",
    "        carts_pred = carts_preds[i]\n",
    "        orders_pred = orders_preds[i]\n",
    "\n",
    "        if type(clicks_pred) == list:\n",
    "            clicks_pred = clicks_pred[:k]\n",
    "        else:\n",
    "            clicks_pred = []\n",
    "        if type(carts_pred) == list:\n",
    "            carts_pred = carts_pred[:k]\n",
    "        else:\n",
    "            carts_pred = []    \n",
    "        if type(orders_pred) == list:\n",
    "            orders_pred = orders_pred[:k]\n",
    "        else:\n",
    "            orders_pred = []\n",
    "\n",
    "        if not np.isnan(clicks_label):\n",
    "            num_clicks += 1\n",
    "            hit_clicks += int(clicks_label in clicks_pred)\n",
    "\n",
    "        if type(carts_label) == np.ndarray:\n",
    "            num_carts += min(len(carts_label), k)\n",
    "            hit_carts += len(set(carts_pred) & set(carts_label))\n",
    "            \n",
    "        if type(orders_label) == np.ndarray:\n",
    "            num_orders += min(len(orders_label), k)\n",
    "            hit_orders += len(set(orders_pred) & set(orders_label))\n",
    "\n",
    "\n",
    "    recall_clicks = hit_clicks / num_clicks\n",
    "    recall_carts = hit_carts / num_carts\n",
    "    recall_orders = hit_orders / num_orders\n",
    "    w_recall_clicks = recall_clicks * 0.10\n",
    "    w_recall_carts = recall_carts * 0.30\n",
    "    w_recall_orders = recall_orders * 0.60\n",
    "    score = w_recall_clicks + w_recall_carts + w_recall_orders\n",
    "\n",
    "    results = {}\n",
    "    results[\"num_clicks\"] = num_clicks\n",
    "    results[\"hit_clicks\"] = hit_clicks\n",
    "    results[\"num_carts\"] = num_carts\n",
    "    results[\"hit_carts\"] = hit_carts\n",
    "    results[\"num_orders\"] = num_orders\n",
    "    results[\"hit_orders\"] = hit_orders\n",
    "    results[\"recall_clicks\"] = format(recall_clicks, \".6f\")\n",
    "    results[\"recall_carts\"] = format(recall_carts, \".6f\")\n",
    "    results[\"recall_orders\"] = format(recall_orders, \".6f\")\n",
    "    results[\"w_recall_clicks\"] = format(w_recall_clicks, \".6f\")\n",
    "    results[\"w_recall_carts\"] = format(w_recall_carts, \".6f\")\n",
    "    results[\"w_recall_orders\"] = format(w_recall_orders, \".6f\")\n",
    "    results[\"score\"] = format(score, \".6f\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidate:\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def __init__(self, pl_df):\n",
    "        self.df = cudf.from_pandas(pl_df.to_pandas())\n",
    "        self.sessions = []\n",
    "        self.aids = []\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def add(self, strategy, name, usetypes=['clicks', 'carts', 'orders'], trans_map=None, k=20):\n",
    "        logger.info(f\"[add_candidate] {name} : start\")\n",
    "        candidate_df = self.df[self.df[\"type\"].isin(usetypes)].copy()\n",
    "        \n",
    "        if strategy == \"session_frequent\":\n",
    "            candidate_df = self._session_frequent(candidate_df, k)\n",
    "        elif strategy == \"session_latest\":\n",
    "            candidate_df = self._session_latest(candidate_df, k)\n",
    "        elif strategy == \"total_frequent\":\n",
    "            candidate_df = self._total_frequent(candidate_df, k)\n",
    "        elif strategy == \"session_last_hourly_frequent\":\n",
    "            candidate_df = self._session_last_hourly_frequent(candidate_df, k)\n",
    "        \n",
    "        if trans_map is not None:\n",
    "            candidate_df[\"aid\"] = candidate_df[\"aid\"].map(trans_map).astype(\"int32\")\n",
    "            candidate_df = candidate_df.dropna(subset=[\"aid\"])\n",
    "        \n",
    "        self.sessions.extend(candidate_df[\"session\"].to_arrow().to_pylist())\n",
    "        self.aids.extend(candidate_df[\"aid\"].to_arrow().to_pylist())\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def get_dataframe(self):\n",
    "        cand_df = pl.DataFrame([\n",
    "            pl.Series(\"session\", self.sessions, pl.Int32),\n",
    "            pl.Series(\"aid\", self.aids, pl.Int32)\n",
    "            ]).unique()\n",
    "        return cand_df\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def _session_frequent(self, candidate_df, k):\n",
    "        candidate_df = candidate_df.groupby([\"session\", \"aid\"])[\"ts\"].count().reset_index()\n",
    "        candidate_df.columns = [\"session\", \"aid\", \"aid_count\"]\n",
    "        candidate_df = candidate_df.sort_values([\"session\", \"aid_count\", \"aid\"], ascending=(True, False, True))\n",
    "        candidate_df = candidate_df[candidate_df.groupby(\"session\")[\"aid_count\"].cumcount() < k].copy()\n",
    "        candidate_df = candidate_df[[\"session\", \"aid\"]].copy()\n",
    "        return candidate_df\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def _session_latest(self, candidate_df, k):\n",
    "        candidate_df = candidate_df.sort_values([\"session\", \"ts\"], ascending=(True, False)).drop_duplicates(subset=[\"session\", \"aid\"])\n",
    "        candidate_df = candidate_df.sort_values([\"session\", \"ts\"], ascending=(True, False))[candidate_df.groupby(\"session\")[\"ts\"].cumcount() < k].copy()\n",
    "        candidate_df = candidate_df[[\"session\", \"aid\"]].copy()\n",
    "        return candidate_df\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "    def _total_frequent(self, candidate_df, k):\n",
    "        candidate_df = candidate_df.groupby(\"aid\")[\"ts\"].count().reset_index()\n",
    "        candidate_df.columns = [\"aid\", \"aid_count\"]\n",
    "        topk_freq_aids = candidate_df.sort_values(\"aid_count\", ascending=False)[\"aid\"].to_arrow().to_pylist()[:k]\n",
    "        sessions = []\n",
    "        aids = []\n",
    "        for session, aid in itertools.product(self.target_sessions, topk_freq_aids):\n",
    "            sessions.append(session)\n",
    "            aids.append(aid)\n",
    "        candidate_df = cudf.DataFrame({\"session\": sessions, \"aid\": aids})\n",
    "        return candidate_df\n",
    "\n",
    "    @noglobal(excepts=[\"cfg\", \"logger\", \"cache\"])\n",
    "    def _session_last_hourly_frequent(self, candidate_df, k):\n",
    "        week = \"week4\"\n",
    "        cache_file = f\"hourly_most_freq_{week}.pkl\"\n",
    "        cache_path = cache.get_abspath(cache_file)\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            hourly_most_freq = pickle.load(f)\n",
    "\n",
    "        sessions_last_record = candidate_df.sort_values(\"ts\", ascending=False).groupby(\"session\").nth(0).reset_index()\n",
    "        sessions_last_record[\"dt\"] = cudf.to_datetime(sessions_last_record[\"ts\"], unit=\"ms\")\n",
    "        sessions_last_record[\"mdh\"] = sessions_last_record[\"dt\"].dt.month.astype(str) + \"_\" +\\\n",
    "                            sessions_last_record[\"dt\"].dt.day.astype(str) + \"_\" +\\\n",
    "                            sessions_last_record[\"dt\"].dt.hour.astype(str)\n",
    "        \n",
    "        sessions = []\n",
    "        aids = []\n",
    "        for session, mdh in zip(sessions_last_record[\"session\"].to_arrow().to_pylist(), sessions_last_record[\"mdh\"].to_arrow().to_pylist()):\n",
    "            sessions.extend([session for _ in range(k)])\n",
    "            aids.extend(hourly_most_freq[mdh][:k])\n",
    "        return cudf.DataFrame({\"session\": sessions, \"aid\": aids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "def make_cand_df(sessions, trans_maps=None):\n",
    "    cand = Candidate(sessions)\n",
    "    cand.add(strategy=\"session_frequent\", name=\"session_frequent\", k=15)\n",
    "    cand.add(strategy=\"session_latest\", name=\"session_latest\", k=15)\n",
    "    cand.add(strategy=\"session_last_hourly_frequent\", name=\"session_last_hourly_frequent\", k=5)\n",
    "    \n",
    "    for i in range(20):\n",
    "        cand.add(strategy=\"session_latest\", trans_map=trans_maps[f\"time_wt_pair{str(i)}\"], name=f\"session_latest_time_wt_pair{str(i)}\", k=5)\n",
    "        cand.add(strategy=\"session_latest\", trans_map=trans_maps[f\"word2vec_pair{str(i)}\"], name=f\"session_latest_word2vec_pair{str(i)}\", k=5)\n",
    "        cand.add(strategy=\"session_latest\", trans_map=trans_maps[f\"pair{str(i)}\"], name=f\"session_latest_pair{str(i)}\", k=5)\n",
    "        cand.add(strategy=\"session_latest\", trans_map=trans_maps[f\"type_wt_pair{str(i)}\"], name=f\"session_latest_type_wt_pair{str(i)}\", k=5)\n",
    "        cand.add(strategy=\"session_latest\", trans_map=trans_maps[f\"clicks2carts_pair{str(i)}\"], name=f\"session_latest_clicks2carts_pair{str(i)}\", k=5)\n",
    "        cand.add(strategy=\"session_latest\", trans_map=trans_maps[f\"clicks2orders_pair{str(i)}\"], name=f\"session_latest_clicks2orders_pair{str(i)}\", k=5)\n",
    "\n",
    "    return cand.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "def get_pair_df(name, wt_col, week):\n",
    "    if week is not None:\n",
    "        name = f\"{name}_{week}\"\n",
    "    return pl.read_parquet(cfg.prep_dir + f\"{name}.parquet\").sort(wt_col, reverse=True)\n",
    "\n",
    "@noglobal(excepts=[\"cfg\", \"logger\"])\n",
    "def get_trans_maps(week=None):\n",
    "    \"\"\"\n",
    "    aidを別のaidに置き換えるmapping辞書を取得する\n",
    "    \"\"\"\n",
    "    trans_maps = {}\n",
    "\n",
    "    pair_df_org = get_pair_df(\"co_visitation_matrix\", \"cnt\", week)\n",
    "    for i in range(20):\n",
    "        pair_df = pair_df_org.groupby(\"aid_x\").head(i+1)\n",
    "        pair_dict = {k: v for k, v in zip(pair_df.get_column(\"aid_x\").to_list(), pair_df.get_column(\"aid_y\").to_list())}\n",
    "        trans_maps[f\"pair{str(i)}\"] = pair_dict\n",
    "    \n",
    "    pair_df_org = get_pair_df(\"co_visitation_matrix_time_weighted\", \"wt\", week)\n",
    "    for i in range(20):\n",
    "        pair_df = pair_df_org.groupby(\"aid_x\").head(i+1)\n",
    "        pair_dict = {k: v for k, v in zip(pair_df.get_column(\"aid_x\").to_list(), pair_df.get_column(\"aid_y\").to_list())}\n",
    "        trans_maps[f\"time_wt_pair{str(i)}\"] = pair_dict\n",
    "\n",
    "    pair_df_org = get_pair_df(\"co_visitation_matrix_type_weighted\", \"wt\", week)\n",
    "    for i in range(20):\n",
    "        pair_df = pair_df_org.groupby(\"aid_x\").head(i+1)\n",
    "        pair_dict = {k: v for k, v in zip(pair_df.get_column(\"aid_x\").to_list(), pair_df.get_column(\"aid_y\").to_list())}\n",
    "        trans_maps[f\"type_wt_pair{str(i)}\"] = pair_dict\n",
    "\n",
    "    pair_df_org = get_pair_df(\"co_visitation_matrix_clicks2carts\", \"cnt\", week)\n",
    "    for i in range(20):\n",
    "        pair_df = pair_df_org.groupby(\"aid_x\").head(i+1)\n",
    "        pair_dict = {k: v for k, v in zip(pair_df.get_column(\"aid_x\").to_list(), pair_df.get_column(\"aid_y\").to_list())}\n",
    "        trans_maps[f\"clicks2carts_pair{str(i)}\"] = pair_dict\n",
    "\n",
    "    pair_df_org = get_pair_df(\"co_visitation_matrix_clicks2orders\", \"cnt\", week)\n",
    "    for i in range(20):\n",
    "        pair_df = pair_df_org.groupby(\"aid_x\").head(i+1)\n",
    "        pair_dict = {k: v for k, v in zip(pair_df.get_column(\"aid_x\").to_list(), pair_df.get_column(\"aid_y\").to_list())}\n",
    "        trans_maps[f\"clicks2orders_pair{str(i)}\"] = pair_dict\n",
    "\n",
    "    pair_df_org = get_pair_df(\"word2vec_similar\", \"sim\", None)\n",
    "    for i in range(20):\n",
    "        pair_df = pair_df = pair_df_org.groupby(\"aid_x\").head(i+1)\n",
    "        pair_dict = {k: v for k, v in zip(pair_df.get_column(\"aid_x\").to_list(), pair_df.get_column(\"aid_y\").to_list())}\n",
    "        trans_maps[f\"word2vec_pair{str(i)}\"] = pair_dict\n",
    "\n",
    "    return trans_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal(excepts=[\"cfg\", \"logger\", \"cache\"])\n",
    "def make_valid_cand():\n",
    "    # データ読み込み\n",
    "    week_sessions = pl.read_parquet(cfg.prep_dir + f\"train_sessions_{cfg.valid_week}.parquet\")\n",
    "    week_sessions = week_sessions.select([\n",
    "        pl.col(\"session\").cast(pl.Int32),\n",
    "        pl.col(\"aid\").cast(pl.Int32),\n",
    "        pl.col(\"ts\"),\n",
    "        pl.col(\"type\")\n",
    "        ])\n",
    "    \n",
    "    week_labels = pl.read_parquet(cfg.prep_dir + f\"labels_{cfg.valid_week}.parquet\")\n",
    "    week_labels = week_labels.select([\n",
    "        pl.col(\"session\").cast(pl.Int32),\n",
    "        pl.col(\"clicks_labels\").cast(pl.Int32),\n",
    "        pl.col(\"carts_labels\"),\n",
    "        pl.col(\"orders_labels\")\n",
    "        ])\n",
    "    valid_sessions = week_sessions.get_column(\"session\").unique().to_list()\n",
    "    \n",
    "    trans_map_cache_file = f\"trans_maps_{cfg.valid_week}.pkl\"\n",
    "    trans_map_cache_path = cache.get_abspath(trans_map_cache_file)\n",
    "    with open(trans_map_cache_path, \"rb\") as f:\n",
    "        trans_maps = pickle.load(f)\n",
    "\n",
    "    # validに使うsessionを絞る\n",
    "    use_session_n = min(cfg.valid_session_n, len(valid_sessions))\n",
    "    random.seed(cfg.seed)\n",
    "    use_sessions = random.sample(valid_sessions, use_session_n)\n",
    "    week_sessions = week_sessions.filter(pl.col(\"session\").is_in(use_sessions))\n",
    "    week_labels = week_labels.filter(pl.col(\"session\").is_in(use_sessions))\n",
    "\n",
    "    # 候補選出\n",
    "    cand_df = make_cand_df(week_sessions, trans_maps=trans_maps)\n",
    "    return cand_df, week_sessions, week_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hourly_most_freq(week):\n",
    "    sessions = pd.read_parquet(cfg.prep_dir + f\"train_sessions_{week}.parquet\")\n",
    "    sessions[\"dt\"] = pd.to_datetime(sessions[\"ts\"], unit=\"ms\")\n",
    "    sessions[\"mdh\"] = sessions[\"dt\"].dt.month.astype(str) + \"_\" +\\\n",
    "                       sessions[\"dt\"].dt.day.astype(str) + \"_\" +\\\n",
    "                       sessions[\"dt\"].dt.hour.astype(str)\n",
    "    sessions = sessions.groupby([\"mdh\", \"aid\"])[\"ts\"].count().reset_index().rename(columns={\"ts\":\"cnt\"})\n",
    "    sessions = sessions.sort_values(\"cnt\", ascending=False).groupby(\"mdh\").head(100)\n",
    "    hourly_most_freq = sessions.sort_values(\"cnt\", ascending=False).groupby(\"mdh\")[\"aid\"].apply(list).to_dict()\n",
    "    cache_file = f\"hourly_most_freq_{week}.pkl\"\n",
    "    cache_path = cache.get_abspath(cache_file)\n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump(hourly_most_freq, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:00:00.364306 \t \n",
      "\n",
      "START\n",
      "\n",
      "\n",
      "0:12:45.326164 \t [add_candidate] session_frequent : start\n",
      "0:12:45.836992 \t [add_candidate] session_latest : start\n",
      "0:12:46.247465 \t [add_candidate] session_last_hourly_frequent : start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cache' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [92], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(cache_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m         pickle\u001b[39m.\u001b[39mdump(trans_maps, f)\n\u001b[0;32m---> 14\u001b[0m cand_df, _, labels \u001b[39m=\u001b[39m make_valid_cand()\n\u001b[1;32m     16\u001b[0m cand_df \u001b[39m=\u001b[39m cand_df\u001b[39m.\u001b[39mto_pandas()\n\u001b[1;32m     17\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto_pandas()\n",
      "Cell \u001b[0;32mIn [90], line 34\u001b[0m, in \u001b[0;36mmake_valid_cand\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m week_labels \u001b[39m=\u001b[39m week_labels\u001b[39m.\u001b[39mfilter(pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39msession\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mis_in(use_sessions))\n\u001b[1;32m     33\u001b[0m \u001b[39m# 候補選出\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m cand_df \u001b[39m=\u001b[39m make_cand_df(week_sessions, trans_maps\u001b[39m=\u001b[39;49mtrans_maps)\n\u001b[1;32m     35\u001b[0m \u001b[39mreturn\u001b[39;00m cand_df, week_sessions, week_labels\n",
      "Cell \u001b[0;32mIn [88], line 6\u001b[0m, in \u001b[0;36mmake_cand_df\u001b[0;34m(sessions, trans_maps)\u001b[0m\n\u001b[1;32m      4\u001b[0m cand\u001b[39m.\u001b[39madd(strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msession_frequent\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msession_frequent\u001b[39m\u001b[39m\"\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n\u001b[1;32m      5\u001b[0m cand\u001b[39m.\u001b[39madd(strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msession_latest\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msession_latest\u001b[39m\u001b[39m\"\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m cand\u001b[39m.\u001b[39;49madd(strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msession_last_hourly_frequent\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msession_last_hourly_frequent\u001b[39;49m\u001b[39m\"\u001b[39;49m, k\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):\n\u001b[1;32m      9\u001b[0m     cand\u001b[39m.\u001b[39madd(strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msession_latest\u001b[39m\u001b[39m\"\u001b[39m, trans_map\u001b[39m=\u001b[39mtrans_maps[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime_wt_pair\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(i)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msession_latest_time_wt_pair\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(i)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn [87], line 20\u001b[0m, in \u001b[0;36mCandidate.add\u001b[0;34m(self, strategy, name, usetypes, trans_map, k)\u001b[0m\n\u001b[1;32m     18\u001b[0m     candidate_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_frequent(candidate_df, k)\n\u001b[1;32m     19\u001b[0m \u001b[39melif\u001b[39;00m strategy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msession_last_hourly_frequent\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m     candidate_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session_last_hourly_frequent(candidate_df, k)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m trans_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     candidate_df[\u001b[39m\"\u001b[39m\u001b[39maid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m candidate_df[\u001b[39m\"\u001b[39m\u001b[39maid\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(trans_map)\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mint32\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [87], line 70\u001b[0m, in \u001b[0;36mCandidate._session_last_hourly_frequent\u001b[0;34m(self, candidate_df, k)\u001b[0m\n\u001b[1;32m     68\u001b[0m week \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mweek4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m cache_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhourly_most_freq_\u001b[39m\u001b[39m{\u001b[39;00mweek\u001b[39m}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 70\u001b[0m cache_path \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39mget_abspath(cache_file)\n\u001b[1;32m     71\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(cache_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     72\u001b[0m     hourly_most_freq \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cache' is not defined"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\n\\nSTART\\n\\n\")\n",
    "cache_file = f\"trans_maps_{cfg.valid_week}.pkl\"\n",
    "cache_path = cache.get_abspath(cache_file)\n",
    "\n",
    "if cache.exists(cache_path):\n",
    "    logger.info(f\"[{cache_file}] cache exists. load cache and skip process.\")\n",
    "    with open(cache_path, \"rb\") as f:\n",
    "        trans_maps = pickle.load(f)\n",
    "else:\n",
    "    trans_maps = get_trans_maps(cfg.valid_week)\n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump(trans_maps, f)\n",
    "\n",
    "cand_df, _, labels = make_valid_cand()\n",
    "\n",
    "cand_df = cand_df.to_pandas()\n",
    "labels = labels.to_pandas()\n",
    "vl_pred_df = cand_df.groupby(\"session\")[\"aid\"].apply(list).reset_index()\n",
    "session_n_max = cand_df[\"session\"].value_counts().max()\n",
    "session_n_mean = cand_df[\"session\"].value_counts().mean()\n",
    "session_n_median = cand_df[\"session\"].value_counts().median()\n",
    "\n",
    "score = evaluate(labels[\"clicks_labels\"].tolist(),\n",
    "                 labels[\"carts_labels\"].tolist(),\n",
    "                 labels[\"orders_labels\"].tolist(),\n",
    "                 vl_pred_df[\"aid\"].tolist(),\n",
    "                 vl_pred_df[\"aid\"].tolist(),\n",
    "                 vl_pred_df[\"aid\"].tolist(),\n",
    "                 session_n_max)\n",
    "\n",
    "session_n_max = cand_df[\"session\"].value_counts().max()\n",
    "session_n_mean = cand_df[\"session\"].value_counts().mean()\n",
    "session_n_median = cand_df[\"session\"].value_counts().median()\n",
    "logger.info(f\"session_n_max : {str(session_n_max)},  session_n_mean : {str(session_n_mean)},  session_n_median : {str(session_n_median)}\")\n",
    "logger.info(f\"score : {str(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
