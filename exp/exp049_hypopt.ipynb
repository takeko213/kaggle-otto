{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp049\n",
    "co_visit rank追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import pathlib\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cudf\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as optuna_lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import line_notify\n",
    "import my_logger\n",
    "from noglobal import noglobal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Cfg:\n",
    "    loglevel = \"INFO\"\n",
    "    exp_name = \"exp049_hypopt\"\n",
    "    seed = 42\n",
    "    k = 20\n",
    "    cand_n = 15\n",
    "    negative_sample = 1\n",
    "    train_chunk_n = 1\n",
    "    type2id = {\"clicks\":0, \"carts\":1, \"orders\":2}\n",
    "    id2type = {0:\"clicks\", 1:\"carts\", 2:\"orders\"}\n",
    "    train_weeks = [\"week3\"]\n",
    "    valid_week = \"week4\"\n",
    "    valid_session_n = 100_000\n",
    "    input_dir = os.getenv('INPUT_DIR')\n",
    "    output_dir = os.getenv('OUTPUT_DIR')\n",
    "    prep_dir = os.getenv(\"PREP_DIR\")\n",
    "\n",
    "cfg = Cfg()\n",
    "os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name), exist_ok=True)\n",
    "os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name, \"cache\"), exist_ok=True)\n",
    "random.seed(cfg.seed)\n",
    "\n",
    "logger = my_logger.init_logger(cfg.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'binary', \n",
    "        'boosting': 'gbdt', \n",
    "        'learning_rate': 0.1, \n",
    "        'metric': 'binary_logloss', \n",
    "        'seed': cfg.seed\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 10:54:06,211]\u001b[0m A new study created in memory with name: no-name-0d5a8659-7cf9-445c-9418-ee9bf20e89cd\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.445741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.350707\tvalid_1's binary_logloss: 0.34536\n",
      "[200]\tvalid_0's binary_logloss: 0.348237\tvalid_1's binary_logloss: 0.343555\n",
      "[300]\tvalid_0's binary_logloss: 0.346895\tvalid_1's binary_logloss: 0.342747\n",
      "[400]\tvalid_0's binary_logloss: 0.345826\tvalid_1's binary_logloss: 0.342236\n",
      "[500]\tvalid_0's binary_logloss: 0.344876\tvalid_1's binary_logloss: 0.341686\n",
      "[600]\tvalid_0's binary_logloss: 0.344016\tvalid_1's binary_logloss: 0.341306\n",
      "[700]\tvalid_0's binary_logloss: 0.343331\tvalid_1's binary_logloss: 0.341102\n",
      "[800]\tvalid_0's binary_logloss: 0.342644\tvalid_1's binary_logloss: 0.340886\n",
      "[900]\tvalid_0's binary_logloss: 0.341936\tvalid_1's binary_logloss: 0.340707\n",
      "[1000]\tvalid_0's binary_logloss: 0.341242\tvalid_1's binary_logloss: 0.340553\n",
      "[1100]\tvalid_0's binary_logloss: 0.340627\tvalid_1's binary_logloss: 0.340445\n",
      "[1200]\tvalid_0's binary_logloss: 0.340052\tvalid_1's binary_logloss: 0.340339\n",
      "[1300]\tvalid_0's binary_logloss: 0.339456\tvalid_1's binary_logloss: 0.340227\n",
      "[1400]\tvalid_0's binary_logloss: 0.338905\tvalid_1's binary_logloss: 0.340135\n",
      "[1500]\tvalid_0's binary_logloss: 0.338369\tvalid_1's binary_logloss: 0.340083\n",
      "[1600]\tvalid_0's binary_logloss: 0.337854\tvalid_1's binary_logloss: 0.340019\n",
      "[1700]\tvalid_0's binary_logloss: 0.337376\tvalid_1's binary_logloss: 0.340004\n",
      "[1800]\tvalid_0's binary_logloss: 0.336878\tvalid_1's binary_logloss: 0.339961\n",
      "[1900]\tvalid_0's binary_logloss: 0.336403\tvalid_1's binary_logloss: 0.339939\n",
      "[2000]\tvalid_0's binary_logloss: 0.33594\tvalid_1's binary_logloss: 0.339911\n",
      "[2100]\tvalid_0's binary_logloss: 0.335449\tvalid_1's binary_logloss: 0.339882\n",
      "[2200]\tvalid_0's binary_logloss: 0.334921\tvalid_1's binary_logloss: 0.33983\n",
      "[2300]\tvalid_0's binary_logloss: 0.334473\tvalid_1's binary_logloss: 0.339822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339813:  14%|#4        | 1/7 [05:36<33:38, 336.45s/it]\u001b[32m[I 2022-12-19 10:59:42,672]\u001b[0m Trial 0 finished with value: 0.33981253383793464 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.33981253383793464.\u001b[0m\n",
      "feature_fraction, val_score: 0.339813:  14%|#4        | 1/7 [05:36<33:38, 336.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2271]\tvalid_0's binary_logloss: 0.334585\tvalid_1's binary_logloss: 0.339813\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.350651\tvalid_1's binary_logloss: 0.345349\n",
      "[200]\tvalid_0's binary_logloss: 0.348261\tvalid_1's binary_logloss: 0.343633\n",
      "[300]\tvalid_0's binary_logloss: 0.346992\tvalid_1's binary_logloss: 0.342996\n",
      "[400]\tvalid_0's binary_logloss: 0.345896\tvalid_1's binary_logloss: 0.342467\n",
      "[500]\tvalid_0's binary_logloss: 0.344904\tvalid_1's binary_logloss: 0.342017\n",
      "[600]\tvalid_0's binary_logloss: 0.344018\tvalid_1's binary_logloss: 0.341608\n",
      "[700]\tvalid_0's binary_logloss: 0.343254\tvalid_1's binary_logloss: 0.341323\n",
      "[800]\tvalid_0's binary_logloss: 0.34252\tvalid_1's binary_logloss: 0.341136\n",
      "[900]\tvalid_0's binary_logloss: 0.341829\tvalid_1's binary_logloss: 0.340977\n",
      "[1000]\tvalid_0's binary_logloss: 0.341124\tvalid_1's binary_logloss: 0.340732\n",
      "[1100]\tvalid_0's binary_logloss: 0.340477\tvalid_1's binary_logloss: 0.340575\n",
      "[1200]\tvalid_0's binary_logloss: 0.33985\tvalid_1's binary_logloss: 0.340441\n",
      "[1300]\tvalid_0's binary_logloss: 0.339213\tvalid_1's binary_logloss: 0.340321\n",
      "[1400]\tvalid_0's binary_logloss: 0.338649\tvalid_1's binary_logloss: 0.340263\n",
      "[1500]\tvalid_0's binary_logloss: 0.33811\tvalid_1's binary_logloss: 0.340231\n",
      "[1600]\tvalid_0's binary_logloss: 0.337564\tvalid_1's binary_logloss: 0.340191\n",
      "[1700]\tvalid_0's binary_logloss: 0.337032\tvalid_1's binary_logloss: 0.340126\n",
      "[1800]\tvalid_0's binary_logloss: 0.336521\tvalid_1's binary_logloss: 0.340129\n",
      "[1900]\tvalid_0's binary_logloss: 0.336019\tvalid_1's binary_logloss: 0.340102\n",
      "[2000]\tvalid_0's binary_logloss: 0.335504\tvalid_1's binary_logloss: 0.340064\n",
      "[2100]\tvalid_0's binary_logloss: 0.33501\tvalid_1's binary_logloss: 0.340016\n",
      "[2200]\tvalid_0's binary_logloss: 0.334585\tvalid_1's binary_logloss: 0.340026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339813:  29%|##8       | 2/7 [10:36<26:14, 314.95s/it]\u001b[32m[I 2022-12-19 11:04:42,568]\u001b[0m Trial 1 finished with value: 0.34000610300304246 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.33981253383793464.\u001b[0m\n",
      "feature_fraction, val_score: 0.339813:  29%|##8       | 2/7 [10:36<26:14, 314.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2116]\tvalid_0's binary_logloss: 0.33493\tvalid_1's binary_logloss: 0.340006\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.395945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.350632\tvalid_1's binary_logloss: 0.345346\n",
      "[200]\tvalid_0's binary_logloss: 0.348214\tvalid_1's binary_logloss: 0.343567\n",
      "[300]\tvalid_0's binary_logloss: 0.346917\tvalid_1's binary_logloss: 0.342847\n",
      "[400]\tvalid_0's binary_logloss: 0.345844\tvalid_1's binary_logloss: 0.34234\n",
      "[500]\tvalid_0's binary_logloss: 0.344892\tvalid_1's binary_logloss: 0.341905\n",
      "[600]\tvalid_0's binary_logloss: 0.344066\tvalid_1's binary_logloss: 0.341621\n",
      "[700]\tvalid_0's binary_logloss: 0.343322\tvalid_1's binary_logloss: 0.341351\n",
      "[800]\tvalid_0's binary_logloss: 0.342564\tvalid_1's binary_logloss: 0.341024\n",
      "[900]\tvalid_0's binary_logloss: 0.341854\tvalid_1's binary_logloss: 0.34082\n",
      "[1000]\tvalid_0's binary_logloss: 0.341205\tvalid_1's binary_logloss: 0.34065\n",
      "[1100]\tvalid_0's binary_logloss: 0.340607\tvalid_1's binary_logloss: 0.340504\n",
      "[1200]\tvalid_0's binary_logloss: 0.339994\tvalid_1's binary_logloss: 0.340378\n",
      "[1300]\tvalid_0's binary_logloss: 0.339387\tvalid_1's binary_logloss: 0.340269\n",
      "[1400]\tvalid_0's binary_logloss: 0.338816\tvalid_1's binary_logloss: 0.340212\n",
      "[1500]\tvalid_0's binary_logloss: 0.338289\tvalid_1's binary_logloss: 0.340154\n",
      "[1600]\tvalid_0's binary_logloss: 0.337748\tvalid_1's binary_logloss: 0.340078\n",
      "[1700]\tvalid_0's binary_logloss: 0.337247\tvalid_1's binary_logloss: 0.340068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339813:  43%|####2     | 3/7 [14:47<19:04, 286.00s/it]\u001b[32m[I 2022-12-19 11:08:54,119]\u001b[0m Trial 2 finished with value: 0.3400575920731876 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.33981253383793464.\u001b[0m\n",
      "feature_fraction, val_score: 0.339813:  43%|####2     | 3/7 [14:47<19:04, 286.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1668]\tvalid_0's binary_logloss: 0.337399\tvalid_1's binary_logloss: 0.340058\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.360731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.3506\tvalid_1's binary_logloss: 0.345325\n",
      "[200]\tvalid_0's binary_logloss: 0.348191\tvalid_1's binary_logloss: 0.343654\n",
      "[300]\tvalid_0's binary_logloss: 0.346838\tvalid_1's binary_logloss: 0.342893\n",
      "[400]\tvalid_0's binary_logloss: 0.345765\tvalid_1's binary_logloss: 0.342279\n",
      "[500]\tvalid_0's binary_logloss: 0.344773\tvalid_1's binary_logloss: 0.341766\n",
      "[600]\tvalid_0's binary_logloss: 0.343927\tvalid_1's binary_logloss: 0.341501\n",
      "[700]\tvalid_0's binary_logloss: 0.343143\tvalid_1's binary_logloss: 0.341141\n",
      "[800]\tvalid_0's binary_logloss: 0.342385\tvalid_1's binary_logloss: 0.340896\n",
      "[900]\tvalid_0's binary_logloss: 0.341691\tvalid_1's binary_logloss: 0.340754\n",
      "[1000]\tvalid_0's binary_logloss: 0.341048\tvalid_1's binary_logloss: 0.340592\n",
      "[1100]\tvalid_0's binary_logloss: 0.340358\tvalid_1's binary_logloss: 0.340419\n",
      "[1200]\tvalid_0's binary_logloss: 0.339772\tvalid_1's binary_logloss: 0.340317\n",
      "[1300]\tvalid_0's binary_logloss: 0.339126\tvalid_1's binary_logloss: 0.340203\n",
      "[1400]\tvalid_0's binary_logloss: 0.338522\tvalid_1's binary_logloss: 0.340109\n",
      "[1500]\tvalid_0's binary_logloss: 0.337974\tvalid_1's binary_logloss: 0.340056\n",
      "[1600]\tvalid_0's binary_logloss: 0.337426\tvalid_1's binary_logloss: 0.34001\n",
      "[1700]\tvalid_0's binary_logloss: 0.336907\tvalid_1's binary_logloss: 0.339974\n",
      "[1800]\tvalid_0's binary_logloss: 0.336363\tvalid_1's binary_logloss: 0.339935\n",
      "[1900]\tvalid_0's binary_logloss: 0.335797\tvalid_1's binary_logloss: 0.339892\n",
      "[2000]\tvalid_0's binary_logloss: 0.335291\tvalid_1's binary_logloss: 0.339913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339813:  57%|#####7    | 4/7 [20:11<15:02, 300.91s/it]\u001b[32m[I 2022-12-19 11:14:17,880]\u001b[0m Trial 3 finished with value: 0.3398719226102076 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.33981253383793464.\u001b[0m\n",
      "feature_fraction, val_score: 0.339813:  57%|#####7    | 4/7 [20:11<15:02, 300.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1956]\tvalid_0's binary_logloss: 0.335521\tvalid_1's binary_logloss: 0.339872\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.352892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.351532\tvalid_1's binary_logloss: 0.345934\n",
      "[200]\tvalid_0's binary_logloss: 0.348549\tvalid_1's binary_logloss: 0.343735\n",
      "[300]\tvalid_0's binary_logloss: 0.34729\tvalid_1's binary_logloss: 0.342962\n",
      "[400]\tvalid_0's binary_logloss: 0.346265\tvalid_1's binary_logloss: 0.342455\n",
      "[500]\tvalid_0's binary_logloss: 0.345377\tvalid_1's binary_logloss: 0.342048\n",
      "[600]\tvalid_0's binary_logloss: 0.344608\tvalid_1's binary_logloss: 0.341656\n",
      "[700]\tvalid_0's binary_logloss: 0.343849\tvalid_1's binary_logloss: 0.341417\n",
      "[800]\tvalid_0's binary_logloss: 0.343174\tvalid_1's binary_logloss: 0.341226\n",
      "[900]\tvalid_0's binary_logloss: 0.342533\tvalid_1's binary_logloss: 0.340998\n",
      "[1000]\tvalid_0's binary_logloss: 0.341955\tvalid_1's binary_logloss: 0.340848\n",
      "[1100]\tvalid_0's binary_logloss: 0.341333\tvalid_1's binary_logloss: 0.340599\n",
      "[1200]\tvalid_0's binary_logloss: 0.340763\tvalid_1's binary_logloss: 0.340466\n",
      "[1300]\tvalid_0's binary_logloss: 0.340221\tvalid_1's binary_logloss: 0.340375\n",
      "[1400]\tvalid_0's binary_logloss: 0.33966\tvalid_1's binary_logloss: 0.340242\n",
      "[1500]\tvalid_0's binary_logloss: 0.339154\tvalid_1's binary_logloss: 0.340191\n",
      "[1600]\tvalid_0's binary_logloss: 0.338669\tvalid_1's binary_logloss: 0.340128\n",
      "[1700]\tvalid_0's binary_logloss: 0.338189\tvalid_1's binary_logloss: 0.34009\n",
      "[1800]\tvalid_0's binary_logloss: 0.337694\tvalid_1's binary_logloss: 0.340025\n",
      "[1900]\tvalid_0's binary_logloss: 0.337268\tvalid_1's binary_logloss: 0.340018\n",
      "[2000]\tvalid_0's binary_logloss: 0.336836\tvalid_1's binary_logloss: 0.33999\n",
      "[2100]\tvalid_0's binary_logloss: 0.336386\tvalid_1's binary_logloss: 0.339934\n",
      "[2200]\tvalid_0's binary_logloss: 0.335927\tvalid_1's binary_logloss: 0.339873\n",
      "[2300]\tvalid_0's binary_logloss: 0.335477\tvalid_1's binary_logloss: 0.339837\n",
      "[2400]\tvalid_0's binary_logloss: 0.335039\tvalid_1's binary_logloss: 0.33979\n",
      "[2500]\tvalid_0's binary_logloss: 0.334613\tvalid_1's binary_logloss: 0.339774\n",
      "[2600]\tvalid_0's binary_logloss: 0.33418\tvalid_1's binary_logloss: 0.339756\n",
      "[2700]\tvalid_0's binary_logloss: 0.333765\tvalid_1's binary_logloss: 0.339743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339740:  71%|#######1  | 5/7 [27:40<11:48, 354.21s/it]\u001b[32m[I 2022-12-19 11:21:46,591]\u001b[0m Trial 4 finished with value: 0.3397395925155384 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.3397395925155384.\u001b[0m\n",
      "feature_fraction, val_score: 0.339740:  71%|#######1  | 5/7 [27:40<11:48, 354.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2663]\tvalid_0's binary_logloss: 0.33391\tvalid_1's binary_logloss: 0.33974\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.347396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.350969\tvalid_1's binary_logloss: 0.345484\n",
      "[200]\tvalid_0's binary_logloss: 0.348284\tvalid_1's binary_logloss: 0.343557\n",
      "[300]\tvalid_0's binary_logloss: 0.347038\tvalid_1's binary_logloss: 0.342824\n",
      "[400]\tvalid_0's binary_logloss: 0.34605\tvalid_1's binary_logloss: 0.342379\n",
      "[500]\tvalid_0's binary_logloss: 0.345143\tvalid_1's binary_logloss: 0.341965\n",
      "[600]\tvalid_0's binary_logloss: 0.344348\tvalid_1's binary_logloss: 0.341581\n",
      "[700]\tvalid_0's binary_logloss: 0.343626\tvalid_1's binary_logloss: 0.341333\n",
      "[800]\tvalid_0's binary_logloss: 0.342914\tvalid_1's binary_logloss: 0.341109\n",
      "[900]\tvalid_0's binary_logloss: 0.342296\tvalid_1's binary_logloss: 0.340929\n",
      "[1000]\tvalid_0's binary_logloss: 0.341666\tvalid_1's binary_logloss: 0.340779\n",
      "[1100]\tvalid_0's binary_logloss: 0.341054\tvalid_1's binary_logloss: 0.340591\n",
      "[1200]\tvalid_0's binary_logloss: 0.340504\tvalid_1's binary_logloss: 0.34051\n",
      "[1300]\tvalid_0's binary_logloss: 0.339926\tvalid_1's binary_logloss: 0.34039\n",
      "[1400]\tvalid_0's binary_logloss: 0.339409\tvalid_1's binary_logloss: 0.340324\n",
      "[1500]\tvalid_0's binary_logloss: 0.338912\tvalid_1's binary_logloss: 0.340257\n",
      "[1600]\tvalid_0's binary_logloss: 0.338372\tvalid_1's binary_logloss: 0.340166\n",
      "[1700]\tvalid_0's binary_logloss: 0.337855\tvalid_1's binary_logloss: 0.34009\n",
      "[1800]\tvalid_0's binary_logloss: 0.337365\tvalid_1's binary_logloss: 0.340045\n",
      "[1900]\tvalid_0's binary_logloss: 0.336872\tvalid_1's binary_logloss: 0.339985\n",
      "[2000]\tvalid_0's binary_logloss: 0.336401\tvalid_1's binary_logloss: 0.339964\n",
      "[2100]\tvalid_0's binary_logloss: 0.335924\tvalid_1's binary_logloss: 0.339903\n",
      "[2200]\tvalid_0's binary_logloss: 0.335464\tvalid_1's binary_logloss: 0.339886\n",
      "[2300]\tvalid_0's binary_logloss: 0.33503\tvalid_1's binary_logloss: 0.339869\n",
      "[2400]\tvalid_0's binary_logloss: 0.334617\tvalid_1's binary_logloss: 0.33983\n",
      "[2500]\tvalid_0's binary_logloss: 0.334197\tvalid_1's binary_logloss: 0.339826\n",
      "[2600]\tvalid_0's binary_logloss: 0.33377\tvalid_1's binary_logloss: 0.339804\n",
      "[2700]\tvalid_0's binary_logloss: 0.333321\tvalid_1's binary_logloss: 0.33979\n",
      "[2800]\tvalid_0's binary_logloss: 0.332887\tvalid_1's binary_logloss: 0.339779\n",
      "[2900]\tvalid_0's binary_logloss: 0.332458\tvalid_1's binary_logloss: 0.339751\n",
      "[3000]\tvalid_0's binary_logloss: 0.332046\tvalid_1's binary_logloss: 0.339741\n",
      "[3100]\tvalid_0's binary_logloss: 0.331646\tvalid_1's binary_logloss: 0.33973\n",
      "[3200]\tvalid_0's binary_logloss: 0.331228\tvalid_1's binary_logloss: 0.339697\n",
      "[3300]\tvalid_0's binary_logloss: 0.330813\tvalid_1's binary_logloss: 0.339678\n",
      "[3400]\tvalid_0's binary_logloss: 0.33039\tvalid_1's binary_logloss: 0.339653\n",
      "[3500]\tvalid_0's binary_logloss: 0.33\tvalid_1's binary_logloss: 0.339666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339649:  86%|########5 | 6/7 [36:45<06:59, 419.11s/it]\u001b[32m[I 2022-12-19 11:30:51,692]\u001b[0m Trial 5 finished with value: 0.33964855394784654 and parameters: {'feature_fraction': 0.5}. Best is trial 5 with value: 0.33964855394784654.\u001b[0m\n",
      "feature_fraction, val_score: 0.339649:  86%|########5 | 6/7 [36:45<06:59, 419.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3404]\tvalid_0's binary_logloss: 0.330374\tvalid_1's binary_logloss: 0.339649\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.667528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.350961\tvalid_1's binary_logloss: 0.345642\n",
      "[200]\tvalid_0's binary_logloss: 0.348367\tvalid_1's binary_logloss: 0.343747\n",
      "[300]\tvalid_0's binary_logloss: 0.34706\tvalid_1's binary_logloss: 0.343\n",
      "[400]\tvalid_0's binary_logloss: 0.346017\tvalid_1's binary_logloss: 0.342437\n",
      "[500]\tvalid_0's binary_logloss: 0.34503\tvalid_1's binary_logloss: 0.341872\n",
      "[600]\tvalid_0's binary_logloss: 0.344262\tvalid_1's binary_logloss: 0.341527\n",
      "[700]\tvalid_0's binary_logloss: 0.343528\tvalid_1's binary_logloss: 0.341298\n",
      "[800]\tvalid_0's binary_logloss: 0.342818\tvalid_1's binary_logloss: 0.341072\n",
      "[900]\tvalid_0's binary_logloss: 0.342151\tvalid_1's binary_logloss: 0.340866\n",
      "[1000]\tvalid_0's binary_logloss: 0.341508\tvalid_1's binary_logloss: 0.340665\n",
      "[1100]\tvalid_0's binary_logloss: 0.340828\tvalid_1's binary_logloss: 0.340492\n",
      "[1200]\tvalid_0's binary_logloss: 0.340255\tvalid_1's binary_logloss: 0.340394\n",
      "[1300]\tvalid_0's binary_logloss: 0.339686\tvalid_1's binary_logloss: 0.340285\n",
      "[1400]\tvalid_0's binary_logloss: 0.339044\tvalid_1's binary_logloss: 0.340113\n",
      "[1500]\tvalid_0's binary_logloss: 0.338488\tvalid_1's binary_logloss: 0.340023\n",
      "[1600]\tvalid_0's binary_logloss: 0.337987\tvalid_1's binary_logloss: 0.339959\n",
      "[1700]\tvalid_0's binary_logloss: 0.337471\tvalid_1's binary_logloss: 0.339906\n",
      "[1800]\tvalid_0's binary_logloss: 0.336952\tvalid_1's binary_logloss: 0.33987\n",
      "[1900]\tvalid_0's binary_logloss: 0.336501\tvalid_1's binary_logloss: 0.339824\n",
      "[2000]\tvalid_0's binary_logloss: 0.336026\tvalid_1's binary_logloss: 0.339795\n",
      "[2100]\tvalid_0's binary_logloss: 0.33557\tvalid_1's binary_logloss: 0.339747\n",
      "[2200]\tvalid_0's binary_logloss: 0.335126\tvalid_1's binary_logloss: 0.33972\n",
      "[2300]\tvalid_0's binary_logloss: 0.334705\tvalid_1's binary_logloss: 0.339695\n",
      "[2400]\tvalid_0's binary_logloss: 0.33424\tvalid_1's binary_logloss: 0.339651\n",
      "[2500]\tvalid_0's binary_logloss: 0.333764\tvalid_1's binary_logloss: 0.339629\n",
      "[2600]\tvalid_0's binary_logloss: 0.333332\tvalid_1's binary_logloss: 0.339616\n",
      "[2700]\tvalid_0's binary_logloss: 0.332919\tvalid_1's binary_logloss: 0.339604\n",
      "[2800]\tvalid_0's binary_logloss: 0.3325\tvalid_1's binary_logloss: 0.339596\n",
      "[2900]\tvalid_0's binary_logloss: 0.332096\tvalid_1's binary_logloss: 0.339597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.339592: 100%|##########| 7/7 [44:08<00:00, 426.94s/it]\u001b[32m[I 2022-12-19 11:38:14,755]\u001b[0m Trial 6 finished with value: 0.3395915207325077 and parameters: {'feature_fraction': 0.6}. Best is trial 6 with value: 0.3395915207325077.\u001b[0m\n",
      "feature_fraction, val_score: 0.339592: 100%|##########| 7/7 [44:08<00:00, 378.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2823]\tvalid_0's binary_logloss: 0.332402\tvalid_1's binary_logloss: 0.339592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.400546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.344582\tvalid_1's binary_logloss: 0.341681\n",
      "[200]\tvalid_0's binary_logloss: 0.340624\tvalid_1's binary_logloss: 0.340517\n",
      "[300]\tvalid_0's binary_logloss: 0.337585\tvalid_1's binary_logloss: 0.340153\n",
      "[400]\tvalid_0's binary_logloss: 0.334981\tvalid_1's binary_logloss: 0.339953\n",
      "[500]\tvalid_0's binary_logloss: 0.332386\tvalid_1's binary_logloss: 0.339857\n",
      "[600]\tvalid_0's binary_logloss: 0.329857\tvalid_1's binary_logloss: 0.339778\n",
      "[700]\tvalid_0's binary_logloss: 0.327513\tvalid_1's binary_logloss: 0.339688\n",
      "[800]\tvalid_0's binary_logloss: 0.325324\tvalid_1's binary_logloss: 0.339652\n",
      "[900]\tvalid_0's binary_logloss: 0.323176\tvalid_1's binary_logloss: 0.339673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:   5%|5         | 1/20 [04:19<1:22:18, 259.92s/it]\u001b[32m[I 2022-12-19 11:42:34,684]\u001b[0m Trial 7 finished with value: 0.339622330774809 and parameters: {'num_leaves': 171}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:   5%|5         | 1/20 [04:19<1:22:18, 259.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[871]\tvalid_0's binary_logloss: 0.323732\tvalid_1's binary_logloss: 0.339622\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.686875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.34412\tvalid_1's binary_logloss: 0.341454\n",
      "[200]\tvalid_0's binary_logloss: 0.339875\tvalid_1's binary_logloss: 0.340395\n",
      "[300]\tvalid_0's binary_logloss: 0.336652\tvalid_1's binary_logloss: 0.340184\n",
      "[400]\tvalid_0's binary_logloss: 0.333682\tvalid_1's binary_logloss: 0.339971\n",
      "[500]\tvalid_0's binary_logloss: 0.331036\tvalid_1's binary_logloss: 0.33993\n",
      "[600]\tvalid_0's binary_logloss: 0.328247\tvalid_1's binary_logloss: 0.339855\n",
      "[700]\tvalid_0's binary_logloss: 0.325657\tvalid_1's binary_logloss: 0.339827\n",
      "[800]\tvalid_0's binary_logloss: 0.323336\tvalid_1's binary_logloss: 0.339872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  10%|#         | 2/20 [08:41<1:18:12, 260.72s/it]\u001b[32m[I 2022-12-19 11:46:55,959]\u001b[0m Trial 8 finished with value: 0.33981142302141937 and parameters: {'num_leaves': 191}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  10%|#         | 2/20 [08:41<1:18:12, 260.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[731]\tvalid_0's binary_logloss: 0.324876\tvalid_1's binary_logloss: 0.339811\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.432354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.344528\tvalid_1's binary_logloss: 0.341617\n",
      "[200]\tvalid_0's binary_logloss: 0.340607\tvalid_1's binary_logloss: 0.340661\n",
      "[300]\tvalid_0's binary_logloss: 0.337644\tvalid_1's binary_logloss: 0.340368\n",
      "[400]\tvalid_0's binary_logloss: 0.334801\tvalid_1's binary_logloss: 0.339989\n",
      "[500]\tvalid_0's binary_logloss: 0.332354\tvalid_1's binary_logloss: 0.339855\n",
      "[600]\tvalid_0's binary_logloss: 0.3299\tvalid_1's binary_logloss: 0.339897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  15%|#5        | 3/20 [11:38<1:03:02, 222.48s/it]\u001b[32m[I 2022-12-19 11:49:52,943]\u001b[0m Trial 9 finished with value: 0.339786429781104 and parameters: {'num_leaves': 173}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  15%|#5        | 3/20 [11:38<1:03:02, 222.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[513]\tvalid_0's binary_logloss: 0.331926\tvalid_1's binary_logloss: 0.339786\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.388876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.352503\tvalid_1's binary_logloss: 0.346665\n",
      "[200]\tvalid_0's binary_logloss: 0.349775\tvalid_1's binary_logloss: 0.344573\n",
      "[300]\tvalid_0's binary_logloss: 0.348418\tvalid_1's binary_logloss: 0.343586\n",
      "[400]\tvalid_0's binary_logloss: 0.347541\tvalid_1's binary_logloss: 0.34303\n",
      "[500]\tvalid_0's binary_logloss: 0.346734\tvalid_1's binary_logloss: 0.342605\n",
      "[600]\tvalid_0's binary_logloss: 0.346049\tvalid_1's binary_logloss: 0.342219\n",
      "[700]\tvalid_0's binary_logloss: 0.345456\tvalid_1's binary_logloss: 0.3419\n",
      "[800]\tvalid_0's binary_logloss: 0.344892\tvalid_1's binary_logloss: 0.341644\n",
      "[900]\tvalid_0's binary_logloss: 0.344356\tvalid_1's binary_logloss: 0.341463\n",
      "[1000]\tvalid_0's binary_logloss: 0.343874\tvalid_1's binary_logloss: 0.341313\n",
      "[1100]\tvalid_0's binary_logloss: 0.343382\tvalid_1's binary_logloss: 0.341175\n",
      "[1200]\tvalid_0's binary_logloss: 0.342941\tvalid_1's binary_logloss: 0.341002\n",
      "[1300]\tvalid_0's binary_logloss: 0.342474\tvalid_1's binary_logloss: 0.340832\n",
      "[1400]\tvalid_0's binary_logloss: 0.341976\tvalid_1's binary_logloss: 0.340615\n",
      "[1500]\tvalid_0's binary_logloss: 0.34155\tvalid_1's binary_logloss: 0.340479\n",
      "[1600]\tvalid_0's binary_logloss: 0.34114\tvalid_1's binary_logloss: 0.340371\n",
      "[1700]\tvalid_0's binary_logloss: 0.340791\tvalid_1's binary_logloss: 0.340339\n",
      "[1800]\tvalid_0's binary_logloss: 0.340393\tvalid_1's binary_logloss: 0.34023\n",
      "[1900]\tvalid_0's binary_logloss: 0.340022\tvalid_1's binary_logloss: 0.340168\n",
      "[2000]\tvalid_0's binary_logloss: 0.339641\tvalid_1's binary_logloss: 0.34013\n",
      "[2100]\tvalid_0's binary_logloss: 0.339323\tvalid_1's binary_logloss: 0.340083\n",
      "[2200]\tvalid_0's binary_logloss: 0.338973\tvalid_1's binary_logloss: 0.340026\n",
      "[2300]\tvalid_0's binary_logloss: 0.33863\tvalid_1's binary_logloss: 0.339947\n",
      "[2400]\tvalid_0's binary_logloss: 0.338291\tvalid_1's binary_logloss: 0.33991\n",
      "[2500]\tvalid_0's binary_logloss: 0.337951\tvalid_1's binary_logloss: 0.339884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  20%|##        | 4/20 [17:34<1:13:24, 275.28s/it]\u001b[32m[I 2022-12-19 11:55:49,151]\u001b[0m Trial 10 finished with value: 0.339879119184035 and parameters: {'num_leaves': 21}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  20%|##        | 4/20 [17:34<1:13:24, 275.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2443]\tvalid_0's binary_logloss: 0.338142\tvalid_1's binary_logloss: 0.339879\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.383023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.344219\tvalid_1's binary_logloss: 0.341624\n",
      "[200]\tvalid_0's binary_logloss: 0.340131\tvalid_1's binary_logloss: 0.340663\n",
      "[300]\tvalid_0's binary_logloss: 0.33693\tvalid_1's binary_logloss: 0.340185\n",
      "[400]\tvalid_0's binary_logloss: 0.3339\tvalid_1's binary_logloss: 0.339899\n",
      "[500]\tvalid_0's binary_logloss: 0.331426\tvalid_1's binary_logloss: 0.33999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  25%|##5       | 5/20 [20:18<58:46, 235.11s/it]  \u001b[32m[I 2022-12-19 11:58:33,031]\u001b[0m Trial 11 finished with value: 0.3398541416324502 and parameters: {'num_leaves': 185}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  25%|##5       | 5/20 [20:18<58:46, 235.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's binary_logloss: 0.332801\tvalid_1's binary_logloss: 0.339854\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.405979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.342759\tvalid_1's binary_logloss: 0.341138\n",
      "[200]\tvalid_0's binary_logloss: 0.33792\tvalid_1's binary_logloss: 0.340492\n",
      "[300]\tvalid_0's binary_logloss: 0.333847\tvalid_1's binary_logloss: 0.340064\n",
      "[400]\tvalid_0's binary_logloss: 0.330444\tvalid_1's binary_logloss: 0.339999\n",
      "[500]\tvalid_0's binary_logloss: 0.326999\tvalid_1's binary_logloss: 0.339969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  30%|###       | 6/20 [23:21<50:44, 217.43s/it]\u001b[32m[I 2022-12-19 12:01:36,161]\u001b[0m Trial 12 finished with value: 0.3399264089869051 and parameters: {'num_leaves': 248}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  30%|###       | 6/20 [23:21<50:44, 217.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[434]\tvalid_0's binary_logloss: 0.329216\tvalid_1's binary_logloss: 0.339926\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.742180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.345271\tvalid_1's binary_logloss: 0.341877\n",
      "[200]\tvalid_0's binary_logloss: 0.341705\tvalid_1's binary_logloss: 0.340829\n",
      "[300]\tvalid_0's binary_logloss: 0.338932\tvalid_1's binary_logloss: 0.34026\n",
      "[400]\tvalid_0's binary_logloss: 0.336527\tvalid_1's binary_logloss: 0.340052\n",
      "[500]\tvalid_0's binary_logloss: 0.334263\tvalid_1's binary_logloss: 0.339845\n",
      "[600]\tvalid_0's binary_logloss: 0.332185\tvalid_1's binary_logloss: 0.339825\n",
      "[700]\tvalid_0's binary_logloss: 0.33008\tvalid_1's binary_logloss: 0.339704\n",
      "[800]\tvalid_0's binary_logloss: 0.328097\tvalid_1's binary_logloss: 0.339733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  35%|###5      | 7/20 [27:04<47:30, 219.27s/it]\u001b[32m[I 2022-12-19 12:05:19,201]\u001b[0m Trial 13 finished with value: 0.3396736411911367 and parameters: {'num_leaves': 145}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  35%|###5      | 7/20 [27:04<47:30, 219.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[716]\tvalid_0's binary_logloss: 0.329753\tvalid_1's binary_logloss: 0.339674\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.735260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.353022\tvalid_1's binary_logloss: 0.347115\n",
      "[200]\tvalid_0's binary_logloss: 0.3501\tvalid_1's binary_logloss: 0.34468\n",
      "[300]\tvalid_0's binary_logloss: 0.348728\tvalid_1's binary_logloss: 0.343734\n",
      "[400]\tvalid_0's binary_logloss: 0.347806\tvalid_1's binary_logloss: 0.343209\n",
      "[500]\tvalid_0's binary_logloss: 0.347035\tvalid_1's binary_logloss: 0.342773\n",
      "[600]\tvalid_0's binary_logloss: 0.346391\tvalid_1's binary_logloss: 0.342376\n",
      "[700]\tvalid_0's binary_logloss: 0.345815\tvalid_1's binary_logloss: 0.34208\n",
      "[800]\tvalid_0's binary_logloss: 0.345233\tvalid_1's binary_logloss: 0.341766\n",
      "[900]\tvalid_0's binary_logloss: 0.344744\tvalid_1's binary_logloss: 0.341548\n",
      "[1000]\tvalid_0's binary_logloss: 0.344282\tvalid_1's binary_logloss: 0.341344\n",
      "[1100]\tvalid_0's binary_logloss: 0.343814\tvalid_1's binary_logloss: 0.341164\n",
      "[1200]\tvalid_0's binary_logloss: 0.343403\tvalid_1's binary_logloss: 0.341026\n",
      "[1300]\tvalid_0's binary_logloss: 0.342992\tvalid_1's binary_logloss: 0.340908\n",
      "[1400]\tvalid_0's binary_logloss: 0.342588\tvalid_1's binary_logloss: 0.34079\n",
      "[1500]\tvalid_0's binary_logloss: 0.34222\tvalid_1's binary_logloss: 0.340744\n",
      "[1600]\tvalid_0's binary_logloss: 0.341832\tvalid_1's binary_logloss: 0.340636\n",
      "[1700]\tvalid_0's binary_logloss: 0.341489\tvalid_1's binary_logloss: 0.340586\n",
      "[1800]\tvalid_0's binary_logloss: 0.341146\tvalid_1's binary_logloss: 0.340512\n",
      "[1900]\tvalid_0's binary_logloss: 0.340775\tvalid_1's binary_logloss: 0.340426\n",
      "[2000]\tvalid_0's binary_logloss: 0.34044\tvalid_1's binary_logloss: 0.340328\n",
      "[2100]\tvalid_0's binary_logloss: 0.340104\tvalid_1's binary_logloss: 0.340267\n",
      "[2200]\tvalid_0's binary_logloss: 0.339776\tvalid_1's binary_logloss: 0.340204\n",
      "[2300]\tvalid_0's binary_logloss: 0.339443\tvalid_1's binary_logloss: 0.340147\n",
      "[2400]\tvalid_0's binary_logloss: 0.33912\tvalid_1's binary_logloss: 0.340104\n",
      "[2500]\tvalid_0's binary_logloss: 0.338808\tvalid_1's binary_logloss: 0.340063\n",
      "[2600]\tvalid_0's binary_logloss: 0.338505\tvalid_1's binary_logloss: 0.340041\n",
      "[2700]\tvalid_0's binary_logloss: 0.338193\tvalid_1's binary_logloss: 0.340007\n",
      "[2800]\tvalid_0's binary_logloss: 0.337908\tvalid_1's binary_logloss: 0.339979\n",
      "[2900]\tvalid_0's binary_logloss: 0.337628\tvalid_1's binary_logloss: 0.339958\n",
      "[3000]\tvalid_0's binary_logloss: 0.337369\tvalid_1's binary_logloss: 0.339946\n",
      "[3100]\tvalid_0's binary_logloss: 0.337084\tvalid_1's binary_logloss: 0.339912\n",
      "[3200]\tvalid_0's binary_logloss: 0.336816\tvalid_1's binary_logloss: 0.339898\n",
      "[3300]\tvalid_0's binary_logloss: 0.33652\tvalid_1's binary_logloss: 0.339848\n",
      "[3400]\tvalid_0's binary_logloss: 0.33626\tvalid_1's binary_logloss: 0.339851\n",
      "[3500]\tvalid_0's binary_logloss: 0.335987\tvalid_1's binary_logloss: 0.339803\n",
      "[3600]\tvalid_0's binary_logloss: 0.335749\tvalid_1's binary_logloss: 0.339807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  40%|####      | 8/20 [35:30<1:02:06, 310.54s/it]\u001b[32m[I 2022-12-19 12:13:45,158]\u001b[0m Trial 14 finished with value: 0.33979786351978764 and parameters: {'num_leaves': 19}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  40%|####      | 8/20 [35:30<1:02:06, 310.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3526]\tvalid_0's binary_logloss: 0.335929\tvalid_1's binary_logloss: 0.339798\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.489910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.345534\tvalid_1's binary_logloss: 0.342068\n",
      "[200]\tvalid_0's binary_logloss: 0.341907\tvalid_1's binary_logloss: 0.340701\n",
      "[300]\tvalid_0's binary_logloss: 0.339472\tvalid_1's binary_logloss: 0.340446\n",
      "[400]\tvalid_0's binary_logloss: 0.337256\tvalid_1's binary_logloss: 0.340264\n",
      "[500]\tvalid_0's binary_logloss: 0.335008\tvalid_1's binary_logloss: 0.340091\n",
      "[600]\tvalid_0's binary_logloss: 0.332978\tvalid_1's binary_logloss: 0.339999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  45%|####5     | 9/20 [38:26<49:12, 268.38s/it]  \u001b[32m[I 2022-12-19 12:16:40,839]\u001b[0m Trial 15 finished with value: 0.33993819901363725 and parameters: {'num_leaves': 137}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  45%|####5     | 9/20 [38:26<49:12, 268.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[564]\tvalid_0's binary_logloss: 0.333658\tvalid_1's binary_logloss: 0.339938\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.410507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.344952\tvalid_1's binary_logloss: 0.341832\n",
      "[200]\tvalid_0's binary_logloss: 0.341158\tvalid_1's binary_logloss: 0.340704\n",
      "[300]\tvalid_0's binary_logloss: 0.338273\tvalid_1's binary_logloss: 0.340248\n",
      "[400]\tvalid_0's binary_logloss: 0.335751\tvalid_1's binary_logloss: 0.340085\n",
      "[500]\tvalid_0's binary_logloss: 0.333472\tvalid_1's binary_logloss: 0.339993\n",
      "[600]\tvalid_0's binary_logloss: 0.330991\tvalid_1's binary_logloss: 0.339874\n",
      "[700]\tvalid_0's binary_logloss: 0.328657\tvalid_1's binary_logloss: 0.339664\n",
      "[800]\tvalid_0's binary_logloss: 0.326533\tvalid_1's binary_logloss: 0.339663\n",
      "[900]\tvalid_0's binary_logloss: 0.32443\tvalid_1's binary_logloss: 0.339668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339592:  50%|#####     | 10/20 [42:34<43:42, 262.21s/it]\u001b[32m[I 2022-12-19 12:20:49,246]\u001b[0m Trial 16 finished with value: 0.33963866636573653 and parameters: {'num_leaves': 158}. Best is trial 7 with value: 0.339622330774809.\u001b[0m\n",
      "num_leaves, val_score: 0.339592:  50%|#####     | 10/20 [42:34<43:42, 262.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[874]\tvalid_0's binary_logloss: 0.324935\tvalid_1's binary_logloss: 0.339639\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.392719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.348047\tvalid_1's binary_logloss: 0.343453\n",
      "[200]\tvalid_0's binary_logloss: 0.345272\tvalid_1's binary_logloss: 0.341915\n",
      "[300]\tvalid_0's binary_logloss: 0.343492\tvalid_1's binary_logloss: 0.341291\n",
      "[400]\tvalid_0's binary_logloss: 0.341942\tvalid_1's binary_logloss: 0.340755\n",
      "[500]\tvalid_0's binary_logloss: 0.340565\tvalid_1's binary_logloss: 0.340414\n",
      "[600]\tvalid_0's binary_logloss: 0.339243\tvalid_1's binary_logloss: 0.340257\n",
      "[700]\tvalid_0's binary_logloss: 0.337983\tvalid_1's binary_logloss: 0.340084\n",
      "[800]\tvalid_0's binary_logloss: 0.336749\tvalid_1's binary_logloss: 0.33998\n",
      "[900]\tvalid_0's binary_logloss: 0.335646\tvalid_1's binary_logloss: 0.339921\n",
      "[1000]\tvalid_0's binary_logloss: 0.334567\tvalid_1's binary_logloss: 0.339803\n",
      "[1100]\tvalid_0's binary_logloss: 0.333449\tvalid_1's binary_logloss: 0.339744\n",
      "[1200]\tvalid_0's binary_logloss: 0.332362\tvalid_1's binary_logloss: 0.33971\n",
      "[1300]\tvalid_0's binary_logloss: 0.331311\tvalid_1's binary_logloss: 0.339677\n",
      "[1400]\tvalid_0's binary_logloss: 0.330276\tvalid_1's binary_logloss: 0.339607\n",
      "[1500]\tvalid_0's binary_logloss: 0.329364\tvalid_1's binary_logloss: 0.339603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339583:  55%|#####5    | 11/20 [47:16<40:15, 268.40s/it]\u001b[32m[I 2022-12-19 12:25:31,664]\u001b[0m Trial 17 finished with value: 0.3395834375034991 and parameters: {'num_leaves': 70}. Best is trial 17 with value: 0.3395834375034991.\u001b[0m\n",
      "num_leaves, val_score: 0.339583:  55%|#####5    | 11/20 [47:16<40:15, 268.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1425]\tvalid_0's binary_logloss: 0.330018\tvalid_1's binary_logloss: 0.339583\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.652219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.348509\tvalid_1's binary_logloss: 0.343787\n",
      "[200]\tvalid_0's binary_logloss: 0.345779\tvalid_1's binary_logloss: 0.342128\n",
      "[300]\tvalid_0's binary_logloss: 0.344142\tvalid_1's binary_logloss: 0.341529\n",
      "[400]\tvalid_0's binary_logloss: 0.342681\tvalid_1's binary_logloss: 0.341076\n",
      "[500]\tvalid_0's binary_logloss: 0.34141\tvalid_1's binary_logloss: 0.340764\n",
      "[600]\tvalid_0's binary_logloss: 0.340191\tvalid_1's binary_logloss: 0.340518\n",
      "[700]\tvalid_0's binary_logloss: 0.339076\tvalid_1's binary_logloss: 0.340328\n",
      "[800]\tvalid_0's binary_logloss: 0.337973\tvalid_1's binary_logloss: 0.340192\n",
      "[900]\tvalid_0's binary_logloss: 0.336958\tvalid_1's binary_logloss: 0.340147\n",
      "[1000]\tvalid_0's binary_logloss: 0.335955\tvalid_1's binary_logloss: 0.340036\n",
      "[1100]\tvalid_0's binary_logloss: 0.334976\tvalid_1's binary_logloss: 0.33998\n",
      "[1200]\tvalid_0's binary_logloss: 0.334058\tvalid_1's binary_logloss: 0.339929\n",
      "[1300]\tvalid_0's binary_logloss: 0.333119\tvalid_1's binary_logloss: 0.339893\n",
      "[1400]\tvalid_0's binary_logloss: 0.332199\tvalid_1's binary_logloss: 0.339837\n",
      "[1500]\tvalid_0's binary_logloss: 0.331354\tvalid_1's binary_logloss: 0.339779\n",
      "[1600]\tvalid_0's binary_logloss: 0.330529\tvalid_1's binary_logloss: 0.339773\n",
      "[1700]\tvalid_0's binary_logloss: 0.329689\tvalid_1's binary_logloss: 0.339735\n",
      "[1800]\tvalid_0's binary_logloss: 0.328883\tvalid_1's binary_logloss: 0.339731\n",
      "[1900]\tvalid_0's binary_logloss: 0.328066\tvalid_1's binary_logloss: 0.339717\n",
      "[2000]\tvalid_0's binary_logloss: 0.327241\tvalid_1's binary_logloss: 0.339719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339583:  60%|######    | 12/20 [53:17<39:31, 296.39s/it]\u001b[32m[I 2022-12-19 12:31:32,094]\u001b[0m Trial 18 finished with value: 0.33970383218441885 and parameters: {'num_leaves': 61}. Best is trial 17 with value: 0.3395834375034991.\u001b[0m\n",
      "num_leaves, val_score: 0.339583:  60%|######    | 12/20 [53:17<39:31, 296.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1926]\tvalid_0's binary_logloss: 0.32784\tvalid_1's binary_logloss: 0.339704\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.770241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.3476\tvalid_1's binary_logloss: 0.34315\n",
      "[200]\tvalid_0's binary_logloss: 0.344786\tvalid_1's binary_logloss: 0.34176\n",
      "[300]\tvalid_0's binary_logloss: 0.342893\tvalid_1's binary_logloss: 0.341164\n",
      "[400]\tvalid_0's binary_logloss: 0.341292\tvalid_1's binary_logloss: 0.340796\n",
      "[500]\tvalid_0's binary_logloss: 0.339718\tvalid_1's binary_logloss: 0.340418\n",
      "[600]\tvalid_0's binary_logloss: 0.338378\tvalid_1's binary_logloss: 0.340241\n",
      "[700]\tvalid_0's binary_logloss: 0.337133\tvalid_1's binary_logloss: 0.340118\n",
      "[800]\tvalid_0's binary_logloss: 0.335818\tvalid_1's binary_logloss: 0.340007\n",
      "[900]\tvalid_0's binary_logloss: 0.334561\tvalid_1's binary_logloss: 0.33986\n",
      "[1000]\tvalid_0's binary_logloss: 0.333209\tvalid_1's binary_logloss: 0.339694\n",
      "[1100]\tvalid_0's binary_logloss: 0.331991\tvalid_1's binary_logloss: 0.339597\n",
      "[1200]\tvalid_0's binary_logloss: 0.330828\tvalid_1's binary_logloss: 0.339537\n",
      "[1300]\tvalid_0's binary_logloss: 0.329795\tvalid_1's binary_logloss: 0.339512\n",
      "[1400]\tvalid_0's binary_logloss: 0.328729\tvalid_1's binary_logloss: 0.339513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  65%|######5   | 13/20 [58:04<34:14, 293.52s/it]\u001b[32m[I 2022-12-19 12:36:18,994]\u001b[0m Trial 19 finished with value: 0.3394997707735428 and parameters: {'num_leaves': 79}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  65%|######5   | 13/20 [58:04<34:14, 293.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1327]\tvalid_0's binary_logloss: 0.329476\tvalid_1's binary_logloss: 0.3395\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.367825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.34725\tvalid_1's binary_logloss: 0.342983\n",
      "[200]\tvalid_0's binary_logloss: 0.344289\tvalid_1's binary_logloss: 0.341514\n",
      "[300]\tvalid_0's binary_logloss: 0.342419\tvalid_1's binary_logloss: 0.341064\n",
      "[400]\tvalid_0's binary_logloss: 0.340619\tvalid_1's binary_logloss: 0.340502\n",
      "[500]\tvalid_0's binary_logloss: 0.339047\tvalid_1's binary_logloss: 0.340214\n",
      "[600]\tvalid_0's binary_logloss: 0.337572\tvalid_1's binary_logloss: 0.340116\n",
      "[700]\tvalid_0's binary_logloss: 0.336086\tvalid_1's binary_logloss: 0.33998\n",
      "[800]\tvalid_0's binary_logloss: 0.334737\tvalid_1's binary_logloss: 0.339884\n",
      "[900]\tvalid_0's binary_logloss: 0.333388\tvalid_1's binary_logloss: 0.339844\n",
      "[1000]\tvalid_0's binary_logloss: 0.332139\tvalid_1's binary_logloss: 0.339797\n",
      "[1100]\tvalid_0's binary_logloss: 0.330864\tvalid_1's binary_logloss: 0.339731\n",
      "[1200]\tvalid_0's binary_logloss: 0.329642\tvalid_1's binary_logloss: 0.33971\n",
      "[1300]\tvalid_0's binary_logloss: 0.328468\tvalid_1's binary_logloss: 0.339674\n",
      "[1400]\tvalid_0's binary_logloss: 0.327295\tvalid_1's binary_logloss: 0.339665\n",
      "[1500]\tvalid_0's binary_logloss: 0.326148\tvalid_1's binary_logloss: 0.339645\n",
      "[1600]\tvalid_0's binary_logloss: 0.325005\tvalid_1's binary_logloss: 0.339585\n",
      "[1700]\tvalid_0's binary_logloss: 0.323972\tvalid_1's binary_logloss: 0.339603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  70%|#######   | 14/20 [1:03:37<30:33, 305.56s/it]\u001b[32m[I 2022-12-19 12:41:52,366]\u001b[0m Trial 20 finished with value: 0.3395807035713621 and parameters: {'num_leaves': 86}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  70%|#######   | 14/20 [1:03:37<30:33, 305.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1630]\tvalid_0's binary_logloss: 0.324675\tvalid_1's binary_logloss: 0.339581\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.380414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.346976\tvalid_1's binary_logloss: 0.342795\n",
      "[200]\tvalid_0's binary_logloss: 0.343865\tvalid_1's binary_logloss: 0.341272\n",
      "[300]\tvalid_0's binary_logloss: 0.341903\tvalid_1's binary_logloss: 0.340803\n",
      "[400]\tvalid_0's binary_logloss: 0.340158\tvalid_1's binary_logloss: 0.340634\n",
      "[500]\tvalid_0's binary_logloss: 0.338556\tvalid_1's binary_logloss: 0.34042\n",
      "[600]\tvalid_0's binary_logloss: 0.336948\tvalid_1's binary_logloss: 0.340209\n",
      "[700]\tvalid_0's binary_logloss: 0.335375\tvalid_1's binary_logloss: 0.340076\n",
      "[800]\tvalid_0's binary_logloss: 0.333975\tvalid_1's binary_logloss: 0.340016\n",
      "[900]\tvalid_0's binary_logloss: 0.332489\tvalid_1's binary_logloss: 0.339966\n",
      "[1000]\tvalid_0's binary_logloss: 0.331162\tvalid_1's binary_logloss: 0.339855\n",
      "[1100]\tvalid_0's binary_logloss: 0.329842\tvalid_1's binary_logloss: 0.339791\n",
      "[1200]\tvalid_0's binary_logloss: 0.32854\tvalid_1's binary_logloss: 0.339741\n",
      "[1300]\tvalid_0's binary_logloss: 0.32732\tvalid_1's binary_logloss: 0.339687\n",
      "[1400]\tvalid_0's binary_logloss: 0.326045\tvalid_1's binary_logloss: 0.339621\n",
      "[1500]\tvalid_0's binary_logloss: 0.324814\tvalid_1's binary_logloss: 0.33962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  75%|#######5  | 15/20 [1:08:45<25:31, 306.23s/it]\u001b[32m[I 2022-12-19 12:47:00,173]\u001b[0m Trial 21 finished with value: 0.3396180847331631 and parameters: {'num_leaves': 94}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  75%|#######5  | 15/20 [1:08:45<25:31, 306.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1423]\tvalid_0's binary_logloss: 0.325767\tvalid_1's binary_logloss: 0.339618\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.425458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.346608\tvalid_1's binary_logloss: 0.342561\n",
      "[200]\tvalid_0's binary_logloss: 0.343561\tvalid_1's binary_logloss: 0.341256\n",
      "[300]\tvalid_0's binary_logloss: 0.341418\tvalid_1's binary_logloss: 0.34081\n",
      "[400]\tvalid_0's binary_logloss: 0.339439\tvalid_1's binary_logloss: 0.34048\n",
      "[500]\tvalid_0's binary_logloss: 0.337614\tvalid_1's binary_logloss: 0.340173\n",
      "[600]\tvalid_0's binary_logloss: 0.335924\tvalid_1's binary_logloss: 0.340059\n",
      "[700]\tvalid_0's binary_logloss: 0.334347\tvalid_1's binary_logloss: 0.339929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  80%|########  | 16/20 [1:11:47<17:55, 268.80s/it]\u001b[32m[I 2022-12-19 12:50:02,051]\u001b[0m Trial 22 finished with value: 0.3399282360315033 and parameters: {'num_leaves': 103}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  80%|########  | 16/20 [1:11:47<17:55, 268.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[698]\tvalid_0's binary_logloss: 0.334379\tvalid_1's binary_logloss: 0.339928\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.349018\tvalid_1's binary_logloss: 0.344185\n",
      "[200]\tvalid_0's binary_logloss: 0.346414\tvalid_1's binary_logloss: 0.34253\n",
      "[300]\tvalid_0's binary_logloss: 0.34491\tvalid_1's binary_logloss: 0.341892\n",
      "[400]\tvalid_0's binary_logloss: 0.343608\tvalid_1's binary_logloss: 0.341422\n",
      "[500]\tvalid_0's binary_logloss: 0.342347\tvalid_1's binary_logloss: 0.340982\n",
      "[600]\tvalid_0's binary_logloss: 0.341205\tvalid_1's binary_logloss: 0.340669\n",
      "[700]\tvalid_0's binary_logloss: 0.34027\tvalid_1's binary_logloss: 0.340538\n",
      "[800]\tvalid_0's binary_logloss: 0.33928\tvalid_1's binary_logloss: 0.340399\n",
      "[900]\tvalid_0's binary_logloss: 0.338367\tvalid_1's binary_logloss: 0.340271\n",
      "[1000]\tvalid_0's binary_logloss: 0.337385\tvalid_1's binary_logloss: 0.340148\n",
      "[1100]\tvalid_0's binary_logloss: 0.336493\tvalid_1's binary_logloss: 0.340048\n",
      "[1200]\tvalid_0's binary_logloss: 0.335617\tvalid_1's binary_logloss: 0.339998\n",
      "[1300]\tvalid_0's binary_logloss: 0.334788\tvalid_1's binary_logloss: 0.339928\n",
      "[1400]\tvalid_0's binary_logloss: 0.333985\tvalid_1's binary_logloss: 0.339864\n",
      "[1500]\tvalid_0's binary_logloss: 0.333193\tvalid_1's binary_logloss: 0.339812\n",
      "[1600]\tvalid_0's binary_logloss: 0.332377\tvalid_1's binary_logloss: 0.339748\n",
      "[1700]\tvalid_0's binary_logloss: 0.33159\tvalid_1's binary_logloss: 0.339717\n",
      "[1800]\tvalid_0's binary_logloss: 0.330839\tvalid_1's binary_logloss: 0.33969\n",
      "[1900]\tvalid_0's binary_logloss: 0.330054\tvalid_1's binary_logloss: 0.339663\n",
      "[2000]\tvalid_0's binary_logloss: 0.329363\tvalid_1's binary_logloss: 0.339667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  85%|########5 | 17/20 [1:17:27<14:30, 290.19s/it]\u001b[32m[I 2022-12-19 12:55:41,980]\u001b[0m Trial 23 finished with value: 0.33964199709267223 and parameters: {'num_leaves': 53}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  85%|########5 | 17/20 [1:17:27<14:30, 290.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1928]\tvalid_0's binary_logloss: 0.329847\tvalid_1's binary_logloss: 0.339642\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.381764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.346524\tvalid_1's binary_logloss: 0.342551\n",
      "[200]\tvalid_0's binary_logloss: 0.343399\tvalid_1's binary_logloss: 0.341113\n",
      "[300]\tvalid_0's binary_logloss: 0.341217\tvalid_1's binary_logloss: 0.340617\n",
      "[400]\tvalid_0's binary_logloss: 0.339176\tvalid_1's binary_logloss: 0.340119\n",
      "[500]\tvalid_0's binary_logloss: 0.337351\tvalid_1's binary_logloss: 0.339925\n",
      "[600]\tvalid_0's binary_logloss: 0.33572\tvalid_1's binary_logloss: 0.339814\n",
      "[700]\tvalid_0's binary_logloss: 0.334192\tvalid_1's binary_logloss: 0.33977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  90%|######### | 18/20 [1:20:27<08:34, 257.02s/it]\u001b[32m[I 2022-12-19 12:58:41,786]\u001b[0m Trial 24 finished with value: 0.3397453151437164 and parameters: {'num_leaves': 104}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  90%|######### | 18/20 [1:20:27<08:34, 257.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[682]\tvalid_0's binary_logloss: 0.334422\tvalid_1's binary_logloss: 0.339745\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.394700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.350046\tvalid_1's binary_logloss: 0.344947\n",
      "[200]\tvalid_0's binary_logloss: 0.347507\tvalid_1's binary_logloss: 0.343163\n",
      "[300]\tvalid_0's binary_logloss: 0.346027\tvalid_1's binary_logloss: 0.342422\n",
      "[400]\tvalid_0's binary_logloss: 0.344877\tvalid_1's binary_logloss: 0.341831\n",
      "[500]\tvalid_0's binary_logloss: 0.343945\tvalid_1's binary_logloss: 0.341558\n",
      "[600]\tvalid_0's binary_logloss: 0.34297\tvalid_1's binary_logloss: 0.3412\n",
      "[700]\tvalid_0's binary_logloss: 0.342082\tvalid_1's binary_logloss: 0.340933\n",
      "[800]\tvalid_0's binary_logloss: 0.341238\tvalid_1's binary_logloss: 0.340656\n",
      "[900]\tvalid_0's binary_logloss: 0.340443\tvalid_1's binary_logloss: 0.340482\n",
      "[1000]\tvalid_0's binary_logloss: 0.339702\tvalid_1's binary_logloss: 0.340414\n",
      "[1100]\tvalid_0's binary_logloss: 0.338949\tvalid_1's binary_logloss: 0.340236\n",
      "[1200]\tvalid_0's binary_logloss: 0.338286\tvalid_1's binary_logloss: 0.340168\n",
      "[1300]\tvalid_0's binary_logloss: 0.337637\tvalid_1's binary_logloss: 0.340126\n",
      "[1400]\tvalid_0's binary_logloss: 0.336937\tvalid_1's binary_logloss: 0.340042\n",
      "[1500]\tvalid_0's binary_logloss: 0.33634\tvalid_1's binary_logloss: 0.340026\n",
      "[1600]\tvalid_0's binary_logloss: 0.335711\tvalid_1's binary_logloss: 0.339954\n",
      "[1700]\tvalid_0's binary_logloss: 0.33507\tvalid_1's binary_logloss: 0.339858\n",
      "[1800]\tvalid_0's binary_logloss: 0.334498\tvalid_1's binary_logloss: 0.339817\n",
      "[1900]\tvalid_0's binary_logloss: 0.33389\tvalid_1's binary_logloss: 0.339743\n",
      "[2000]\tvalid_0's binary_logloss: 0.333323\tvalid_1's binary_logloss: 0.339739\n",
      "[2100]\tvalid_0's binary_logloss: 0.332751\tvalid_1's binary_logloss: 0.339708\n",
      "[2200]\tvalid_0's binary_logloss: 0.332204\tvalid_1's binary_logloss: 0.339706\n",
      "[2300]\tvalid_0's binary_logloss: 0.331639\tvalid_1's binary_logloss: 0.339715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500:  95%|#########5| 19/20 [1:26:38<04:51, 291.30s/it]\u001b[32m[I 2022-12-19 13:04:52,925]\u001b[0m Trial 25 finished with value: 0.33970138822157026 and parameters: {'num_leaves': 40}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500:  95%|#########5| 19/20 [1:26:38<04:51, 291.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2272]\tvalid_0's binary_logloss: 0.331792\tvalid_1's binary_logloss: 0.339701\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.726257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347536\tvalid_1's binary_logloss: 0.343165\n",
      "[200]\tvalid_0's binary_logloss: 0.34477\tvalid_1's binary_logloss: 0.341831\n",
      "[300]\tvalid_0's binary_logloss: 0.342844\tvalid_1's binary_logloss: 0.341154\n",
      "[400]\tvalid_0's binary_logloss: 0.341141\tvalid_1's binary_logloss: 0.340657\n",
      "[500]\tvalid_0's binary_logloss: 0.339636\tvalid_1's binary_logloss: 0.340384\n",
      "[600]\tvalid_0's binary_logloss: 0.338221\tvalid_1's binary_logloss: 0.340264\n",
      "[700]\tvalid_0's binary_logloss: 0.336855\tvalid_1's binary_logloss: 0.340102\n",
      "[800]\tvalid_0's binary_logloss: 0.335575\tvalid_1's binary_logloss: 0.339995\n",
      "[900]\tvalid_0's binary_logloss: 0.334327\tvalid_1's binary_logloss: 0.339854\n",
      "[1000]\tvalid_0's binary_logloss: 0.333147\tvalid_1's binary_logloss: 0.339831\n",
      "[1100]\tvalid_0's binary_logloss: 0.331961\tvalid_1's binary_logloss: 0.339765\n",
      "[1200]\tvalid_0's binary_logloss: 0.330819\tvalid_1's binary_logloss: 0.33972\n",
      "[1300]\tvalid_0's binary_logloss: 0.329653\tvalid_1's binary_logloss: 0.339687\n",
      "[1400]\tvalid_0's binary_logloss: 0.328419\tvalid_1's binary_logloss: 0.339601\n",
      "[1500]\tvalid_0's binary_logloss: 0.327363\tvalid_1's binary_logloss: 0.339603\n",
      "[1600]\tvalid_0's binary_logloss: 0.326265\tvalid_1's binary_logloss: 0.339543\n",
      "[1700]\tvalid_0's binary_logloss: 0.325261\tvalid_1's binary_logloss: 0.339561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.339500: 100%|##########| 20/20 [1:32:11<00:00, 303.85s/it]\u001b[32m[I 2022-12-19 13:10:26,040]\u001b[0m Trial 26 finished with value: 0.3395420463353433 and parameters: {'num_leaves': 80}. Best is trial 19 with value: 0.3394997707735428.\u001b[0m\n",
      "num_leaves, val_score: 0.339500: 100%|##########| 20/20 [1:32:11<00:00, 276.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1607]\tvalid_0's binary_logloss: 0.326192\tvalid_1's binary_logloss: 0.339542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.438285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347559\tvalid_1's binary_logloss: 0.343166\n",
      "[200]\tvalid_0's binary_logloss: 0.344737\tvalid_1's binary_logloss: 0.341819\n",
      "[300]\tvalid_0's binary_logloss: 0.342814\tvalid_1's binary_logloss: 0.341187\n",
      "[400]\tvalid_0's binary_logloss: 0.341182\tvalid_1's binary_logloss: 0.340841\n",
      "[500]\tvalid_0's binary_logloss: 0.339725\tvalid_1's binary_logloss: 0.340639\n",
      "[600]\tvalid_0's binary_logloss: 0.338326\tvalid_1's binary_logloss: 0.340548\n",
      "[700]\tvalid_0's binary_logloss: 0.336944\tvalid_1's binary_logloss: 0.340391\n",
      "[800]\tvalid_0's binary_logloss: 0.335669\tvalid_1's binary_logloss: 0.340378\n",
      "[900]\tvalid_0's binary_logloss: 0.334414\tvalid_1's binary_logloss: 0.340303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  10%|#         | 1/10 [03:16<29:28, 196.47s/it]\u001b[32m[I 2022-12-19 13:13:42,517]\u001b[0m Trial 27 finished with value: 0.34011174301695185 and parameters: {'bagging_fraction': 0.7410216783180754, 'bagging_freq': 4}. Best is trial 27 with value: 0.34011174301695185.\u001b[0m\n",
      "bagging, val_score: 0.339500:  10%|#         | 1/10 [03:16<29:28, 196.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[832]\tvalid_0's binary_logloss: 0.335257\tvalid_1's binary_logloss: 0.340112\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.658937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347659\tvalid_1's binary_logloss: 0.343373\n",
      "[200]\tvalid_0's binary_logloss: 0.34478\tvalid_1's binary_logloss: 0.341821\n",
      "[300]\tvalid_0's binary_logloss: 0.342996\tvalid_1's binary_logloss: 0.341145\n",
      "[400]\tvalid_0's binary_logloss: 0.34131\tvalid_1's binary_logloss: 0.341167\n",
      "[500]\tvalid_0's binary_logloss: 0.339785\tvalid_1's binary_logloss: 0.340528\n",
      "[600]\tvalid_0's binary_logloss: 0.338393\tvalid_1's binary_logloss: 0.340597\n",
      "[700]\tvalid_0's binary_logloss: 0.33704\tvalid_1's binary_logloss: 0.34041\n",
      "[800]\tvalid_0's binary_logloss: 0.335779\tvalid_1's binary_logloss: 0.340303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  20%|##        | 2/10 [06:01<23:45, 178.19s/it]\u001b[32m[I 2022-12-19 13:16:27,907]\u001b[0m Trial 28 finished with value: 0.34002800591693116 and parameters: {'bagging_fraction': 0.6095235375707089, 'bagging_freq': 7}. Best is trial 28 with value: 0.34002800591693116.\u001b[0m\n",
      "bagging, val_score: 0.339500:  20%|##        | 2/10 [06:01<23:45, 178.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[784]\tvalid_0's binary_logloss: 0.335968\tvalid_1's binary_logloss: 0.340028\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.438624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347589\tvalid_1's binary_logloss: 0.343242\n",
      "[200]\tvalid_0's binary_logloss: 0.344695\tvalid_1's binary_logloss: 0.341702\n",
      "[300]\tvalid_0's binary_logloss: 0.342817\tvalid_1's binary_logloss: 0.341092\n",
      "[400]\tvalid_0's binary_logloss: 0.341064\tvalid_1's binary_logloss: 0.340735\n",
      "[500]\tvalid_0's binary_logloss: 0.339638\tvalid_1's binary_logloss: 0.340532\n",
      "[600]\tvalid_0's binary_logloss: 0.338209\tvalid_1's binary_logloss: 0.340269\n",
      "[700]\tvalid_0's binary_logloss: 0.336946\tvalid_1's binary_logloss: 0.340262\n",
      "[800]\tvalid_0's binary_logloss: 0.335645\tvalid_1's binary_logloss: 0.340059\n",
      "[900]\tvalid_0's binary_logloss: 0.334392\tvalid_1's binary_logloss: 0.34008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  30%|###       | 3/10 [09:29<22:19, 191.42s/it]\u001b[32m[I 2022-12-19 13:19:55,081]\u001b[0m Trial 29 finished with value: 0.3400067700341273 and parameters: {'bagging_fraction': 0.8512024874191433, 'bagging_freq': 6}. Best is trial 29 with value: 0.3400067700341273.\u001b[0m\n",
      "bagging, val_score: 0.339500:  30%|###       | 3/10 [09:29<22:19, 191.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[840]\tvalid_0's binary_logloss: 0.335121\tvalid_1's binary_logloss: 0.340007\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.665080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347596\tvalid_1's binary_logloss: 0.343138\n",
      "[200]\tvalid_0's binary_logloss: 0.34468\tvalid_1's binary_logloss: 0.341705\n",
      "[300]\tvalid_0's binary_logloss: 0.342778\tvalid_1's binary_logloss: 0.341109\n",
      "[400]\tvalid_0's binary_logloss: 0.341131\tvalid_1's binary_logloss: 0.340765\n",
      "[500]\tvalid_0's binary_logloss: 0.339632\tvalid_1's binary_logloss: 0.340505\n",
      "[600]\tvalid_0's binary_logloss: 0.3382\tvalid_1's binary_logloss: 0.340359\n",
      "[700]\tvalid_0's binary_logloss: 0.336813\tvalid_1's binary_logloss: 0.340219\n",
      "[800]\tvalid_0's binary_logloss: 0.335525\tvalid_1's binary_logloss: 0.340101\n",
      "[900]\tvalid_0's binary_logloss: 0.334282\tvalid_1's binary_logloss: 0.34003\n",
      "[1000]\tvalid_0's binary_logloss: 0.333039\tvalid_1's binary_logloss: 0.339984\n",
      "[1100]\tvalid_0's binary_logloss: 0.331853\tvalid_1's binary_logloss: 0.33997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  40%|####      | 4/10 [13:38<21:25, 214.17s/it]\u001b[32m[I 2022-12-19 13:24:04,128]\u001b[0m Trial 30 finished with value: 0.33991393456317526 and parameters: {'bagging_fraction': 0.7336363367224781, 'bagging_freq': 1}. Best is trial 30 with value: 0.33991393456317526.\u001b[0m\n",
      "bagging, val_score: 0.339500:  40%|####      | 4/10 [13:38<21:25, 214.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1095]\tvalid_0's binary_logloss: 0.331912\tvalid_1's binary_logloss: 0.339914\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.413817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347535\tvalid_1's binary_logloss: 0.343145\n",
      "[200]\tvalid_0's binary_logloss: 0.344769\tvalid_1's binary_logloss: 0.341811\n",
      "[300]\tvalid_0's binary_logloss: 0.342713\tvalid_1's binary_logloss: 0.341013\n",
      "[400]\tvalid_0's binary_logloss: 0.341115\tvalid_1's binary_logloss: 0.340629\n",
      "[500]\tvalid_0's binary_logloss: 0.339586\tvalid_1's binary_logloss: 0.340539\n",
      "[600]\tvalid_0's binary_logloss: 0.338236\tvalid_1's binary_logloss: 0.340404\n",
      "[700]\tvalid_0's binary_logloss: 0.336907\tvalid_1's binary_logloss: 0.340241\n",
      "[800]\tvalid_0's binary_logloss: 0.335583\tvalid_1's binary_logloss: 0.340212\n",
      "[900]\tvalid_0's binary_logloss: 0.33433\tvalid_1's binary_logloss: 0.340024\n",
      "[1000]\tvalid_0's binary_logloss: 0.333067\tvalid_1's binary_logloss: 0.339846\n",
      "[1100]\tvalid_0's binary_logloss: 0.331884\tvalid_1's binary_logloss: 0.339784\n",
      "[1200]\tvalid_0's binary_logloss: 0.33073\tvalid_1's binary_logloss: 0.33968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  50%|#####     | 5/10 [18:18<19:51, 238.23s/it]\u001b[32m[I 2022-12-19 13:28:45,009]\u001b[0m Trial 31 finished with value: 0.33968004569321664 and parameters: {'bagging_fraction': 0.8717565402807532, 'bagging_freq': 4}. Best is trial 31 with value: 0.33968004569321664.\u001b[0m\n",
      "bagging, val_score: 0.339500:  50%|#####     | 5/10 [18:18<19:51, 238.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\tvalid_0's binary_logloss: 0.329579\tvalid_1's binary_logloss: 0.339719\n",
      "Early stopping, best iteration is:\n",
      "[1200]\tvalid_0's binary_logloss: 0.33073\tvalid_1's binary_logloss: 0.33968\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.439222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347577\tvalid_1's binary_logloss: 0.343147\n",
      "[200]\tvalid_0's binary_logloss: 0.344684\tvalid_1's binary_logloss: 0.341793\n",
      "[300]\tvalid_0's binary_logloss: 0.342688\tvalid_1's binary_logloss: 0.341017\n",
      "[400]\tvalid_0's binary_logloss: 0.341049\tvalid_1's binary_logloss: 0.340676\n",
      "[500]\tvalid_0's binary_logloss: 0.339539\tvalid_1's binary_logloss: 0.340441\n",
      "[600]\tvalid_0's binary_logloss: 0.338043\tvalid_1's binary_logloss: 0.34025\n",
      "[700]\tvalid_0's binary_logloss: 0.336784\tvalid_1's binary_logloss: 0.34017\n",
      "[800]\tvalid_0's binary_logloss: 0.335485\tvalid_1's binary_logloss: 0.34004\n",
      "[900]\tvalid_0's binary_logloss: 0.334219\tvalid_1's binary_logloss: 0.339934\n",
      "[1000]\tvalid_0's binary_logloss: 0.332951\tvalid_1's binary_logloss: 0.339857\n",
      "[1100]\tvalid_0's binary_logloss: 0.331695\tvalid_1's binary_logloss: 0.339711\n",
      "[1200]\tvalid_0's binary_logloss: 0.330515\tvalid_1's binary_logloss: 0.339698\n",
      "[1300]\tvalid_0's binary_logloss: 0.329392\tvalid_1's binary_logloss: 0.339655\n",
      "[1400]\tvalid_0's binary_logloss: 0.32826\tvalid_1's binary_logloss: 0.3396\n",
      "[1500]\tvalid_0's binary_logloss: 0.327171\tvalid_1's binary_logloss: 0.339637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  60%|######    | 6/10 [23:07<17:01, 255.47s/it]\u001b[32m[I 2022-12-19 13:33:33,957]\u001b[0m Trial 32 finished with value: 0.3395242043262087 and parameters: {'bagging_fraction': 0.8518736398234721, 'bagging_freq': 1}. Best is trial 32 with value: 0.3395242043262087.\u001b[0m\n",
      "bagging, val_score: 0.339500:  60%|######    | 6/10 [23:07<17:01, 255.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1424]\tvalid_0's binary_logloss: 0.328006\tvalid_1's binary_logloss: 0.339524\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.754643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347545\tvalid_1's binary_logloss: 0.343115\n",
      "[200]\tvalid_0's binary_logloss: 0.344754\tvalid_1's binary_logloss: 0.34179\n",
      "[300]\tvalid_0's binary_logloss: 0.342812\tvalid_1's binary_logloss: 0.341127\n",
      "[400]\tvalid_0's binary_logloss: 0.341161\tvalid_1's binary_logloss: 0.340687\n",
      "[500]\tvalid_0's binary_logloss: 0.339673\tvalid_1's binary_logloss: 0.340578\n",
      "[600]\tvalid_0's binary_logloss: 0.338324\tvalid_1's binary_logloss: 0.340482\n",
      "[700]\tvalid_0's binary_logloss: 0.336948\tvalid_1's binary_logloss: 0.340285\n",
      "[800]\tvalid_0's binary_logloss: 0.335646\tvalid_1's binary_logloss: 0.340338\n",
      "[900]\tvalid_0's binary_logloss: 0.334392\tvalid_1's binary_logloss: 0.340162\n",
      "[1000]\tvalid_0's binary_logloss: 0.333133\tvalid_1's binary_logloss: 0.340068\n",
      "[1100]\tvalid_0's binary_logloss: 0.331913\tvalid_1's binary_logloss: 0.339978\n",
      "[1200]\tvalid_0's binary_logloss: 0.330748\tvalid_1's binary_logloss: 0.339827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  70%|#######   | 7/10 [27:32<12:54, 258.31s/it]\u001b[32m[I 2022-12-19 13:37:58,119]\u001b[0m Trial 33 finished with value: 0.33982700613745503 and parameters: {'bagging_fraction': 0.8609833249094581, 'bagging_freq': 4}. Best is trial 32 with value: 0.3395242043262087.\u001b[0m\n",
      "bagging, val_score: 0.339500:  70%|#######   | 7/10 [27:32<12:54, 258.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\tvalid_0's binary_logloss: 0.329559\tvalid_1's binary_logloss: 0.339932\n",
      "Early stopping, best iteration is:\n",
      "[1200]\tvalid_0's binary_logloss: 0.330748\tvalid_1's binary_logloss: 0.339827\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.404514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347655\tvalid_1's binary_logloss: 0.343328\n",
      "[200]\tvalid_0's binary_logloss: 0.344741\tvalid_1's binary_logloss: 0.341745\n",
      "[300]\tvalid_0's binary_logloss: 0.342862\tvalid_1's binary_logloss: 0.341285\n",
      "[400]\tvalid_0's binary_logloss: 0.341268\tvalid_1's binary_logloss: 0.340804\n",
      "[500]\tvalid_0's binary_logloss: 0.339763\tvalid_1's binary_logloss: 0.3406\n",
      "[600]\tvalid_0's binary_logloss: 0.338329\tvalid_1's binary_logloss: 0.340417\n",
      "[700]\tvalid_0's binary_logloss: 0.336954\tvalid_1's binary_logloss: 0.340135\n",
      "[800]\tvalid_0's binary_logloss: 0.335631\tvalid_1's binary_logloss: 0.340141\n",
      "[900]\tvalid_0's binary_logloss: 0.334381\tvalid_1's binary_logloss: 0.340005\n",
      "[1000]\tvalid_0's binary_logloss: 0.33316\tvalid_1's binary_logloss: 0.340051\n",
      "[1100]\tvalid_0's binary_logloss: 0.331948\tvalid_1's binary_logloss: 0.339857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  80%|########  | 8/10 [31:25<08:20, 250.39s/it]\u001b[32m[I 2022-12-19 13:41:51,547]\u001b[0m Trial 34 finished with value: 0.3397606088782568 and parameters: {'bagging_fraction': 0.7728631593376849, 'bagging_freq': 5}. Best is trial 32 with value: 0.3395242043262087.\u001b[0m\n",
      "bagging, val_score: 0.339500:  80%|########  | 8/10 [31:25<08:20, 250.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1040]\tvalid_0's binary_logloss: 0.332657\tvalid_1's binary_logloss: 0.339761\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.441587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347565\tvalid_1's binary_logloss: 0.343327\n",
      "[200]\tvalid_0's binary_logloss: 0.344718\tvalid_1's binary_logloss: 0.341863\n",
      "[300]\tvalid_0's binary_logloss: 0.342769\tvalid_1's binary_logloss: 0.341106\n",
      "[400]\tvalid_0's binary_logloss: 0.341081\tvalid_1's binary_logloss: 0.340542\n",
      "[500]\tvalid_0's binary_logloss: 0.339635\tvalid_1's binary_logloss: 0.340424\n",
      "[600]\tvalid_0's binary_logloss: 0.338219\tvalid_1's binary_logloss: 0.340196\n",
      "[700]\tvalid_0's binary_logloss: 0.336836\tvalid_1's binary_logloss: 0.340104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339500:  90%|######### | 9/10 [34:10<03:43, 223.58s/it]\u001b[32m[I 2022-12-19 13:44:36,182]\u001b[0m Trial 35 finished with value: 0.34002140271772624 and parameters: {'bagging_fraction': 0.8324791997490357, 'bagging_freq': 7}. Best is trial 32 with value: 0.3395242043262087.\u001b[0m\n",
      "bagging, val_score: 0.339500:  90%|######### | 9/10 [34:10<03:43, 223.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's binary_logloss: 0.338107\tvalid_1's binary_logloss: 0.340021\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.743349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347557\tvalid_1's binary_logloss: 0.343173\n",
      "[200]\tvalid_0's binary_logloss: 0.344775\tvalid_1's binary_logloss: 0.341696\n",
      "[300]\tvalid_0's binary_logloss: 0.342808\tvalid_1's binary_logloss: 0.3411\n",
      "[400]\tvalid_0's binary_logloss: 0.341075\tvalid_1's binary_logloss: 0.340643\n",
      "[500]\tvalid_0's binary_logloss: 0.339562\tvalid_1's binary_logloss: 0.340308\n",
      "[600]\tvalid_0's binary_logloss: 0.338167\tvalid_1's binary_logloss: 0.340103\n",
      "[700]\tvalid_0's binary_logloss: 0.336792\tvalid_1's binary_logloss: 0.339976\n",
      "[800]\tvalid_0's binary_logloss: 0.335492\tvalid_1's binary_logloss: 0.339796\n",
      "[900]\tvalid_0's binary_logloss: 0.334225\tvalid_1's binary_logloss: 0.339706\n",
      "[1000]\tvalid_0's binary_logloss: 0.332987\tvalid_1's binary_logloss: 0.339585\n",
      "[1100]\tvalid_0's binary_logloss: 0.331846\tvalid_1's binary_logloss: 0.33961\n",
      "[1200]\tvalid_0's binary_logloss: 0.330684\tvalid_1's binary_logloss: 0.339556\n",
      "[1300]\tvalid_0's binary_logloss: 0.329496\tvalid_1's binary_logloss: 0.339518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.339454: 100%|##########| 10/10 [39:14<00:00, 248.48s/it]\u001b[32m[I 2022-12-19 13:49:40,415]\u001b[0m Trial 36 finished with value: 0.33945354798525085 and parameters: {'bagging_fraction': 0.9295272232672004, 'bagging_freq': 2}. Best is trial 36 with value: 0.33945354798525085.\u001b[0m\n",
      "bagging, val_score: 0.339454: 100%|##########| 10/10 [39:14<00:00, 235.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1250]\tvalid_0's binary_logloss: 0.330083\tvalid_1's binary_logloss: 0.339454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339454:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.401422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347618\tvalid_1's binary_logloss: 0.343156\n",
      "[200]\tvalid_0's binary_logloss: 0.344712\tvalid_1's binary_logloss: 0.341502\n",
      "[300]\tvalid_0's binary_logloss: 0.342764\tvalid_1's binary_logloss: 0.340992\n",
      "[400]\tvalid_0's binary_logloss: 0.341199\tvalid_1's binary_logloss: 0.340656\n",
      "[500]\tvalid_0's binary_logloss: 0.33971\tvalid_1's binary_logloss: 0.340337\n",
      "[600]\tvalid_0's binary_logloss: 0.3383\tvalid_1's binary_logloss: 0.34011\n",
      "[700]\tvalid_0's binary_logloss: 0.336946\tvalid_1's binary_logloss: 0.339981\n",
      "[800]\tvalid_0's binary_logloss: 0.335683\tvalid_1's binary_logloss: 0.339835\n",
      "[900]\tvalid_0's binary_logloss: 0.334449\tvalid_1's binary_logloss: 0.339762\n",
      "[1000]\tvalid_0's binary_logloss: 0.333246\tvalid_1's binary_logloss: 0.33967\n",
      "[1100]\tvalid_0's binary_logloss: 0.332093\tvalid_1's binary_logloss: 0.339675\n",
      "[1200]\tvalid_0's binary_logloss: 0.330921\tvalid_1's binary_logloss: 0.33957\n",
      "[1300]\tvalid_0's binary_logloss: 0.32978\tvalid_1's binary_logloss: 0.339544\n",
      "[1400]\tvalid_0's binary_logloss: 0.328674\tvalid_1's binary_logloss: 0.33949\n",
      "[1500]\tvalid_0's binary_logloss: 0.327555\tvalid_1's binary_logloss: 0.339408\n",
      "[1600]\tvalid_0's binary_logloss: 0.326446\tvalid_1's binary_logloss: 0.339448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339378:  17%|#6        | 1/6 [06:06<30:34, 366.97s/it]\u001b[32m[I 2022-12-19 13:55:47,393]\u001b[0m Trial 37 finished with value: 0.33937780891633623 and parameters: {'feature_fraction': 0.552}. Best is trial 37 with value: 0.33937780891633623.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.339378:  17%|#6        | 1/6 [06:06<30:34, 366.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1556]\tvalid_0's binary_logloss: 0.326928\tvalid_1's binary_logloss: 0.339378\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.361545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347414\tvalid_1's binary_logloss: 0.343122\n",
      "[200]\tvalid_0's binary_logloss: 0.344599\tvalid_1's binary_logloss: 0.341626\n",
      "[300]\tvalid_0's binary_logloss: 0.342631\tvalid_1's binary_logloss: 0.341042\n",
      "[400]\tvalid_0's binary_logloss: 0.340928\tvalid_1's binary_logloss: 0.340655\n",
      "[500]\tvalid_0's binary_logloss: 0.339458\tvalid_1's binary_logloss: 0.340431\n",
      "[600]\tvalid_0's binary_logloss: 0.338037\tvalid_1's binary_logloss: 0.34025\n",
      "[700]\tvalid_0's binary_logloss: 0.336601\tvalid_1's binary_logloss: 0.340064\n",
      "[800]\tvalid_0's binary_logloss: 0.335232\tvalid_1's binary_logloss: 0.339828\n",
      "[900]\tvalid_0's binary_logloss: 0.333968\tvalid_1's binary_logloss: 0.339802\n",
      "[1000]\tvalid_0's binary_logloss: 0.332736\tvalid_1's binary_logloss: 0.339737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339378:  33%|###3      | 2/6 [10:27<20:18, 304.63s/it]\u001b[32m[I 2022-12-19 14:00:08,388]\u001b[0m Trial 38 finished with value: 0.3397148737166906 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 37 with value: 0.33937780891633623.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.339378:  33%|###3      | 2/6 [10:27<20:18, 304.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's binary_logloss: 0.332834\tvalid_1's binary_logloss: 0.339715\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.414981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347544\tvalid_1's binary_logloss: 0.343117\n",
      "[200]\tvalid_0's binary_logloss: 0.344706\tvalid_1's binary_logloss: 0.341549\n",
      "[300]\tvalid_0's binary_logloss: 0.342832\tvalid_1's binary_logloss: 0.341081\n",
      "[400]\tvalid_0's binary_logloss: 0.341108\tvalid_1's binary_logloss: 0.340686\n",
      "[500]\tvalid_0's binary_logloss: 0.339644\tvalid_1's binary_logloss: 0.340382\n",
      "[600]\tvalid_0's binary_logloss: 0.338237\tvalid_1's binary_logloss: 0.340124\n",
      "[700]\tvalid_0's binary_logloss: 0.3369\tvalid_1's binary_logloss: 0.340028\n",
      "[800]\tvalid_0's binary_logloss: 0.335579\tvalid_1's binary_logloss: 0.339787\n",
      "[900]\tvalid_0's binary_logloss: 0.334352\tvalid_1's binary_logloss: 0.339735\n",
      "[1000]\tvalid_0's binary_logloss: 0.333121\tvalid_1's binary_logloss: 0.339604\n",
      "[1100]\tvalid_0's binary_logloss: 0.331946\tvalid_1's binary_logloss: 0.339609\n",
      "[1200]\tvalid_0's binary_logloss: 0.330785\tvalid_1's binary_logloss: 0.339541\n",
      "[1300]\tvalid_0's binary_logloss: 0.329608\tvalid_1's binary_logloss: 0.3395\n",
      "[1400]\tvalid_0's binary_logloss: 0.328466\tvalid_1's binary_logloss: 0.339458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339378:  50%|#####     | 3/6 [16:03<15:56, 318.89s/it]\u001b[32m[I 2022-12-19 14:05:44,254]\u001b[0m Trial 39 finished with value: 0.3394322842450688 and parameters: {'feature_fraction': 0.584}. Best is trial 37 with value: 0.33937780891633623.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.339378:  50%|#####     | 3/6 [16:03<15:56, 318.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.329135\tvalid_1's binary_logloss: 0.339432\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347396\tvalid_1's binary_logloss: 0.34309\n",
      "[200]\tvalid_0's binary_logloss: 0.3446\tvalid_1's binary_logloss: 0.341613\n",
      "[300]\tvalid_0's binary_logloss: 0.342577\tvalid_1's binary_logloss: 0.341043\n",
      "[400]\tvalid_0's binary_logloss: 0.340895\tvalid_1's binary_logloss: 0.340705\n",
      "[500]\tvalid_0's binary_logloss: 0.339448\tvalid_1's binary_logloss: 0.340423\n",
      "[600]\tvalid_0's binary_logloss: 0.337974\tvalid_1's binary_logloss: 0.340137\n",
      "[700]\tvalid_0's binary_logloss: 0.336647\tvalid_1's binary_logloss: 0.340071\n",
      "[800]\tvalid_0's binary_logloss: 0.33531\tvalid_1's binary_logloss: 0.339871\n",
      "[900]\tvalid_0's binary_logloss: 0.333999\tvalid_1's binary_logloss: 0.339769\n",
      "[1000]\tvalid_0's binary_logloss: 0.332749\tvalid_1's binary_logloss: 0.339641\n",
      "[1100]\tvalid_0's binary_logloss: 0.33159\tvalid_1's binary_logloss: 0.339653\n",
      "[1200]\tvalid_0's binary_logloss: 0.330374\tvalid_1's binary_logloss: 0.339592\n",
      "[1300]\tvalid_0's binary_logloss: 0.329197\tvalid_1's binary_logloss: 0.33957\n",
      "[1400]\tvalid_0's binary_logloss: 0.328062\tvalid_1's binary_logloss: 0.339532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339378:  67%|######6   | 4/6 [21:28<10:42, 321.29s/it]\u001b[32m[I 2022-12-19 14:11:09,206]\u001b[0m Trial 40 finished with value: 0.33950468529220457 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 37 with value: 0.33937780891633623.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.339378:  67%|######6   | 4/6 [21:28<10:42, 321.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.328729\tvalid_1's binary_logloss: 0.339505\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.391971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347675\tvalid_1's binary_logloss: 0.343229\n",
      "[200]\tvalid_0's binary_logloss: 0.344838\tvalid_1's binary_logloss: 0.34173\n",
      "[300]\tvalid_0's binary_logloss: 0.342818\tvalid_1's binary_logloss: 0.340982\n",
      "[400]\tvalid_0's binary_logloss: 0.341132\tvalid_1's binary_logloss: 0.3406\n",
      "[500]\tvalid_0's binary_logloss: 0.339712\tvalid_1's binary_logloss: 0.340392\n",
      "[600]\tvalid_0's binary_logloss: 0.338319\tvalid_1's binary_logloss: 0.340209\n",
      "[700]\tvalid_0's binary_logloss: 0.336947\tvalid_1's binary_logloss: 0.340108\n",
      "[800]\tvalid_0's binary_logloss: 0.335598\tvalid_1's binary_logloss: 0.339847\n",
      "[900]\tvalid_0's binary_logloss: 0.334349\tvalid_1's binary_logloss: 0.339733\n",
      "[1000]\tvalid_0's binary_logloss: 0.333146\tvalid_1's binary_logloss: 0.33965\n",
      "[1100]\tvalid_0's binary_logloss: 0.331995\tvalid_1's binary_logloss: 0.339666\n",
      "[1200]\tvalid_0's binary_logloss: 0.33084\tvalid_1's binary_logloss: 0.339631\n",
      "[1300]\tvalid_0's binary_logloss: 0.329721\tvalid_1's binary_logloss: 0.339596\n",
      "[1400]\tvalid_0's binary_logloss: 0.328618\tvalid_1's binary_logloss: 0.339558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339378:  83%|########3 | 5/6 [26:47<05:20, 320.42s/it]\u001b[32m[I 2022-12-19 14:16:28,086]\u001b[0m Trial 41 finished with value: 0.3395349036782727 and parameters: {'feature_fraction': 0.52}. Best is trial 37 with value: 0.33937780891633623.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.339378:  83%|########3 | 5/6 [26:47<05:20, 320.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.329258\tvalid_1's binary_logloss: 0.339535\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.380512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347561\tvalid_1's binary_logloss: 0.34318\n",
      "[200]\tvalid_0's binary_logloss: 0.344674\tvalid_1's binary_logloss: 0.341624\n",
      "[300]\tvalid_0's binary_logloss: 0.342665\tvalid_1's binary_logloss: 0.341015\n",
      "[400]\tvalid_0's binary_logloss: 0.340991\tvalid_1's binary_logloss: 0.340635\n",
      "[500]\tvalid_0's binary_logloss: 0.339558\tvalid_1's binary_logloss: 0.340387\n",
      "[600]\tvalid_0's binary_logloss: 0.338156\tvalid_1's binary_logloss: 0.340147\n",
      "[700]\tvalid_0's binary_logloss: 0.336786\tvalid_1's binary_logloss: 0.340052\n",
      "[800]\tvalid_0's binary_logloss: 0.335445\tvalid_1's binary_logloss: 0.339868\n",
      "[900]\tvalid_0's binary_logloss: 0.334175\tvalid_1's binary_logloss: 0.339819\n",
      "[1000]\tvalid_0's binary_logloss: 0.332935\tvalid_1's binary_logloss: 0.339693\n",
      "[1100]\tvalid_0's binary_logloss: 0.33175\tvalid_1's binary_logloss: 0.339694\n",
      "[1200]\tvalid_0's binary_logloss: 0.330599\tvalid_1's binary_logloss: 0.339649\n",
      "[1300]\tvalid_0's binary_logloss: 0.32944\tvalid_1's binary_logloss: 0.339614\n",
      "[1400]\tvalid_0's binary_logloss: 0.328258\tvalid_1's binary_logloss: 0.339542\n",
      "[1500]\tvalid_0's binary_logloss: 0.327171\tvalid_1's binary_logloss: 0.339487\n",
      "[1600]\tvalid_0's binary_logloss: 0.326092\tvalid_1's binary_logloss: 0.339557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.339378: 100%|##########| 6/6 [33:07<00:00, 340.65s/it]\u001b[32m[I 2022-12-19 14:22:48,025]\u001b[0m Trial 42 finished with value: 0.33947261402482987 and parameters: {'feature_fraction': 0.616}. Best is trial 37 with value: 0.33937780891633623.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.339378: 100%|##########| 6/6 [33:07<00:00, 331.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1556]\tvalid_0's binary_logloss: 0.326558\tvalid_1's binary_logloss: 0.339473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.339378:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.381596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347707\tvalid_1's binary_logloss: 0.343308\n",
      "[200]\tvalid_0's binary_logloss: 0.344725\tvalid_1's binary_logloss: 0.341345\n",
      "[300]\tvalid_0's binary_logloss: 0.343006\tvalid_1's binary_logloss: 0.340672\n",
      "[400]\tvalid_0's binary_logloss: 0.34155\tvalid_1's binary_logloss: 0.340206\n",
      "[500]\tvalid_0's binary_logloss: 0.340353\tvalid_1's binary_logloss: 0.339919\n",
      "[600]\tvalid_0's binary_logloss: 0.33923\tvalid_1's binary_logloss: 0.339691\n",
      "[700]\tvalid_0's binary_logloss: 0.338104\tvalid_1's binary_logloss: 0.339465\n",
      "[800]\tvalid_0's binary_logloss: 0.33706\tvalid_1's binary_logloss: 0.339194\n",
      "[900]\tvalid_0's binary_logloss: 0.336093\tvalid_1's binary_logloss: 0.339144\n",
      "[1000]\tvalid_0's binary_logloss: 0.335109\tvalid_1's binary_logloss: 0.339022\n",
      "[1100]\tvalid_0's binary_logloss: 0.334188\tvalid_1's binary_logloss: 0.33901\n",
      "[1200]\tvalid_0's binary_logloss: 0.333272\tvalid_1's binary_logloss: 0.338935\n",
      "[1300]\tvalid_0's binary_logloss: 0.332385\tvalid_1's binary_logloss: 0.338861\n",
      "[1400]\tvalid_0's binary_logloss: 0.331516\tvalid_1's binary_logloss: 0.338776\n",
      "[1500]\tvalid_0's binary_logloss: 0.33066\tvalid_1's binary_logloss: 0.33866\n",
      "[1600]\tvalid_0's binary_logloss: 0.329844\tvalid_1's binary_logloss: 0.338723\n",
      "[1700]\tvalid_0's binary_logloss: 0.329009\tvalid_1's binary_logloss: 0.338714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:   5%|5         | 1/20 [06:39<2:06:27, 399.32s/it]\u001b[32m[I 2022-12-19 14:29:27,357]\u001b[0m Trial 43 finished with value: 0.33862803726332613 and parameters: {'lambda_l1': 7.096178391060172, 'lambda_l2': 5.011525959095806e-06}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:   5%|5         | 1/20 [06:39<2:06:27, 399.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.329409\tvalid_1's binary_logloss: 0.338628\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.353827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347618\tvalid_1's binary_logloss: 0.343159\n",
      "[200]\tvalid_0's binary_logloss: 0.344712\tvalid_1's binary_logloss: 0.341505\n",
      "[300]\tvalid_0's binary_logloss: 0.342764\tvalid_1's binary_logloss: 0.340997\n",
      "[400]\tvalid_0's binary_logloss: 0.341199\tvalid_1's binary_logloss: 0.340662\n",
      "[500]\tvalid_0's binary_logloss: 0.33971\tvalid_1's binary_logloss: 0.340345\n",
      "[600]\tvalid_0's binary_logloss: 0.338265\tvalid_1's binary_logloss: 0.340092\n",
      "[700]\tvalid_0's binary_logloss: 0.336898\tvalid_1's binary_logloss: 0.340032\n",
      "[800]\tvalid_0's binary_logloss: 0.335593\tvalid_1's binary_logloss: 0.339812\n",
      "[900]\tvalid_0's binary_logloss: 0.334374\tvalid_1's binary_logloss: 0.339704\n",
      "[1000]\tvalid_0's binary_logloss: 0.333177\tvalid_1's binary_logloss: 0.339586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  10%|#         | 2/20 [10:52<1:34:05, 313.63s/it]\u001b[32m[I 2022-12-19 14:33:41,000]\u001b[0m Trial 44 finished with value: 0.3395573985701061 and parameters: {'lambda_l1': 6.674122792933715e-07, 'lambda_l2': 2.224962382131696e-08}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  10%|#         | 2/20 [10:52<1:34:05, 313.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[982]\tvalid_0's binary_logloss: 0.333376\tvalid_1's binary_logloss: 0.339557\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.345171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347619\tvalid_1's binary_logloss: 0.343114\n",
      "[200]\tvalid_0's binary_logloss: 0.344735\tvalid_1's binary_logloss: 0.341546\n",
      "[300]\tvalid_0's binary_logloss: 0.342696\tvalid_1's binary_logloss: 0.34096\n",
      "[400]\tvalid_0's binary_logloss: 0.341107\tvalid_1's binary_logloss: 0.340669\n",
      "[500]\tvalid_0's binary_logloss: 0.339638\tvalid_1's binary_logloss: 0.340349\n",
      "[600]\tvalid_0's binary_logloss: 0.338181\tvalid_1's binary_logloss: 0.340063\n",
      "[700]\tvalid_0's binary_logloss: 0.336867\tvalid_1's binary_logloss: 0.340001\n",
      "[800]\tvalid_0's binary_logloss: 0.335572\tvalid_1's binary_logloss: 0.339809\n",
      "[900]\tvalid_0's binary_logloss: 0.334377\tvalid_1's binary_logloss: 0.339758\n",
      "[1000]\tvalid_0's binary_logloss: 0.333175\tvalid_1's binary_logloss: 0.339631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  15%|#5        | 3/20 [15:10<1:21:32, 287.79s/it]\u001b[32m[I 2022-12-19 14:37:58,047]\u001b[0m Trial 45 finished with value: 0.3396082786066275 and parameters: {'lambda_l1': 0.010253232524784875, 'lambda_l2': 1.7003702943659255e-06}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  15%|#5        | 3/20 [15:10<1:21:32, 287.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's binary_logloss: 0.333256\tvalid_1's binary_logloss: 0.339608\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.353704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347649\tvalid_1's binary_logloss: 0.343177\n",
      "[200]\tvalid_0's binary_logloss: 0.344769\tvalid_1's binary_logloss: 0.341678\n",
      "[300]\tvalid_0's binary_logloss: 0.342922\tvalid_1's binary_logloss: 0.341185\n",
      "[400]\tvalid_0's binary_logloss: 0.341242\tvalid_1's binary_logloss: 0.340757\n",
      "[500]\tvalid_0's binary_logloss: 0.339832\tvalid_1's binary_logloss: 0.340483\n",
      "[600]\tvalid_0's binary_logloss: 0.338392\tvalid_1's binary_logloss: 0.340186\n",
      "[700]\tvalid_0's binary_logloss: 0.336993\tvalid_1's binary_logloss: 0.340018\n",
      "[800]\tvalid_0's binary_logloss: 0.335735\tvalid_1's binary_logloss: 0.339815\n",
      "[900]\tvalid_0's binary_logloss: 0.334485\tvalid_1's binary_logloss: 0.33974\n",
      "[1000]\tvalid_0's binary_logloss: 0.333307\tvalid_1's binary_logloss: 0.33965\n",
      "[1100]\tvalid_0's binary_logloss: 0.332184\tvalid_1's binary_logloss: 0.339677\n",
      "[1200]\tvalid_0's binary_logloss: 0.331033\tvalid_1's binary_logloss: 0.339605\n",
      "[1300]\tvalid_0's binary_logloss: 0.329871\tvalid_1's binary_logloss: 0.339543\n",
      "[1400]\tvalid_0's binary_logloss: 0.328768\tvalid_1's binary_logloss: 0.339475\n",
      "[1500]\tvalid_0's binary_logloss: 0.327722\tvalid_1's binary_logloss: 0.33942\n",
      "[1600]\tvalid_0's binary_logloss: 0.326627\tvalid_1's binary_logloss: 0.339448\n",
      "[1700]\tvalid_0's binary_logloss: 0.325563\tvalid_1's binary_logloss: 0.339455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  20%|##        | 4/20 [21:38<1:27:23, 327.70s/it]\u001b[32m[I 2022-12-19 14:44:26,923]\u001b[0m Trial 46 finished with value: 0.3393707671341479 and parameters: {'lambda_l1': 3.2497292505143924e-08, 'lambda_l2': 0.09650182190892809}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  20%|##        | 4/20 [21:38<1:27:23, 327.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.326084\tvalid_1's binary_logloss: 0.339371\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.419219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347657\tvalid_1's binary_logloss: 0.343263\n",
      "[200]\tvalid_0's binary_logloss: 0.344778\tvalid_1's binary_logloss: 0.341471\n",
      "[300]\tvalid_0's binary_logloss: 0.343015\tvalid_1's binary_logloss: 0.340812\n",
      "[400]\tvalid_0's binary_logloss: 0.341608\tvalid_1's binary_logloss: 0.340433\n",
      "[500]\tvalid_0's binary_logloss: 0.340301\tvalid_1's binary_logloss: 0.340042\n",
      "[600]\tvalid_0's binary_logloss: 0.339104\tvalid_1's binary_logloss: 0.339748\n",
      "[700]\tvalid_0's binary_logloss: 0.337957\tvalid_1's binary_logloss: 0.339597\n",
      "[800]\tvalid_0's binary_logloss: 0.336883\tvalid_1's binary_logloss: 0.339384\n",
      "[900]\tvalid_0's binary_logloss: 0.335798\tvalid_1's binary_logloss: 0.339272\n",
      "[1000]\tvalid_0's binary_logloss: 0.334784\tvalid_1's binary_logloss: 0.339145\n",
      "[1100]\tvalid_0's binary_logloss: 0.333846\tvalid_1's binary_logloss: 0.33911\n",
      "[1200]\tvalid_0's binary_logloss: 0.332883\tvalid_1's binary_logloss: 0.339021\n",
      "[1300]\tvalid_0's binary_logloss: 0.331929\tvalid_1's binary_logloss: 0.338962\n",
      "[1400]\tvalid_0's binary_logloss: 0.331014\tvalid_1's binary_logloss: 0.338915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  25%|##5       | 5/20 [27:11<1:22:22, 329.51s/it]\u001b[32m[I 2022-12-19 14:49:59,659]\u001b[0m Trial 47 finished with value: 0.3388965018240673 and parameters: {'lambda_l1': 0.016705959395324255, 'lambda_l2': 8.643589777068707}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  25%|##5       | 5/20 [27:11<1:22:22, 329.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.331552\tvalid_1's binary_logloss: 0.338897\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.406330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347617\tvalid_1's binary_logloss: 0.343135\n",
      "[200]\tvalid_0's binary_logloss: 0.344834\tvalid_1's binary_logloss: 0.341652\n",
      "[300]\tvalid_0's binary_logloss: 0.342916\tvalid_1's binary_logloss: 0.341056\n",
      "[400]\tvalid_0's binary_logloss: 0.341326\tvalid_1's binary_logloss: 0.340684\n",
      "[500]\tvalid_0's binary_logloss: 0.339871\tvalid_1's binary_logloss: 0.340401\n",
      "[600]\tvalid_0's binary_logloss: 0.338477\tvalid_1's binary_logloss: 0.340156\n",
      "[700]\tvalid_0's binary_logloss: 0.337165\tvalid_1's binary_logloss: 0.3401\n",
      "[800]\tvalid_0's binary_logloss: 0.335864\tvalid_1's binary_logloss: 0.339839\n",
      "[900]\tvalid_0's binary_logloss: 0.334611\tvalid_1's binary_logloss: 0.339734\n",
      "[1000]\tvalid_0's binary_logloss: 0.333396\tvalid_1's binary_logloss: 0.339574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  30%|###       | 6/20 [31:25<1:10:52, 303.78s/it]\u001b[32m[I 2022-12-19 14:54:13,472]\u001b[0m Trial 48 finished with value: 0.3395412449187951 and parameters: {'lambda_l1': 0.0010030365219409487, 'lambda_l2': 0.16355900740797763}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  30%|###       | 6/20 [31:25<1:10:52, 303.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[982]\tvalid_0's binary_logloss: 0.333604\tvalid_1's binary_logloss: 0.339541\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.356634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347632\tvalid_1's binary_logloss: 0.343133\n",
      "[200]\tvalid_0's binary_logloss: 0.344773\tvalid_1's binary_logloss: 0.341559\n",
      "[300]\tvalid_0's binary_logloss: 0.342882\tvalid_1's binary_logloss: 0.341096\n",
      "[400]\tvalid_0's binary_logloss: 0.341265\tvalid_1's binary_logloss: 0.340824\n",
      "[500]\tvalid_0's binary_logloss: 0.339778\tvalid_1's binary_logloss: 0.340488\n",
      "[600]\tvalid_0's binary_logloss: 0.338388\tvalid_1's binary_logloss: 0.340272\n",
      "[700]\tvalid_0's binary_logloss: 0.337056\tvalid_1's binary_logloss: 0.34018\n",
      "[800]\tvalid_0's binary_logloss: 0.335737\tvalid_1's binary_logloss: 0.339958\n",
      "[900]\tvalid_0's binary_logloss: 0.334481\tvalid_1's binary_logloss: 0.339882\n",
      "[1000]\tvalid_0's binary_logloss: 0.33324\tvalid_1's binary_logloss: 0.339725\n",
      "[1100]\tvalid_0's binary_logloss: 0.332075\tvalid_1's binary_logloss: 0.339714\n",
      "[1200]\tvalid_0's binary_logloss: 0.330894\tvalid_1's binary_logloss: 0.339645\n",
      "[1300]\tvalid_0's binary_logloss: 0.329757\tvalid_1's binary_logloss: 0.339621\n",
      "[1400]\tvalid_0's binary_logloss: 0.32863\tvalid_1's binary_logloss: 0.339508\n",
      "[1500]\tvalid_0's binary_logloss: 0.327567\tvalid_1's binary_logloss: 0.339435\n",
      "[1600]\tvalid_0's binary_logloss: 0.326512\tvalid_1's binary_logloss: 0.339487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  35%|###5      | 7/20 [37:32<1:10:18, 324.53s/it]\u001b[32m[I 2022-12-19 15:00:20,737]\u001b[0m Trial 49 finished with value: 0.33940774556099074 and parameters: {'lambda_l1': 0.015235816745172947, 'lambda_l2': 8.667260655863151e-05}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  35%|###5      | 7/20 [37:32<1:10:18, 324.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1556]\tvalid_0's binary_logloss: 0.326964\tvalid_1's binary_logloss: 0.339408\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.359319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347661\tvalid_1's binary_logloss: 0.343123\n",
      "[200]\tvalid_0's binary_logloss: 0.344689\tvalid_1's binary_logloss: 0.341349\n",
      "[300]\tvalid_0's binary_logloss: 0.342881\tvalid_1's binary_logloss: 0.340822\n",
      "[400]\tvalid_0's binary_logloss: 0.341317\tvalid_1's binary_logloss: 0.34038\n",
      "[500]\tvalid_0's binary_logloss: 0.339952\tvalid_1's binary_logloss: 0.340097\n",
      "[600]\tvalid_0's binary_logloss: 0.338646\tvalid_1's binary_logloss: 0.33991\n",
      "[700]\tvalid_0's binary_logloss: 0.337359\tvalid_1's binary_logloss: 0.339774\n",
      "[800]\tvalid_0's binary_logloss: 0.336099\tvalid_1's binary_logloss: 0.3396\n",
      "[900]\tvalid_0's binary_logloss: 0.334947\tvalid_1's binary_logloss: 0.339556\n",
      "[1000]\tvalid_0's binary_logloss: 0.333791\tvalid_1's binary_logloss: 0.339443\n",
      "[1100]\tvalid_0's binary_logloss: 0.332689\tvalid_1's binary_logloss: 0.339423\n",
      "[1200]\tvalid_0's binary_logloss: 0.331605\tvalid_1's binary_logloss: 0.339352\n",
      "[1300]\tvalid_0's binary_logloss: 0.330545\tvalid_1's binary_logloss: 0.339302\n",
      "[1400]\tvalid_0's binary_logloss: 0.329503\tvalid_1's binary_logloss: 0.339264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  40%|####      | 8/20 [42:55<1:04:49, 324.10s/it]\u001b[32m[I 2022-12-19 15:05:43,896]\u001b[0m Trial 50 finished with value: 0.3392383263397072 and parameters: {'lambda_l1': 1.0769288693272256e-06, 'lambda_l2': 0.9729217914740961}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  40%|####      | 8/20 [42:55<1:04:49, 324.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.330106\tvalid_1's binary_logloss: 0.339238\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.403745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347618\tvalid_1's binary_logloss: 0.343159\n",
      "[200]\tvalid_0's binary_logloss: 0.344712\tvalid_1's binary_logloss: 0.341506\n",
      "[300]\tvalid_0's binary_logloss: 0.342748\tvalid_1's binary_logloss: 0.341\n",
      "[400]\tvalid_0's binary_logloss: 0.341165\tvalid_1's binary_logloss: 0.340675\n",
      "[500]\tvalid_0's binary_logloss: 0.339684\tvalid_1's binary_logloss: 0.340373\n",
      "[600]\tvalid_0's binary_logloss: 0.338275\tvalid_1's binary_logloss: 0.340124\n",
      "[700]\tvalid_0's binary_logloss: 0.336939\tvalid_1's binary_logloss: 0.340064\n",
      "[800]\tvalid_0's binary_logloss: 0.335647\tvalid_1's binary_logloss: 0.339885\n",
      "[900]\tvalid_0's binary_logloss: 0.334361\tvalid_1's binary_logloss: 0.339772\n",
      "[1000]\tvalid_0's binary_logloss: 0.333187\tvalid_1's binary_logloss: 0.339663\n",
      "[1100]\tvalid_0's binary_logloss: 0.33205\tvalid_1's binary_logloss: 0.339694\n",
      "[1200]\tvalid_0's binary_logloss: 0.330885\tvalid_1's binary_logloss: 0.339612\n",
      "[1300]\tvalid_0's binary_logloss: 0.329749\tvalid_1's binary_logloss: 0.339562\n",
      "[1400]\tvalid_0's binary_logloss: 0.328592\tvalid_1's binary_logloss: 0.339476\n",
      "[1500]\tvalid_0's binary_logloss: 0.327528\tvalid_1's binary_logloss: 0.33944\n",
      "[1600]\tvalid_0's binary_logloss: 0.32643\tvalid_1's binary_logloss: 0.339511\n",
      "[1700]\tvalid_0's binary_logloss: 0.325359\tvalid_1's binary_logloss: 0.339545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  45%|####5     | 9/20 [49:20<1:02:52, 342.99s/it]\u001b[32m[I 2022-12-19 15:12:08,424]\u001b[0m Trial 51 finished with value: 0.33943173381862823 and parameters: {'lambda_l1': 2.1871713940916974e-08, 'lambda_l2': 5.706713942146569e-05}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  45%|####5     | 9/20 [49:20<1:02:52, 342.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.325865\tvalid_1's binary_logloss: 0.339432\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.346910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347658\tvalid_1's binary_logloss: 0.343219\n",
      "[200]\tvalid_0's binary_logloss: 0.344784\tvalid_1's binary_logloss: 0.341478\n",
      "[300]\tvalid_0's binary_logloss: 0.342885\tvalid_1's binary_logloss: 0.340789\n",
      "[400]\tvalid_0's binary_logloss: 0.341365\tvalid_1's binary_logloss: 0.340333\n",
      "[500]\tvalid_0's binary_logloss: 0.339996\tvalid_1's binary_logloss: 0.340009\n",
      "[600]\tvalid_0's binary_logloss: 0.338731\tvalid_1's binary_logloss: 0.339748\n",
      "[700]\tvalid_0's binary_logloss: 0.337466\tvalid_1's binary_logloss: 0.339612\n",
      "[800]\tvalid_0's binary_logloss: 0.336254\tvalid_1's binary_logloss: 0.33938\n",
      "[900]\tvalid_0's binary_logloss: 0.335106\tvalid_1's binary_logloss: 0.339297\n",
      "[1000]\tvalid_0's binary_logloss: 0.334009\tvalid_1's binary_logloss: 0.339155\n",
      "[1100]\tvalid_0's binary_logloss: 0.332979\tvalid_1's binary_logloss: 0.339174\n",
      "[1200]\tvalid_0's binary_logloss: 0.331933\tvalid_1's binary_logloss: 0.339075\n",
      "[1300]\tvalid_0's binary_logloss: 0.330888\tvalid_1's binary_logloss: 0.338975\n",
      "[1400]\tvalid_0's binary_logloss: 0.32989\tvalid_1's binary_logloss: 0.338903\n",
      "[1500]\tvalid_0's binary_logloss: 0.328895\tvalid_1's binary_logloss: 0.338831\n",
      "[1600]\tvalid_0's binary_logloss: 0.327919\tvalid_1's binary_logloss: 0.338886\n",
      "[1700]\tvalid_0's binary_logloss: 0.32696\tvalid_1's binary_logloss: 0.338894\n",
      "[1800]\tvalid_0's binary_logloss: 0.326021\tvalid_1's binary_logloss: 0.338838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338628:  50%|#####     | 10/20 [56:17<1:00:57, 365.77s/it]\u001b[32m[I 2022-12-19 15:19:05,213]\u001b[0m Trial 52 finished with value: 0.33880216336401653 and parameters: {'lambda_l1': 2.5398153280701776, 'lambda_l2': 1.151907778420723e-05}. Best is trial 43 with value: 0.33862803726332613.\u001b[0m\n",
      "regularization_factors, val_score: 0.338628:  50%|#####     | 10/20 [56:17<1:00:57, 365.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1782]\tvalid_0's binary_logloss: 0.326186\tvalid_1's binary_logloss: 0.338802\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.372864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347703\tvalid_1's binary_logloss: 0.343277\n",
      "[200]\tvalid_0's binary_logloss: 0.344721\tvalid_1's binary_logloss: 0.341392\n",
      "[300]\tvalid_0's binary_logloss: 0.342873\tvalid_1's binary_logloss: 0.340595\n",
      "[400]\tvalid_0's binary_logloss: 0.341437\tvalid_1's binary_logloss: 0.340126\n",
      "[500]\tvalid_0's binary_logloss: 0.340167\tvalid_1's binary_logloss: 0.339778\n",
      "[600]\tvalid_0's binary_logloss: 0.339022\tvalid_1's binary_logloss: 0.339571\n",
      "[700]\tvalid_0's binary_logloss: 0.337883\tvalid_1's binary_logloss: 0.339457\n",
      "[800]\tvalid_0's binary_logloss: 0.336777\tvalid_1's binary_logloss: 0.339193\n",
      "[900]\tvalid_0's binary_logloss: 0.335755\tvalid_1's binary_logloss: 0.339105\n",
      "[1000]\tvalid_0's binary_logloss: 0.334785\tvalid_1's binary_logloss: 0.338987\n",
      "[1100]\tvalid_0's binary_logloss: 0.333811\tvalid_1's binary_logloss: 0.338974\n",
      "[1200]\tvalid_0's binary_logloss: 0.332856\tvalid_1's binary_logloss: 0.338879\n",
      "[1300]\tvalid_0's binary_logloss: 0.331935\tvalid_1's binary_logloss: 0.338837\n",
      "[1400]\tvalid_0's binary_logloss: 0.331016\tvalid_1's binary_logloss: 0.338763\n",
      "[1500]\tvalid_0's binary_logloss: 0.330143\tvalid_1's binary_logloss: 0.338673\n",
      "[1600]\tvalid_0's binary_logloss: 0.329268\tvalid_1's binary_logloss: 0.338712\n",
      "[1700]\tvalid_0's binary_logloss: 0.328403\tvalid_1's binary_logloss: 0.338723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  55%|#####5    | 11/20 [1:02:53<56:16, 375.16s/it]  \u001b[32m[I 2022-12-19 15:25:41,663]\u001b[0m Trial 53 finished with value: 0.33862147976979545 and parameters: {'lambda_l1': 5.485903737168179, 'lambda_l2': 0.005594683492536064}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  55%|#####5    | 11/20 [1:02:53<56:16, 375.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.328816\tvalid_1's binary_logloss: 0.338621\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.356712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347702\tvalid_1's binary_logloss: 0.343298\n",
      "[200]\tvalid_0's binary_logloss: 0.344761\tvalid_1's binary_logloss: 0.341383\n",
      "[300]\tvalid_0's binary_logloss: 0.342941\tvalid_1's binary_logloss: 0.340637\n",
      "[400]\tvalid_0's binary_logloss: 0.341572\tvalid_1's binary_logloss: 0.340187\n",
      "[500]\tvalid_0's binary_logloss: 0.340374\tvalid_1's binary_logloss: 0.339872\n",
      "[600]\tvalid_0's binary_logloss: 0.339229\tvalid_1's binary_logloss: 0.33964\n",
      "[700]\tvalid_0's binary_logloss: 0.338126\tvalid_1's binary_logloss: 0.339521\n",
      "[800]\tvalid_0's binary_logloss: 0.337122\tvalid_1's binary_logloss: 0.339286\n",
      "[900]\tvalid_0's binary_logloss: 0.336136\tvalid_1's binary_logloss: 0.339206\n",
      "[1000]\tvalid_0's binary_logloss: 0.335149\tvalid_1's binary_logloss: 0.339041\n",
      "[1100]\tvalid_0's binary_logloss: 0.334242\tvalid_1's binary_logloss: 0.339036\n",
      "[1200]\tvalid_0's binary_logloss: 0.333349\tvalid_1's binary_logloss: 0.338955\n",
      "[1300]\tvalid_0's binary_logloss: 0.332466\tvalid_1's binary_logloss: 0.338928\n",
      "[1400]\tvalid_0's binary_logloss: 0.331595\tvalid_1's binary_logloss: 0.338862\n",
      "[1500]\tvalid_0's binary_logloss: 0.330778\tvalid_1's binary_logloss: 0.338782\n",
      "[1600]\tvalid_0's binary_logloss: 0.329955\tvalid_1's binary_logloss: 0.338828\n",
      "[1700]\tvalid_0's binary_logloss: 0.329168\tvalid_1's binary_logloss: 0.338861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  60%|######    | 12/20 [1:09:34<51:02, 382.83s/it]\u001b[32m[I 2022-12-19 15:32:22,051]\u001b[0m Trial 54 finished with value: 0.33875058506185074 and parameters: {'lambda_l1': 7.614863583679999, 'lambda_l2': 0.0029992723449617795}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  60%|######    | 12/20 [1:09:34<51:02, 382.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.329535\tvalid_1's binary_logloss: 0.338751\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.332990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347683\tvalid_1's binary_logloss: 0.34318\n",
      "[200]\tvalid_0's binary_logloss: 0.344797\tvalid_1's binary_logloss: 0.341616\n",
      "[300]\tvalid_0's binary_logloss: 0.342781\tvalid_1's binary_logloss: 0.340885\n",
      "[400]\tvalid_0's binary_logloss: 0.341212\tvalid_1's binary_logloss: 0.340605\n",
      "[500]\tvalid_0's binary_logloss: 0.339757\tvalid_1's binary_logloss: 0.340251\n",
      "[600]\tvalid_0's binary_logloss: 0.338334\tvalid_1's binary_logloss: 0.34002\n",
      "[700]\tvalid_0's binary_logloss: 0.336978\tvalid_1's binary_logloss: 0.339935\n",
      "[800]\tvalid_0's binary_logloss: 0.335694\tvalid_1's binary_logloss: 0.339775\n",
      "[900]\tvalid_0's binary_logloss: 0.334453\tvalid_1's binary_logloss: 0.33967\n",
      "[1000]\tvalid_0's binary_logloss: 0.333215\tvalid_1's binary_logloss: 0.339483\n",
      "[1100]\tvalid_0's binary_logloss: 0.332085\tvalid_1's binary_logloss: 0.339493\n",
      "[1200]\tvalid_0's binary_logloss: 0.330946\tvalid_1's binary_logloss: 0.339446\n",
      "[1300]\tvalid_0's binary_logloss: 0.329809\tvalid_1's binary_logloss: 0.339408\n",
      "[1400]\tvalid_0's binary_logloss: 0.328639\tvalid_1's binary_logloss: 0.339362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  65%|######5   | 13/20 [1:14:57<42:34, 364.99s/it]\u001b[32m[I 2022-12-19 15:37:45,992]\u001b[0m Trial 55 finished with value: 0.33933775039268876 and parameters: {'lambda_l1': 0.44922977183272467, 'lambda_l2': 0.002396198540947499}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  65%|######5   | 13/20 [1:14:57<42:34, 364.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.329336\tvalid_1's binary_logloss: 0.339338\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.349112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.34761\tvalid_1's binary_logloss: 0.343136\n",
      "[200]\tvalid_0's binary_logloss: 0.344696\tvalid_1's binary_logloss: 0.341426\n",
      "[300]\tvalid_0's binary_logloss: 0.342757\tvalid_1's binary_logloss: 0.340904\n",
      "[400]\tvalid_0's binary_logloss: 0.341102\tvalid_1's binary_logloss: 0.340513\n",
      "[500]\tvalid_0's binary_logloss: 0.339637\tvalid_1's binary_logloss: 0.340246\n",
      "[600]\tvalid_0's binary_logloss: 0.33827\tvalid_1's binary_logloss: 0.340017\n",
      "[700]\tvalid_0's binary_logloss: 0.336956\tvalid_1's binary_logloss: 0.339945\n",
      "[800]\tvalid_0's binary_logloss: 0.335671\tvalid_1's binary_logloss: 0.33972\n",
      "[900]\tvalid_0's binary_logloss: 0.334426\tvalid_1's binary_logloss: 0.33963\n",
      "[1000]\tvalid_0's binary_logloss: 0.33322\tvalid_1's binary_logloss: 0.339514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  70%|#######   | 14/20 [1:19:14<33:13, 332.21s/it]\u001b[32m[I 2022-12-19 15:42:02,433]\u001b[0m Trial 56 finished with value: 0.33948061950252295 and parameters: {'lambda_l1': 0.32714583309330064, 'lambda_l2': 2.7969582353364297e-07}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  70%|#######   | 14/20 [1:19:14<33:13, 332.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's binary_logloss: 0.333301\tvalid_1's binary_logloss: 0.339481\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.378140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347618\tvalid_1's binary_logloss: 0.343157\n",
      "[200]\tvalid_0's binary_logloss: 0.344774\tvalid_1's binary_logloss: 0.34164\n",
      "[300]\tvalid_0's binary_logloss: 0.342797\tvalid_1's binary_logloss: 0.34104\n",
      "[400]\tvalid_0's binary_logloss: 0.341102\tvalid_1's binary_logloss: 0.340652\n",
      "[500]\tvalid_0's binary_logloss: 0.339667\tvalid_1's binary_logloss: 0.340388\n",
      "[600]\tvalid_0's binary_logloss: 0.338277\tvalid_1's binary_logloss: 0.340211\n",
      "[700]\tvalid_0's binary_logloss: 0.336982\tvalid_1's binary_logloss: 0.340134\n",
      "[800]\tvalid_0's binary_logloss: 0.335644\tvalid_1's binary_logloss: 0.339876\n",
      "[900]\tvalid_0's binary_logloss: 0.334394\tvalid_1's binary_logloss: 0.339803\n",
      "[1000]\tvalid_0's binary_logloss: 0.333192\tvalid_1's binary_logloss: 0.339708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  75%|#######5  | 15/20 [1:23:30<25:46, 309.34s/it]\u001b[32m[I 2022-12-19 15:46:18,774]\u001b[0m Trial 57 finished with value: 0.33968149326306213 and parameters: {'lambda_l1': 3.6734395663704245e-05, 'lambda_l2': 0.001440369639687596}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  75%|#######5  | 15/20 [1:23:30<25:46, 309.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[982]\tvalid_0's binary_logloss: 0.3334\tvalid_1's binary_logloss: 0.339681\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.382440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347638\tvalid_1's binary_logloss: 0.343256\n",
      "[200]\tvalid_0's binary_logloss: 0.344684\tvalid_1's binary_logloss: 0.341562\n",
      "[300]\tvalid_0's binary_logloss: 0.342725\tvalid_1's binary_logloss: 0.340914\n",
      "[400]\tvalid_0's binary_logloss: 0.341111\tvalid_1's binary_logloss: 0.340568\n",
      "[500]\tvalid_0's binary_logloss: 0.339641\tvalid_1's binary_logloss: 0.340285\n",
      "[600]\tvalid_0's binary_logloss: 0.338257\tvalid_1's binary_logloss: 0.340085\n",
      "[700]\tvalid_0's binary_logloss: 0.336966\tvalid_1's binary_logloss: 0.340014\n",
      "[800]\tvalid_0's binary_logloss: 0.335657\tvalid_1's binary_logloss: 0.339773\n",
      "[900]\tvalid_0's binary_logloss: 0.334399\tvalid_1's binary_logloss: 0.339699\n",
      "[1000]\tvalid_0's binary_logloss: 0.333231\tvalid_1's binary_logloss: 0.339586\n",
      "[1100]\tvalid_0's binary_logloss: 0.3321\tvalid_1's binary_logloss: 0.339609\n",
      "[1200]\tvalid_0's binary_logloss: 0.330949\tvalid_1's binary_logloss: 0.339529\n",
      "[1300]\tvalid_0's binary_logloss: 0.329799\tvalid_1's binary_logloss: 0.339478\n",
      "[1400]\tvalid_0's binary_logloss: 0.328644\tvalid_1's binary_logloss: 0.339411\n",
      "[1500]\tvalid_0's binary_logloss: 0.32755\tvalid_1's binary_logloss: 0.339329\n",
      "[1600]\tvalid_0's binary_logloss: 0.326509\tvalid_1's binary_logloss: 0.33939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  80%|########  | 16/20 [1:29:37<21:47, 326.77s/it]\u001b[32m[I 2022-12-19 15:52:26,021]\u001b[0m Trial 58 finished with value: 0.33931267621172095 and parameters: {'lambda_l1': 0.2252308013818547, 'lambda_l2': 0.013747939149828496}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  80%|########  | 16/20 [1:29:37<21:47, 326.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1556]\tvalid_0's binary_logloss: 0.326958\tvalid_1's binary_logloss: 0.339313\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.344732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347618\tvalid_1's binary_logloss: 0.343156\n",
      "[200]\tvalid_0's binary_logloss: 0.344712\tvalid_1's binary_logloss: 0.341502\n",
      "[300]\tvalid_0's binary_logloss: 0.342764\tvalid_1's binary_logloss: 0.340984\n",
      "[400]\tvalid_0's binary_logloss: 0.341198\tvalid_1's binary_logloss: 0.340664\n",
      "[500]\tvalid_0's binary_logloss: 0.339741\tvalid_1's binary_logloss: 0.340394\n",
      "[600]\tvalid_0's binary_logloss: 0.338342\tvalid_1's binary_logloss: 0.340196\n",
      "[700]\tvalid_0's binary_logloss: 0.337025\tvalid_1's binary_logloss: 0.34007\n",
      "[800]\tvalid_0's binary_logloss: 0.335737\tvalid_1's binary_logloss: 0.339892\n",
      "[900]\tvalid_0's binary_logloss: 0.334498\tvalid_1's binary_logloss: 0.339845\n",
      "[1000]\tvalid_0's binary_logloss: 0.333272\tvalid_1's binary_logloss: 0.339708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  85%|########5 | 17/20 [1:33:51<15:14, 304.77s/it]\u001b[32m[I 2022-12-19 15:56:39,626]\u001b[0m Trial 59 finished with value: 0.33968435934574254 and parameters: {'lambda_l1': 0.00013334711737377769, 'lambda_l2': 1.3516820443430047e-06}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  85%|########5 | 17/20 [1:33:51<15:14, 304.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[982]\tvalid_0's binary_logloss: 0.333486\tvalid_1's binary_logloss: 0.339684\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.349562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347698\tvalid_1's binary_logloss: 0.343266\n",
      "[200]\tvalid_0's binary_logloss: 0.344722\tvalid_1's binary_logloss: 0.341398\n",
      "[300]\tvalid_0's binary_logloss: 0.342828\tvalid_1's binary_logloss: 0.340692\n",
      "[400]\tvalid_0's binary_logloss: 0.341342\tvalid_1's binary_logloss: 0.340296\n",
      "[500]\tvalid_0's binary_logloss: 0.340005\tvalid_1's binary_logloss: 0.340009\n",
      "[600]\tvalid_0's binary_logloss: 0.338748\tvalid_1's binary_logloss: 0.339799\n",
      "[700]\tvalid_0's binary_logloss: 0.337503\tvalid_1's binary_logloss: 0.339639\n",
      "[800]\tvalid_0's binary_logloss: 0.336316\tvalid_1's binary_logloss: 0.339464\n",
      "[900]\tvalid_0's binary_logloss: 0.335222\tvalid_1's binary_logloss: 0.339397\n",
      "[1000]\tvalid_0's binary_logloss: 0.334126\tvalid_1's binary_logloss: 0.339285\n",
      "[1100]\tvalid_0's binary_logloss: 0.333101\tvalid_1's binary_logloss: 0.339275\n",
      "[1200]\tvalid_0's binary_logloss: 0.332038\tvalid_1's binary_logloss: 0.339162\n",
      "[1300]\tvalid_0's binary_logloss: 0.330983\tvalid_1's binary_logloss: 0.339081\n",
      "[1400]\tvalid_0's binary_logloss: 0.329947\tvalid_1's binary_logloss: 0.339015\n",
      "[1500]\tvalid_0's binary_logloss: 0.328994\tvalid_1's binary_logloss: 0.338922\n",
      "[1600]\tvalid_0's binary_logloss: 0.328032\tvalid_1's binary_logloss: 0.33899\n",
      "[1700]\tvalid_0's binary_logloss: 0.327111\tvalid_1's binary_logloss: 0.338996\n",
      "[1800]\tvalid_0's binary_logloss: 0.326163\tvalid_1's binary_logloss: 0.338899\n",
      "[1900]\tvalid_0's binary_logloss: 0.325238\tvalid_1's binary_logloss: 0.338909\n",
      "[2000]\tvalid_0's binary_logloss: 0.32433\tvalid_1's binary_logloss: 0.338922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  90%|######### | 18/20 [1:41:12<11:31, 345.56s/it]\u001b[32m[I 2022-12-19 16:04:00,136]\u001b[0m Trial 60 finished with value: 0.3388459443642551 and parameters: {'lambda_l1': 2.7149470495833703, 'lambda_l2': 1.54374277129442e-08}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  90%|######### | 18/20 [1:41:12<11:31, 345.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1910]\tvalid_0's binary_logloss: 0.325146\tvalid_1's binary_logloss: 0.338846\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.353285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347683\tvalid_1's binary_logloss: 0.343198\n",
      "[200]\tvalid_0's binary_logloss: 0.344715\tvalid_1's binary_logloss: 0.341486\n",
      "[300]\tvalid_0's binary_logloss: 0.342785\tvalid_1's binary_logloss: 0.340784\n",
      "[400]\tvalid_0's binary_logloss: 0.341174\tvalid_1's binary_logloss: 0.340492\n",
      "[500]\tvalid_0's binary_logloss: 0.339726\tvalid_1's binary_logloss: 0.340267\n",
      "[600]\tvalid_0's binary_logloss: 0.338302\tvalid_1's binary_logloss: 0.339991\n",
      "[700]\tvalid_0's binary_logloss: 0.336993\tvalid_1's binary_logloss: 0.339933\n",
      "[800]\tvalid_0's binary_logloss: 0.335705\tvalid_1's binary_logloss: 0.339708\n",
      "[900]\tvalid_0's binary_logloss: 0.33446\tvalid_1's binary_logloss: 0.339652\n",
      "[1000]\tvalid_0's binary_logloss: 0.333266\tvalid_1's binary_logloss: 0.339553\n",
      "[1100]\tvalid_0's binary_logloss: 0.332124\tvalid_1's binary_logloss: 0.339589\n",
      "[1200]\tvalid_0's binary_logloss: 0.330941\tvalid_1's binary_logloss: 0.339505\n",
      "[1300]\tvalid_0's binary_logloss: 0.329822\tvalid_1's binary_logloss: 0.339457\n",
      "[1400]\tvalid_0's binary_logloss: 0.328684\tvalid_1's binary_logloss: 0.339391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621:  95%|#########5| 19/20 [1:46:37<05:39, 339.55s/it]\u001b[32m[I 2022-12-19 16:09:25,700]\u001b[0m Trial 61 finished with value: 0.33937606125053354 and parameters: {'lambda_l1': 0.10271231026666786, 'lambda_l2': 0.0003133385557278234}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621:  95%|#########5| 19/20 [1:46:37<05:39, 339.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.329359\tvalid_1's binary_logloss: 0.339376\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.355997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347618\tvalid_1's binary_logloss: 0.343156\n",
      "[200]\tvalid_0's binary_logloss: 0.344804\tvalid_1's binary_logloss: 0.341647\n",
      "[300]\tvalid_0's binary_logloss: 0.342842\tvalid_1's binary_logloss: 0.341058\n",
      "[400]\tvalid_0's binary_logloss: 0.341243\tvalid_1's binary_logloss: 0.3407\n",
      "[500]\tvalid_0's binary_logloss: 0.339762\tvalid_1's binary_logloss: 0.340387\n",
      "[600]\tvalid_0's binary_logloss: 0.338382\tvalid_1's binary_logloss: 0.340188\n",
      "[700]\tvalid_0's binary_logloss: 0.337044\tvalid_1's binary_logloss: 0.340085\n",
      "[800]\tvalid_0's binary_logloss: 0.335736\tvalid_1's binary_logloss: 0.339877\n",
      "[900]\tvalid_0's binary_logloss: 0.334438\tvalid_1's binary_logloss: 0.339782\n",
      "[1000]\tvalid_0's binary_logloss: 0.333227\tvalid_1's binary_logloss: 0.339668\n",
      "[1100]\tvalid_0's binary_logloss: 0.332081\tvalid_1's binary_logloss: 0.339692\n",
      "[1200]\tvalid_0's binary_logloss: 0.330909\tvalid_1's binary_logloss: 0.339613\n",
      "[1300]\tvalid_0's binary_logloss: 0.329771\tvalid_1's binary_logloss: 0.339576\n",
      "[1400]\tvalid_0's binary_logloss: 0.328659\tvalid_1's binary_logloss: 0.339508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.338621: 100%|##########| 20/20 [1:52:02<00:00, 335.09s/it]\u001b[32m[I 2022-12-19 16:14:50,374]\u001b[0m Trial 62 finished with value: 0.3394935665587471 and parameters: {'lambda_l1': 0.0014332379165227483, 'lambda_l2': 9.629987787135096e-06}. Best is trial 53 with value: 0.33862147976979545.\u001b[0m\n",
      "regularization_factors, val_score: 0.338621: 100%|##########| 20/20 [1:52:02<00:00, 336.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's binary_logloss: 0.32932\tvalid_1's binary_logloss: 0.339494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.338621:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.392985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347721\tvalid_1's binary_logloss: 0.343316\n",
      "[200]\tvalid_0's binary_logloss: 0.344676\tvalid_1's binary_logloss: 0.341375\n",
      "[300]\tvalid_0's binary_logloss: 0.342889\tvalid_1's binary_logloss: 0.340662\n",
      "[400]\tvalid_0's binary_logloss: 0.341497\tvalid_1's binary_logloss: 0.340187\n",
      "[500]\tvalid_0's binary_logloss: 0.340215\tvalid_1's binary_logloss: 0.339817\n",
      "[600]\tvalid_0's binary_logloss: 0.339026\tvalid_1's binary_logloss: 0.339552\n",
      "[700]\tvalid_0's binary_logloss: 0.337902\tvalid_1's binary_logloss: 0.339428\n",
      "[800]\tvalid_0's binary_logloss: 0.336843\tvalid_1's binary_logloss: 0.339185\n",
      "[900]\tvalid_0's binary_logloss: 0.335801\tvalid_1's binary_logloss: 0.339093\n",
      "[1000]\tvalid_0's binary_logloss: 0.334764\tvalid_1's binary_logloss: 0.338966\n",
      "[1100]\tvalid_0's binary_logloss: 0.333808\tvalid_1's binary_logloss: 0.338958\n",
      "[1200]\tvalid_0's binary_logloss: 0.332888\tvalid_1's binary_logloss: 0.338895\n",
      "[1300]\tvalid_0's binary_logloss: 0.331987\tvalid_1's binary_logloss: 0.338888\n",
      "[1400]\tvalid_0's binary_logloss: 0.331062\tvalid_1's binary_logloss: 0.338793\n",
      "[1500]\tvalid_0's binary_logloss: 0.330198\tvalid_1's binary_logloss: 0.338706\n",
      "[1600]\tvalid_0's binary_logloss: 0.329323\tvalid_1's binary_logloss: 0.338749\n",
      "[1700]\tvalid_0's binary_logloss: 0.328451\tvalid_1's binary_logloss: 0.338766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.338621:  20%|##        | 1/5 [06:34<26:16, 394.24s/it]\u001b[32m[I 2022-12-19 16:21:24,622]\u001b[0m Trial 63 finished with value: 0.3386652751071345 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.3386652751071345.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.338621:  20%|##        | 1/5 [06:34<26:16, 394.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.328858\tvalid_1's binary_logloss: 0.338665\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.400009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347703\tvalid_1's binary_logloss: 0.343277\n",
      "[200]\tvalid_0's binary_logloss: 0.34467\tvalid_1's binary_logloss: 0.341313\n",
      "[300]\tvalid_0's binary_logloss: 0.342925\tvalid_1's binary_logloss: 0.340689\n",
      "[400]\tvalid_0's binary_logloss: 0.34152\tvalid_1's binary_logloss: 0.340243\n",
      "[500]\tvalid_0's binary_logloss: 0.340284\tvalid_1's binary_logloss: 0.339906\n",
      "[600]\tvalid_0's binary_logloss: 0.339096\tvalid_1's binary_logloss: 0.339668\n",
      "[700]\tvalid_0's binary_logloss: 0.337951\tvalid_1's binary_logloss: 0.33952\n",
      "[800]\tvalid_0's binary_logloss: 0.336833\tvalid_1's binary_logloss: 0.339257\n",
      "[900]\tvalid_0's binary_logloss: 0.335802\tvalid_1's binary_logloss: 0.33917\n",
      "[1000]\tvalid_0's binary_logloss: 0.334743\tvalid_1's binary_logloss: 0.339011\n",
      "[1100]\tvalid_0's binary_logloss: 0.333812\tvalid_1's binary_logloss: 0.339035\n",
      "[1200]\tvalid_0's binary_logloss: 0.332868\tvalid_1's binary_logloss: 0.338944\n",
      "[1300]\tvalid_0's binary_logloss: 0.331941\tvalid_1's binary_logloss: 0.338876\n",
      "[1400]\tvalid_0's binary_logloss: 0.331011\tvalid_1's binary_logloss: 0.338798\n",
      "[1500]\tvalid_0's binary_logloss: 0.330136\tvalid_1's binary_logloss: 0.338711\n",
      "[1600]\tvalid_0's binary_logloss: 0.32927\tvalid_1's binary_logloss: 0.338746\n",
      "[1700]\tvalid_0's binary_logloss: 0.328398\tvalid_1's binary_logloss: 0.338756\n",
      "[1800]\tvalid_0's binary_logloss: 0.327553\tvalid_1's binary_logloss: 0.338681\n",
      "[1900]\tvalid_0's binary_logloss: 0.326698\tvalid_1's binary_logloss: 0.338668\n",
      "[2000]\tvalid_0's binary_logloss: 0.325903\tvalid_1's binary_logloss: 0.338692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.338608:  40%|####      | 2/5 [14:04<21:21, 427.30s/it]\u001b[32m[I 2022-12-19 16:28:55,067]\u001b[0m Trial 64 finished with value: 0.3386076649648047 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.3386076649648047.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.338608:  40%|####      | 2/5 [14:04<21:21, 427.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1910]\tvalid_0's binary_logloss: 0.326622\tvalid_1's binary_logloss: 0.338608\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.380672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347689\tvalid_1's binary_logloss: 0.343322\n",
      "[200]\tvalid_0's binary_logloss: 0.344724\tvalid_1's binary_logloss: 0.341407\n",
      "[300]\tvalid_0's binary_logloss: 0.342925\tvalid_1's binary_logloss: 0.340675\n",
      "[400]\tvalid_0's binary_logloss: 0.341499\tvalid_1's binary_logloss: 0.340275\n",
      "[500]\tvalid_0's binary_logloss: 0.340256\tvalid_1's binary_logloss: 0.339982\n",
      "[600]\tvalid_0's binary_logloss: 0.339017\tvalid_1's binary_logloss: 0.339639\n",
      "[700]\tvalid_0's binary_logloss: 0.337842\tvalid_1's binary_logloss: 0.339486\n",
      "[800]\tvalid_0's binary_logloss: 0.336765\tvalid_1's binary_logloss: 0.339272\n",
      "[900]\tvalid_0's binary_logloss: 0.335712\tvalid_1's binary_logloss: 0.339187\n",
      "[1000]\tvalid_0's binary_logloss: 0.334695\tvalid_1's binary_logloss: 0.339039\n",
      "[1100]\tvalid_0's binary_logloss: 0.333741\tvalid_1's binary_logloss: 0.339016\n",
      "[1200]\tvalid_0's binary_logloss: 0.332785\tvalid_1's binary_logloss: 0.338951\n",
      "[1300]\tvalid_0's binary_logloss: 0.331841\tvalid_1's binary_logloss: 0.338908\n",
      "[1400]\tvalid_0's binary_logloss: 0.330922\tvalid_1's binary_logloss: 0.338818\n",
      "[1500]\tvalid_0's binary_logloss: 0.330073\tvalid_1's binary_logloss: 0.338733\n",
      "[1600]\tvalid_0's binary_logloss: 0.329222\tvalid_1's binary_logloss: 0.338775\n",
      "[1700]\tvalid_0's binary_logloss: 0.328355\tvalid_1's binary_logloss: 0.338799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.338608:  60%|######    | 3/5 [21:03<14:06, 423.30s/it]\u001b[32m[I 2022-12-19 16:35:53,674]\u001b[0m Trial 65 finished with value: 0.3386953436282283 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.3386076649648047.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.338608:  60%|######    | 3/5 [21:03<14:06, 423.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.328781\tvalid_1's binary_logloss: 0.338695\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.351836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347703\tvalid_1's binary_logloss: 0.343277\n",
      "[200]\tvalid_0's binary_logloss: 0.344654\tvalid_1's binary_logloss: 0.341272\n",
      "[300]\tvalid_0's binary_logloss: 0.342923\tvalid_1's binary_logloss: 0.340639\n",
      "[400]\tvalid_0's binary_logloss: 0.341488\tvalid_1's binary_logloss: 0.34021\n",
      "[500]\tvalid_0's binary_logloss: 0.340251\tvalid_1's binary_logloss: 0.339897\n",
      "[600]\tvalid_0's binary_logloss: 0.33906\tvalid_1's binary_logloss: 0.339673\n",
      "[700]\tvalid_0's binary_logloss: 0.337887\tvalid_1's binary_logloss: 0.339482\n",
      "[800]\tvalid_0's binary_logloss: 0.336815\tvalid_1's binary_logloss: 0.339282\n",
      "[900]\tvalid_0's binary_logloss: 0.335785\tvalid_1's binary_logloss: 0.339217\n",
      "[1000]\tvalid_0's binary_logloss: 0.334749\tvalid_1's binary_logloss: 0.339042\n",
      "[1100]\tvalid_0's binary_logloss: 0.333787\tvalid_1's binary_logloss: 0.339051\n",
      "[1200]\tvalid_0's binary_logloss: 0.33285\tvalid_1's binary_logloss: 0.338969\n",
      "[1300]\tvalid_0's binary_logloss: 0.331923\tvalid_1's binary_logloss: 0.33892\n",
      "[1400]\tvalid_0's binary_logloss: 0.331004\tvalid_1's binary_logloss: 0.338811\n",
      "[1500]\tvalid_0's binary_logloss: 0.330097\tvalid_1's binary_logloss: 0.338694\n",
      "[1600]\tvalid_0's binary_logloss: 0.329246\tvalid_1's binary_logloss: 0.338753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.338608:  80%|########  | 4/5 [27:37<06:51, 411.88s/it]\u001b[32m[I 2022-12-19 16:42:27,996]\u001b[0m Trial 66 finished with value: 0.3386796688734146 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.3386076649648047.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.338608:  80%|########  | 4/5 [27:37<06:51, 411.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1556]\tvalid_0's binary_logloss: 0.32961\tvalid_1's binary_logloss: 0.33868\n",
      "[LightGBM] [Info] Number of positive: 2634664, number of negative: 2634664\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.511492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11905\n",
      "[LightGBM] [Info] Number of data points in the train set: 5269328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.347703\tvalid_1's binary_logloss: 0.343277\n",
      "[200]\tvalid_0's binary_logloss: 0.34467\tvalid_1's binary_logloss: 0.341313\n",
      "[300]\tvalid_0's binary_logloss: 0.342912\tvalid_1's binary_logloss: 0.340708\n",
      "[400]\tvalid_0's binary_logloss: 0.341508\tvalid_1's binary_logloss: 0.340271\n",
      "[500]\tvalid_0's binary_logloss: 0.340242\tvalid_1's binary_logloss: 0.33994\n",
      "[600]\tvalid_0's binary_logloss: 0.33907\tvalid_1's binary_logloss: 0.339718\n",
      "[700]\tvalid_0's binary_logloss: 0.337952\tvalid_1's binary_logloss: 0.339626\n",
      "[800]\tvalid_0's binary_logloss: 0.336827\tvalid_1's binary_logloss: 0.339358\n",
      "[900]\tvalid_0's binary_logloss: 0.33578\tvalid_1's binary_logloss: 0.339233\n",
      "[1000]\tvalid_0's binary_logloss: 0.334755\tvalid_1's binary_logloss: 0.339081\n",
      "[1100]\tvalid_0's binary_logloss: 0.333791\tvalid_1's binary_logloss: 0.339085\n",
      "[1200]\tvalid_0's binary_logloss: 0.332883\tvalid_1's binary_logloss: 0.339016\n",
      "[1300]\tvalid_0's binary_logloss: 0.33195\tvalid_1's binary_logloss: 0.338948\n",
      "[1400]\tvalid_0's binary_logloss: 0.331043\tvalid_1's binary_logloss: 0.338875\n",
      "[1500]\tvalid_0's binary_logloss: 0.33014\tvalid_1's binary_logloss: 0.338779\n",
      "[1600]\tvalid_0's binary_logloss: 0.329267\tvalid_1's binary_logloss: 0.338805\n",
      "[1700]\tvalid_0's binary_logloss: 0.328394\tvalid_1's binary_logloss: 0.33882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.338608: 100%|##########| 5/5 [34:20<00:00, 408.67s/it]\u001b[32m[I 2022-12-19 16:49:10,979]\u001b[0m Trial 67 finished with value: 0.3387135186349279 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.3386076649648047.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.338608: 100%|##########| 5/5 [34:20<00:00, 412.12s/it]\n",
      "5:55:11.505201 \t clicks best_params\n",
      "5:55:11.506722 \t {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 5.485903737168179, 'lambda_l2': 0.005594683492536064, 'num_leaves': 79, 'feature_fraction': 0.552, 'bagging_fraction': 0.9295272232672004, 'bagging_freq': 2, 'min_child_samples': 10, 'num_iterations': 2000000, 'early_stopping_round': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.328802\tvalid_1's binary_logloss: 0.338714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 16:49:15,900]\u001b[0m A new study created in memory with name: no-name-2ecae3c2-4870-4f5a-a1d2-b696a6651ec8\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.432371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.326947\tvalid_1's binary_logloss: 0.319746\n",
      "[200]\tvalid_0's binary_logloss: 0.321986\tvalid_1's binary_logloss: 0.316572\n",
      "[300]\tvalid_0's binary_logloss: 0.31928\tvalid_1's binary_logloss: 0.315636\n",
      "[400]\tvalid_0's binary_logloss: 0.317237\tvalid_1's binary_logloss: 0.315284\n",
      "[500]\tvalid_0's binary_logloss: 0.315298\tvalid_1's binary_logloss: 0.315082\n",
      "[600]\tvalid_0's binary_logloss: 0.313466\tvalid_1's binary_logloss: 0.314871\n",
      "[700]\tvalid_0's binary_logloss: 0.311778\tvalid_1's binary_logloss: 0.31467\n",
      "[800]\tvalid_0's binary_logloss: 0.310155\tvalid_1's binary_logloss: 0.314564\n",
      "[900]\tvalid_0's binary_logloss: 0.308659\tvalid_1's binary_logloss: 0.314434\n",
      "[1000]\tvalid_0's binary_logloss: 0.307219\tvalid_1's binary_logloss: 0.314439\n",
      "[1100]\tvalid_0's binary_logloss: 0.305829\tvalid_1's binary_logloss: 0.314439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314416:  14%|#4        | 1/7 [01:30<09:01, 90.32s/it]\u001b[32m[I 2022-12-19 16:50:46,228]\u001b[0m Trial 0 finished with value: 0.3144164082736987 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.3144164082736987.\u001b[0m\n",
      "feature_fraction, val_score: 0.314416:  14%|#4        | 1/7 [01:30<09:01, 90.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1010]\tvalid_0's binary_logloss: 0.307072\tvalid_1's binary_logloss: 0.314416\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.352947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.327552\tvalid_1's binary_logloss: 0.320038\n",
      "[200]\tvalid_0's binary_logloss: 0.322306\tvalid_1's binary_logloss: 0.316848\n",
      "[300]\tvalid_0's binary_logloss: 0.319781\tvalid_1's binary_logloss: 0.316017\n",
      "[400]\tvalid_0's binary_logloss: 0.317635\tvalid_1's binary_logloss: 0.3155\n",
      "[500]\tvalid_0's binary_logloss: 0.315811\tvalid_1's binary_logloss: 0.315224\n",
      "[600]\tvalid_0's binary_logloss: 0.31401\tvalid_1's binary_logloss: 0.314996\n",
      "[700]\tvalid_0's binary_logloss: 0.312426\tvalid_1's binary_logloss: 0.314819\n",
      "[800]\tvalid_0's binary_logloss: 0.310836\tvalid_1's binary_logloss: 0.314717\n",
      "[900]\tvalid_0's binary_logloss: 0.309314\tvalid_1's binary_logloss: 0.314654\n",
      "[1000]\tvalid_0's binary_logloss: 0.307851\tvalid_1's binary_logloss: 0.314581\n",
      "[1100]\tvalid_0's binary_logloss: 0.306401\tvalid_1's binary_logloss: 0.314541\n",
      "[1200]\tvalid_0's binary_logloss: 0.305111\tvalid_1's binary_logloss: 0.314549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314416:  29%|##8       | 2/7 [03:06<07:49, 93.86s/it]\u001b[32m[I 2022-12-19 16:52:22,559]\u001b[0m Trial 1 finished with value: 0.3145131462359138 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.3144164082736987.\u001b[0m\n",
      "feature_fraction, val_score: 0.314416:  29%|##8       | 2/7 [03:06<07:49, 93.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1125]\tvalid_0's binary_logloss: 0.306056\tvalid_1's binary_logloss: 0.314513\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.328591\tvalid_1's binary_logloss: 0.320877\n",
      "[200]\tvalid_0's binary_logloss: 0.322814\tvalid_1's binary_logloss: 0.317102\n",
      "[300]\tvalid_0's binary_logloss: 0.320329\tvalid_1's binary_logloss: 0.316161\n",
      "[400]\tvalid_0's binary_logloss: 0.318254\tvalid_1's binary_logloss: 0.315656\n",
      "[500]\tvalid_0's binary_logloss: 0.316353\tvalid_1's binary_logloss: 0.315275\n",
      "[600]\tvalid_0's binary_logloss: 0.314679\tvalid_1's binary_logloss: 0.315011\n",
      "[700]\tvalid_0's binary_logloss: 0.313137\tvalid_1's binary_logloss: 0.31477\n",
      "[800]\tvalid_0's binary_logloss: 0.311658\tvalid_1's binary_logloss: 0.314664\n",
      "[900]\tvalid_0's binary_logloss: 0.310197\tvalid_1's binary_logloss: 0.314595\n",
      "[1000]\tvalid_0's binary_logloss: 0.308814\tvalid_1's binary_logloss: 0.314503\n",
      "[1100]\tvalid_0's binary_logloss: 0.3075\tvalid_1's binary_logloss: 0.314431\n",
      "[1200]\tvalid_0's binary_logloss: 0.306177\tvalid_1's binary_logloss: 0.314374\n",
      "[1300]\tvalid_0's binary_logloss: 0.304799\tvalid_1's binary_logloss: 0.314345\n",
      "[1400]\tvalid_0's binary_logloss: 0.303534\tvalid_1's binary_logloss: 0.314327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314306:  43%|####2     | 3/7 [05:00<06:51, 102.98s/it]\u001b[32m[I 2022-12-19 16:54:16,390]\u001b[0m Trial 2 finished with value: 0.31430566955697115 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.31430566955697115.\u001b[0m\n",
      "feature_fraction, val_score: 0.314306:  43%|####2     | 3/7 [05:00<06:51, 102.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1379]\tvalid_0's binary_logloss: 0.303788\tvalid_1's binary_logloss: 0.314306\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.376601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.327406\tvalid_1's binary_logloss: 0.320046\n",
      "[200]\tvalid_0's binary_logloss: 0.322271\tvalid_1's binary_logloss: 0.316912\n",
      "[300]\tvalid_0's binary_logloss: 0.319661\tvalid_1's binary_logloss: 0.316021\n",
      "[400]\tvalid_0's binary_logloss: 0.317551\tvalid_1's binary_logloss: 0.315613\n",
      "[500]\tvalid_0's binary_logloss: 0.315668\tvalid_1's binary_logloss: 0.315319\n",
      "[600]\tvalid_0's binary_logloss: 0.313919\tvalid_1's binary_logloss: 0.315114\n",
      "[700]\tvalid_0's binary_logloss: 0.312208\tvalid_1's binary_logloss: 0.314905\n",
      "[800]\tvalid_0's binary_logloss: 0.310615\tvalid_1's binary_logloss: 0.314805\n",
      "[900]\tvalid_0's binary_logloss: 0.309116\tvalid_1's binary_logloss: 0.314697\n",
      "[1000]\tvalid_0's binary_logloss: 0.307686\tvalid_1's binary_logloss: 0.31464\n",
      "[1100]\tvalid_0's binary_logloss: 0.306171\tvalid_1's binary_logloss: 0.314585\n",
      "[1200]\tvalid_0's binary_logloss: 0.304657\tvalid_1's binary_logloss: 0.314572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314306:  57%|#####7    | 4/7 [06:43<05:09, 103.16s/it]\u001b[32m[I 2022-12-19 16:55:59,825]\u001b[0m Trial 3 finished with value: 0.31455689243586815 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.31430566955697115.\u001b[0m\n",
      "feature_fraction, val_score: 0.314306:  57%|#####7    | 4/7 [06:43<05:09, 103.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1151]\tvalid_0's binary_logloss: 0.305395\tvalid_1's binary_logloss: 0.314557\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.326791\tvalid_1's binary_logloss: 0.319552\n",
      "[200]\tvalid_0's binary_logloss: 0.321858\tvalid_1's binary_logloss: 0.31668\n",
      "[300]\tvalid_0's binary_logloss: 0.319337\tvalid_1's binary_logloss: 0.315872\n",
      "[400]\tvalid_0's binary_logloss: 0.317204\tvalid_1's binary_logloss: 0.315454\n",
      "[500]\tvalid_0's binary_logloss: 0.315266\tvalid_1's binary_logloss: 0.315159\n",
      "[600]\tvalid_0's binary_logloss: 0.313407\tvalid_1's binary_logloss: 0.314897\n",
      "[700]\tvalid_0's binary_logloss: 0.311673\tvalid_1's binary_logloss: 0.314664\n",
      "[800]\tvalid_0's binary_logloss: 0.310011\tvalid_1's binary_logloss: 0.31464\n",
      "[900]\tvalid_0's binary_logloss: 0.308503\tvalid_1's binary_logloss: 0.314536\n",
      "[1000]\tvalid_0's binary_logloss: 0.307017\tvalid_1's binary_logloss: 0.314478\n",
      "[1100]\tvalid_0's binary_logloss: 0.305494\tvalid_1's binary_logloss: 0.314406\n",
      "[1200]\tvalid_0's binary_logloss: 0.304013\tvalid_1's binary_logloss: 0.314409\n",
      "Early stopping, best iteration is:\n",
      "[1104]\tvalid_0's binary_logloss: 0.305417\tvalid_1's binary_logloss: 0.314402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314306:  71%|#######1  | 5/7 [08:11<03:14, 97.38s/it] \u001b[32m[I 2022-12-19 16:57:26,950]\u001b[0m Trial 4 finished with value: 0.31440178247419576 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.31430566955697115.\u001b[0m\n",
      "feature_fraction, val_score: 0.314306:  71%|#######1  | 5/7 [08:11<03:14, 97.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.327799\tvalid_1's binary_logloss: 0.320351\n",
      "[200]\tvalid_0's binary_logloss: 0.322398\tvalid_1's binary_logloss: 0.316819\n",
      "[300]\tvalid_0's binary_logloss: 0.319901\tvalid_1's binary_logloss: 0.315961\n",
      "[400]\tvalid_0's binary_logloss: 0.31788\tvalid_1's binary_logloss: 0.315523\n",
      "[500]\tvalid_0's binary_logloss: 0.316036\tvalid_1's binary_logloss: 0.3152\n",
      "[600]\tvalid_0's binary_logloss: 0.314274\tvalid_1's binary_logloss: 0.314974\n",
      "[700]\tvalid_0's binary_logloss: 0.312711\tvalid_1's binary_logloss: 0.314814\n",
      "[800]\tvalid_0's binary_logloss: 0.311186\tvalid_1's binary_logloss: 0.314624\n",
      "[900]\tvalid_0's binary_logloss: 0.309722\tvalid_1's binary_logloss: 0.314618\n",
      "[1000]\tvalid_0's binary_logloss: 0.308324\tvalid_1's binary_logloss: 0.31457\n",
      "[1100]\tvalid_0's binary_logloss: 0.30695\tvalid_1's binary_logloss: 0.314533\n",
      "[1200]\tvalid_0's binary_logloss: 0.305603\tvalid_1's binary_logloss: 0.314524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314306:  86%|########5 | 6/7 [09:54<01:39, 99.31s/it]\u001b[32m[I 2022-12-19 16:59:10,021]\u001b[0m Trial 5 finished with value: 0.3144906620249064 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.31430566955697115.\u001b[0m\n",
      "feature_fraction, val_score: 0.314306:  86%|########5 | 6/7 [09:54<01:39, 99.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1166]\tvalid_0's binary_logloss: 0.306037\tvalid_1's binary_logloss: 0.314491\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.326889\tvalid_1's binary_logloss: 0.319675\n",
      "[200]\tvalid_0's binary_logloss: 0.321894\tvalid_1's binary_logloss: 0.316624\n",
      "[300]\tvalid_0's binary_logloss: 0.3193\tvalid_1's binary_logloss: 0.315855\n",
      "[400]\tvalid_0's binary_logloss: 0.31712\tvalid_1's binary_logloss: 0.315424\n",
      "[500]\tvalid_0's binary_logloss: 0.315222\tvalid_1's binary_logloss: 0.315184\n",
      "[600]\tvalid_0's binary_logloss: 0.31325\tvalid_1's binary_logloss: 0.314975\n",
      "[700]\tvalid_0's binary_logloss: 0.311547\tvalid_1's binary_logloss: 0.314863\n",
      "[800]\tvalid_0's binary_logloss: 0.309908\tvalid_1's binary_logloss: 0.314734\n",
      "[900]\tvalid_0's binary_logloss: 0.308345\tvalid_1's binary_logloss: 0.314706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.314306: 100%|##########| 7/7 [11:19<00:00, 94.64s/it]\u001b[32m[I 2022-12-19 17:00:35,048]\u001b[0m Trial 6 finished with value: 0.31466879894515803 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.31430566955697115.\u001b[0m\n",
      "feature_fraction, val_score: 0.314306: 100%|##########| 7/7 [11:19<00:00, 97.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[843]\tvalid_0's binary_logloss: 0.309169\tvalid_1's binary_logloss: 0.314669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.314306:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.323777\tvalid_1's binary_logloss: 0.317887\n",
      "[200]\tvalid_0's binary_logloss: 0.31769\tvalid_1's binary_logloss: 0.315333\n",
      "[300]\tvalid_0's binary_logloss: 0.31409\tvalid_1's binary_logloss: 0.314807\n",
      "[400]\tvalid_0's binary_logloss: 0.310992\tvalid_1's binary_logloss: 0.314632\n",
      "[500]\tvalid_0's binary_logloss: 0.308028\tvalid_1's binary_logloss: 0.314599\n",
      "[600]\tvalid_0's binary_logloss: 0.305235\tvalid_1's binary_logloss: 0.31453\n",
      "[700]\tvalid_0's binary_logloss: 0.302595\tvalid_1's binary_logloss: 0.314538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.314306:   5%|5         | 1/20 [01:10<22:12, 70.11s/it]\u001b[32m[I 2022-12-19 17:01:45,163]\u001b[0m Trial 7 finished with value: 0.31447402738276703 and parameters: {'num_leaves': 64}. Best is trial 7 with value: 0.31447402738276703.\u001b[0m\n",
      "num_leaves, val_score: 0.314306:   5%|5         | 1/20 [01:10<22:12, 70.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[663]\tvalid_0's binary_logloss: 0.303512\tvalid_1's binary_logloss: 0.314474\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.315948\tvalid_1's binary_logloss: 0.315348\n",
      "[200]\tvalid_0's binary_logloss: 0.30597\tvalid_1's binary_logloss: 0.314176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.314128:  10%|#         | 2/20 [02:11<19:32, 65.13s/it]\u001b[32m[I 2022-12-19 17:02:46,805]\u001b[0m Trial 8 finished with value: 0.3141277286973473 and parameters: {'num_leaves': 176}. Best is trial 8 with value: 0.3141277286973473.\u001b[0m\n",
      "num_leaves, val_score: 0.314128:  10%|#         | 2/20 [02:11<19:32, 65.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's binary_logloss: 0.307596\tvalid_1's binary_logloss: 0.314128\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.337058\tvalid_1's binary_logloss: 0.326688\n",
      "[200]\tvalid_0's binary_logloss: 0.329968\tvalid_1's binary_logloss: 0.321536\n",
      "[300]\tvalid_0's binary_logloss: 0.327008\tvalid_1's binary_logloss: 0.319435\n",
      "[400]\tvalid_0's binary_logloss: 0.325263\tvalid_1's binary_logloss: 0.318297\n",
      "[500]\tvalid_0's binary_logloss: 0.324013\tvalid_1's binary_logloss: 0.317561\n",
      "[600]\tvalid_0's binary_logloss: 0.322782\tvalid_1's binary_logloss: 0.31688\n",
      "[700]\tvalid_0's binary_logloss: 0.321889\tvalid_1's binary_logloss: 0.316528\n",
      "[800]\tvalid_0's binary_logloss: 0.320956\tvalid_1's binary_logloss: 0.316145\n",
      "[900]\tvalid_0's binary_logloss: 0.320209\tvalid_1's binary_logloss: 0.315862\n",
      "[1000]\tvalid_0's binary_logloss: 0.319397\tvalid_1's binary_logloss: 0.315584\n",
      "[1100]\tvalid_0's binary_logloss: 0.318714\tvalid_1's binary_logloss: 0.315386\n",
      "[1200]\tvalid_0's binary_logloss: 0.318057\tvalid_1's binary_logloss: 0.315251\n",
      "[1300]\tvalid_0's binary_logloss: 0.317418\tvalid_1's binary_logloss: 0.315104\n",
      "[1400]\tvalid_0's binary_logloss: 0.316748\tvalid_1's binary_logloss: 0.314988\n",
      "[1500]\tvalid_0's binary_logloss: 0.316189\tvalid_1's binary_logloss: 0.314869\n",
      "[1600]\tvalid_0's binary_logloss: 0.315624\tvalid_1's binary_logloss: 0.314723\n",
      "[1700]\tvalid_0's binary_logloss: 0.315104\tvalid_1's binary_logloss: 0.314637\n",
      "[1800]\tvalid_0's binary_logloss: 0.314526\tvalid_1's binary_logloss: 0.314544\n",
      "[1900]\tvalid_0's binary_logloss: 0.314036\tvalid_1's binary_logloss: 0.314488\n",
      "[2000]\tvalid_0's binary_logloss: 0.313499\tvalid_1's binary_logloss: 0.314452\n",
      "[2100]\tvalid_0's binary_logloss: 0.313022\tvalid_1's binary_logloss: 0.31442\n",
      "[2200]\tvalid_0's binary_logloss: 0.312556\tvalid_1's binary_logloss: 0.31439\n",
      "[2300]\tvalid_0's binary_logloss: 0.312053\tvalid_1's binary_logloss: 0.314306\n",
      "[2400]\tvalid_0's binary_logloss: 0.311551\tvalid_1's binary_logloss: 0.31426\n",
      "[2500]\tvalid_0's binary_logloss: 0.311087\tvalid_1's binary_logloss: 0.314215\n",
      "[2600]\tvalid_0's binary_logloss: 0.310602\tvalid_1's binary_logloss: 0.314191\n",
      "[2700]\tvalid_0's binary_logloss: 0.310156\tvalid_1's binary_logloss: 0.314175\n",
      "[2800]\tvalid_0's binary_logloss: 0.309716\tvalid_1's binary_logloss: 0.31416\n",
      "[2900]\tvalid_0's binary_logloss: 0.309285\tvalid_1's binary_logloss: 0.314146\n",
      "[3000]\tvalid_0's binary_logloss: 0.308829\tvalid_1's binary_logloss: 0.314135\n",
      "[3100]\tvalid_0's binary_logloss: 0.308405\tvalid_1's binary_logloss: 0.314132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.314127:  15%|#5        | 3/20 [05:47<37:57, 133.97s/it]\u001b[32m[I 2022-12-19 17:06:22,696]\u001b[0m Trial 9 finished with value: 0.31412721920445064 and parameters: {'num_leaves': 12}. Best is trial 9 with value: 0.31412721920445064.\u001b[0m\n",
      "num_leaves, val_score: 0.314127:  15%|#5        | 3/20 [05:47<37:57, 133.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3051]\tvalid_0's binary_logloss: 0.308621\tvalid_1's binary_logloss: 0.314127\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31202\tvalid_1's binary_logloss: 0.314871\n",
      "[200]\tvalid_0's binary_logloss: 0.299279\tvalid_1's binary_logloss: 0.314215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  20%|##        | 4/20 [06:46<27:48, 104.27s/it]\u001b[32m[I 2022-12-19 17:07:21,446]\u001b[0m Trial 10 finished with value: 0.31396841490589167 and parameters: {'num_leaves': 252}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  20%|##        | 4/20 [06:46<27:48, 104.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.303725\tvalid_1's binary_logloss: 0.313968\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.313101\tvalid_1's binary_logloss: 0.314958\n",
      "[200]\tvalid_0's binary_logloss: 0.301237\tvalid_1's binary_logloss: 0.314233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  25%|##5       | 5/20 [07:47<22:11, 88.74s/it] \u001b[32m[I 2022-12-19 17:08:22,644]\u001b[0m Trial 11 finished with value: 0.3141384989370696 and parameters: {'num_leaves': 230}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  25%|##5       | 5/20 [07:47<22:11, 88.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's binary_logloss: 0.303559\tvalid_1's binary_logloss: 0.314138\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.317029\tvalid_1's binary_logloss: 0.315626\n",
      "[200]\tvalid_0's binary_logloss: 0.307761\tvalid_1's binary_logloss: 0.314389\n",
      "[300]\tvalid_0's binary_logloss: 0.301002\tvalid_1's binary_logloss: 0.314508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  30%|###       | 6/20 [08:48<18:28, 79.18s/it]\u001b[32m[I 2022-12-19 17:09:23,272]\u001b[0m Trial 12 finished with value: 0.3143453002688023 and parameters: {'num_leaves': 158}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  30%|###       | 6/20 [08:48<18:28, 79.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's binary_logloss: 0.306505\tvalid_1's binary_logloss: 0.314345\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312957\tvalid_1's binary_logloss: 0.314948\n",
      "[200]\tvalid_0's binary_logloss: 0.301015\tvalid_1's binary_logloss: 0.314371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  35%|###5      | 7/20 [09:46<15:40, 72.32s/it]\u001b[32m[I 2022-12-19 17:10:21,477]\u001b[0m Trial 13 finished with value: 0.31412658259936654 and parameters: {'num_leaves': 232}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  35%|###5      | 7/20 [09:46<15:40, 72.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.306011\tvalid_1's binary_logloss: 0.314127\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.319929\tvalid_1's binary_logloss: 0.316461\n",
      "[200]\tvalid_0's binary_logloss: 0.31232\tvalid_1's binary_logloss: 0.314615\n",
      "[300]\tvalid_0's binary_logloss: 0.307201\tvalid_1's binary_logloss: 0.314565\n",
      "[400]\tvalid_0's binary_logloss: 0.302375\tvalid_1's binary_logloss: 0.314473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  40%|####      | 8/20 [10:59<14:32, 72.72s/it]\u001b[32m[I 2022-12-19 17:11:35,040]\u001b[0m Trial 14 finished with value: 0.3144439055764002 and parameters: {'num_leaves': 111}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  40%|####      | 8/20 [10:59<14:32, 72.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's binary_logloss: 0.302733\tvalid_1's binary_logloss: 0.314444\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314833\tvalid_1's binary_logloss: 0.315158\n",
      "[200]\tvalid_0's binary_logloss: 0.304115\tvalid_1's binary_logloss: 0.314155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  45%|####5     | 9/20 [11:50<12:04, 65.82s/it]\u001b[32m[I 2022-12-19 17:12:25,692]\u001b[0m Trial 15 finished with value: 0.31409099091506676 and parameters: {'num_leaves': 197}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  45%|####5     | 9/20 [11:50<12:04, 65.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.305467\tvalid_1's binary_logloss: 0.314091\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31246\tvalid_1's binary_logloss: 0.314882\n",
      "[200]\tvalid_0's binary_logloss: 0.299878\tvalid_1's binary_logloss: 0.314192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  50%|#####     | 10/20 [12:55<10:55, 65.58s/it]\u001b[32m[I 2022-12-19 17:13:30,722]\u001b[0m Trial 16 finished with value: 0.31411910207219984 and parameters: {'num_leaves': 242}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  50%|#####     | 10/20 [12:55<10:55, 65.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.301902\tvalid_1's binary_logloss: 0.314119\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.320187\tvalid_1's binary_logloss: 0.316407\n",
      "[200]\tvalid_0's binary_logloss: 0.312772\tvalid_1's binary_logloss: 0.314585\n",
      "[300]\tvalid_0's binary_logloss: 0.307503\tvalid_1's binary_logloss: 0.314386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  55%|#####5    | 11/20 [13:58<09:43, 64.78s/it]\u001b[32m[I 2022-12-19 17:14:33,705]\u001b[0m Trial 17 finished with value: 0.31438393612995874 and parameters: {'num_leaves': 108}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  55%|#####5    | 11/20 [13:58<09:43, 64.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[299]\tvalid_0's binary_logloss: 0.307535\tvalid_1's binary_logloss: 0.314384\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.315199\tvalid_1's binary_logloss: 0.31528\n",
      "[200]\tvalid_0's binary_logloss: 0.304574\tvalid_1's binary_logloss: 0.314426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  60%|######    | 12/20 [14:51<08:08, 61.12s/it]\u001b[32m[I 2022-12-19 17:15:26,441]\u001b[0m Trial 18 finished with value: 0.31425464607348313 and parameters: {'num_leaves': 191}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  60%|######    | 12/20 [14:51<08:08, 61.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.308505\tvalid_1's binary_logloss: 0.314255\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314421\tvalid_1's binary_logloss: 0.315093\n",
      "[200]\tvalid_0's binary_logloss: 0.303407\tvalid_1's binary_logloss: 0.314293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  65%|######5   | 13/20 [15:55<07:13, 61.93s/it]\u001b[32m[I 2022-12-19 17:16:30,229]\u001b[0m Trial 19 finished with value: 0.3142563945104781 and parameters: {'num_leaves': 204}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  65%|######5   | 13/20 [15:55<07:13, 61.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.304421\tvalid_1's binary_logloss: 0.314256\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311894\tvalid_1's binary_logloss: 0.314698\n",
      "[200]\tvalid_0's binary_logloss: 0.299169\tvalid_1's binary_logloss: 0.314222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  70%|#######   | 14/20 [16:56<06:10, 61.74s/it]\u001b[32m[I 2022-12-19 17:17:31,540]\u001b[0m Trial 20 finished with value: 0.31397664860556423 and parameters: {'num_leaves': 253}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  70%|#######   | 14/20 [16:56<06:10, 61.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's binary_logloss: 0.303502\tvalid_1's binary_logloss: 0.313977\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31202\tvalid_1's binary_logloss: 0.314871\n",
      "[200]\tvalid_0's binary_logloss: 0.299279\tvalid_1's binary_logloss: 0.314215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  75%|#######5  | 15/20 [17:57<05:07, 61.41s/it]\u001b[32m[I 2022-12-19 17:18:32,199]\u001b[0m Trial 21 finished with value: 0.31396841490589167 and parameters: {'num_leaves': 252}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  75%|#######5  | 15/20 [17:57<05:07, 61.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.303725\tvalid_1's binary_logloss: 0.313968\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.317909\tvalid_1's binary_logloss: 0.31571\n",
      "[200]\tvalid_0's binary_logloss: 0.30914\tvalid_1's binary_logloss: 0.314328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  80%|########  | 16/20 [18:54<04:01, 60.29s/it]\u001b[32m[I 2022-12-19 17:19:29,890]\u001b[0m Trial 22 finished with value: 0.3143201953153392 and parameters: {'num_leaves': 143}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  80%|########  | 16/20 [18:54<04:01, 60.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.309281\tvalid_1's binary_logloss: 0.31432\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.313648\tvalid_1's binary_logloss: 0.315089\n",
      "[200]\tvalid_0's binary_logloss: 0.302126\tvalid_1's binary_logloss: 0.314377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  85%|########5 | 17/20 [19:56<03:02, 60.79s/it]\u001b[32m[I 2022-12-19 17:20:31,850]\u001b[0m Trial 23 finished with value: 0.31425117254183604 and parameters: {'num_leaves': 218}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  85%|########5 | 17/20 [19:56<03:02, 60.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.306218\tvalid_1's binary_logloss: 0.314251\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311806\tvalid_1's binary_logloss: 0.314847\n",
      "[200]\tvalid_0's binary_logloss: 0.299027\tvalid_1's binary_logloss: 0.314367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  90%|######### | 18/20 [21:05<02:06, 63.24s/it]\u001b[32m[I 2022-12-19 17:21:40,785]\u001b[0m Trial 24 finished with value: 0.31406067596053894 and parameters: {'num_leaves': 255}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  90%|######### | 18/20 [21:05<02:06, 63.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.302531\tvalid_1's binary_logloss: 0.314061\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.324283\tvalid_1's binary_logloss: 0.318113\n",
      "[200]\tvalid_0's binary_logloss: 0.318433\tvalid_1's binary_logloss: 0.315489\n",
      "[300]\tvalid_0's binary_logloss: 0.314894\tvalid_1's binary_logloss: 0.314944\n",
      "[400]\tvalid_0's binary_logloss: 0.311924\tvalid_1's binary_logloss: 0.314711\n",
      "[500]\tvalid_0's binary_logloss: 0.309264\tvalid_1's binary_logloss: 0.314642\n",
      "[600]\tvalid_0's binary_logloss: 0.306528\tvalid_1's binary_logloss: 0.314601\n",
      "[700]\tvalid_0's binary_logloss: 0.304149\tvalid_1's binary_logloss: 0.314643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968:  95%|#########5| 19/20 [22:25<01:08, 68.12s/it]\u001b[32m[I 2022-12-19 17:23:00,263]\u001b[0m Trial 25 finished with value: 0.31457614697912734 and parameters: {'num_leaves': 59}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968:  95%|#########5| 19/20 [22:25<01:08, 68.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[621]\tvalid_0's binary_logloss: 0.306015\tvalid_1's binary_logloss: 0.314576\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.316367\tvalid_1's binary_logloss: 0.315534\n",
      "[200]\tvalid_0's binary_logloss: 0.306617\tvalid_1's binary_logloss: 0.314424\n",
      "[300]\tvalid_0's binary_logloss: 0.299165\tvalid_1's binary_logloss: 0.314548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.313968: 100%|##########| 20/20 [23:43<00:00, 71.03s/it]\u001b[32m[I 2022-12-19 17:24:18,070]\u001b[0m Trial 26 finished with value: 0.314391015678197 and parameters: {'num_leaves': 169}. Best is trial 10 with value: 0.31396841490589167.\u001b[0m\n",
      "num_leaves, val_score: 0.313968: 100%|##########| 20/20 [23:43<00:00, 71.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's binary_logloss: 0.301405\tvalid_1's binary_logloss: 0.314391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.361630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.313338\tvalid_1's binary_logloss: 0.316329\n",
      "[200]\tvalid_0's binary_logloss: 0.301328\tvalid_1's binary_logloss: 0.316121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  10%|#         | 1/10 [00:43<06:35, 43.91s/it]\u001b[32m[I 2022-12-19 17:25:01,981]\u001b[0m Trial 27 finished with value: 0.31521826443332607 and parameters: {'bagging_fraction': 0.40283835368904813, 'bagging_freq': 7}. Best is trial 27 with value: 0.31521826443332607.\u001b[0m\n",
      "bagging, val_score: 0.313968:  10%|#         | 1/10 [00:43<06:35, 43.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.306376\tvalid_1's binary_logloss: 0.315218\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312212\tvalid_1's binary_logloss: 0.314943\n",
      "[200]\tvalid_0's binary_logloss: 0.299236\tvalid_1's binary_logloss: 0.314222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  20%|##        | 2/10 [01:59<08:19, 62.41s/it]\u001b[32m[I 2022-12-19 17:26:17,340]\u001b[0m Trial 28 finished with value: 0.31421041863915816 and parameters: {'bagging_fraction': 0.7893463661461013, 'bagging_freq': 3}. Best is trial 28 with value: 0.31421041863915816.\u001b[0m\n",
      "bagging, val_score: 0.313968:  20%|##        | 2/10 [01:59<08:19, 62.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's binary_logloss: 0.289083\tvalid_1's binary_logloss: 0.314898\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.299124\tvalid_1's binary_logloss: 0.31421\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312162\tvalid_1's binary_logloss: 0.314877\n",
      "[200]\tvalid_0's binary_logloss: 0.299359\tvalid_1's binary_logloss: 0.314163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  30%|###       | 3/10 [02:59<07:11, 61.63s/it]\u001b[32m[I 2022-12-19 17:27:18,048]\u001b[0m Trial 29 finished with value: 0.3141432101220969 and parameters: {'bagging_fraction': 0.8034219244810344, 'bagging_freq': 3}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  30%|###       | 3/10 [02:59<07:11, 61.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's binary_logloss: 0.289044\tvalid_1's binary_logloss: 0.314942\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.299255\tvalid_1's binary_logloss: 0.314143\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312176\tvalid_1's binary_logloss: 0.314945\n",
      "[200]\tvalid_0's binary_logloss: 0.299301\tvalid_1's binary_logloss: 0.314313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  40%|####      | 4/10 [03:51<05:46, 57.73s/it]\u001b[32m[I 2022-12-19 17:28:09,786]\u001b[0m Trial 30 finished with value: 0.31430376717062625 and parameters: {'bagging_fraction': 0.7689841271323192, 'bagging_freq': 3}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  40%|####      | 4/10 [03:51<05:46, 57.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's binary_logloss: 0.307485\tvalid_1's binary_logloss: 0.314304\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.313338\tvalid_1's binary_logloss: 0.316381\n",
      "[200]\tvalid_0's binary_logloss: 0.301111\tvalid_1's binary_logloss: 0.316014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  50%|#####     | 5/10 [04:48<04:47, 57.47s/it]\u001b[32m[I 2022-12-19 17:29:06,800]\u001b[0m Trial 31 finished with value: 0.3150672084589983 and parameters: {'bagging_fraction': 0.4189572502811205, 'bagging_freq': 7}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  50%|#####     | 5/10 [04:48<04:47, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.306353\tvalid_1's binary_logloss: 0.315067\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312166\tvalid_1's binary_logloss: 0.315218\n",
      "[200]\tvalid_0's binary_logloss: 0.299462\tvalid_1's binary_logloss: 0.314491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  60%|######    | 6/10 [05:59<04:07, 61.85s/it]\u001b[32m[I 2022-12-19 17:30:17,158]\u001b[0m Trial 32 finished with value: 0.31420204224895365 and parameters: {'bagging_fraction': 0.7996547181576673, 'bagging_freq': 5}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  60%|######    | 6/10 [05:59<04:07, 61.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.302872\tvalid_1's binary_logloss: 0.314202\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312346\tvalid_1's binary_logloss: 0.3155\n",
      "[200]\tvalid_0's binary_logloss: 0.299728\tvalid_1's binary_logloss: 0.315341\n",
      "[300]\tvalid_0's binary_logloss: 0.289503\tvalid_1's binary_logloss: 0.315467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  70%|#######   | 7/10 [07:04<03:08, 62.89s/it]\u001b[32m[I 2022-12-19 17:31:22,200]\u001b[0m Trial 33 finished with value: 0.31469318668553503 and parameters: {'bagging_fraction': 0.6633388863523648, 'bagging_freq': 7}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  70%|#######   | 7/10 [07:04<03:08, 62.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's binary_logloss: 0.295587\tvalid_1's binary_logloss: 0.314693\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31237\tvalid_1's binary_logloss: 0.315326\n",
      "[200]\tvalid_0's binary_logloss: 0.299495\tvalid_1's binary_logloss: 0.314667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  80%|########  | 8/10 [07:59<02:00, 60.40s/it]\u001b[32m[I 2022-12-19 17:32:17,271]\u001b[0m Trial 34 finished with value: 0.31459257711269445 and parameters: {'bagging_fraction': 0.7253368813069245, 'bagging_freq': 1}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  80%|########  | 8/10 [07:59<02:00, 60.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's binary_logloss: 0.302681\tvalid_1's binary_logloss: 0.314593\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312935\tvalid_1's binary_logloss: 0.315882\n",
      "[200]\tvalid_0's binary_logloss: 0.300438\tvalid_1's binary_logloss: 0.31567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968:  90%|######### | 9/10 [08:51<00:57, 57.78s/it]\u001b[32m[I 2022-12-19 17:33:09,296]\u001b[0m Trial 35 finished with value: 0.3150298730996116 and parameters: {'bagging_fraction': 0.5076292691856369, 'bagging_freq': 4}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968:  90%|######### | 9/10 [08:51<00:57, 57.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.307537\tvalid_1's binary_logloss: 0.31503\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312929\tvalid_1's binary_logloss: 0.316076\n",
      "[200]\tvalid_0's binary_logloss: 0.300619\tvalid_1's binary_logloss: 0.315803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.313968: 100%|##########| 10/10 [09:31<00:00, 52.39s/it]\u001b[32m[I 2022-12-19 17:33:49,617]\u001b[0m Trial 36 finished with value: 0.3151093184111438 and parameters: {'bagging_fraction': 0.46872073755459776, 'bagging_freq': 5}. Best is trial 29 with value: 0.3141432101220969.\u001b[0m\n",
      "bagging, val_score: 0.313968: 100%|##########| 10/10 [09:31<00:00, 57.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.303973\tvalid_1's binary_logloss: 0.315109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.313968:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.370814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311399\tvalid_1's binary_logloss: 0.314612\n",
      "[200]\tvalid_0's binary_logloss: 0.298456\tvalid_1's binary_logloss: 0.314352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.313968:  33%|###3      | 1/3 [01:01<02:03, 61.60s/it]\u001b[32m[I 2022-12-19 17:34:51,219]\u001b[0m Trial 37 finished with value: 0.314091775571245 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.314091775571245.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.313968:  33%|###3      | 1/3 [01:01<02:03, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.304495\tvalid_1's binary_logloss: 0.314092\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311449\tvalid_1's binary_logloss: 0.314681\n",
      "[200]\tvalid_0's binary_logloss: 0.29882\tvalid_1's binary_logloss: 0.314379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.313968:  67%|######6   | 2/3 [02:02<01:01, 61.26s/it]\u001b[32m[I 2022-12-19 17:35:52,243]\u001b[0m Trial 38 finished with value: 0.3140020277597182 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.3140020277597182.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.313968:  67%|######6   | 2/3 [02:02<01:01, 61.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.304618\tvalid_1's binary_logloss: 0.314002\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311784\tvalid_1's binary_logloss: 0.314814\n",
      "[200]\tvalid_0's binary_logloss: 0.299159\tvalid_1's binary_logloss: 0.314266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.313968: 100%|##########| 3/3 [03:03<00:00, 61.18s/it]\u001b[32m[I 2022-12-19 17:36:53,330]\u001b[0m Trial 39 finished with value: 0.3140772664029722 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 38 with value: 0.3140020277597182.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.313968: 100%|##########| 3/3 [03:03<00:00, 61.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.303511\tvalid_1's binary_logloss: 0.314077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313968:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.393872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311978\tvalid_1's binary_logloss: 0.314767\n",
      "[200]\tvalid_0's binary_logloss: 0.29924\tvalid_1's binary_logloss: 0.314155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313968:   5%|5         | 1/20 [00:59<18:53, 59.66s/it]\u001b[32m[I 2022-12-19 17:37:52,991]\u001b[0m Trial 40 finished with value: 0.3140661720399086 and parameters: {'lambda_l1': 0.0013716288306815751, 'lambda_l2': 1.5522076263713434e-07}. Best is trial 40 with value: 0.3140661720399086.\u001b[0m\n",
      "regularization_factors, val_score: 0.313968:   5%|5         | 1/20 [00:59<18:53, 59.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.304457\tvalid_1's binary_logloss: 0.314066\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311994\tvalid_1's binary_logloss: 0.314805\n",
      "[200]\tvalid_0's binary_logloss: 0.29931\tvalid_1's binary_logloss: 0.314202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313968:  10%|#         | 2/20 [02:01<18:16, 60.93s/it]\u001b[32m[I 2022-12-19 17:38:54,806]\u001b[0m Trial 41 finished with value: 0.3141077964983512 and parameters: {'lambda_l1': 0.0700056382082983, 'lambda_l2': 1.900880985026897e-07}. Best is trial 40 with value: 0.3140661720399086.\u001b[0m\n",
      "regularization_factors, val_score: 0.313968:  10%|#         | 2/20 [02:01<18:16, 60.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.304449\tvalid_1's binary_logloss: 0.314108\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312077\tvalid_1's binary_logloss: 0.314773\n",
      "[200]\tvalid_0's binary_logloss: 0.299338\tvalid_1's binary_logloss: 0.314006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313893:  15%|#5        | 3/20 [03:07<17:56, 63.35s/it]\u001b[32m[I 2022-12-19 17:40:01,046]\u001b[0m Trial 42 finished with value: 0.313893367279223 and parameters: {'lambda_l1': 0.39200219063722036, 'lambda_l2': 0.0001296038074930266}. Best is trial 42 with value: 0.313893367279223.\u001b[0m\n",
      "regularization_factors, val_score: 0.313893:  15%|#5        | 3/20 [03:07<17:56, 63.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.300487\tvalid_1's binary_logloss: 0.313893\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312413\tvalid_1's binary_logloss: 0.314788\n",
      "[200]\tvalid_0's binary_logloss: 0.300784\tvalid_1's binary_logloss: 0.313775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313762:  20%|##        | 4/20 [04:08<16:38, 62.41s/it]\u001b[32m[I 2022-12-19 17:41:02,022]\u001b[0m Trial 43 finished with value: 0.31376214896246907 and parameters: {'lambda_l1': 0.0006716922908906348, 'lambda_l2': 1.013161115887582}. Best is trial 43 with value: 0.31376214896246907.\u001b[0m\n",
      "regularization_factors, val_score: 0.313762:  20%|##        | 4/20 [04:08<16:38, 62.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.301066\tvalid_1's binary_logloss: 0.313762\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312037\tvalid_1's binary_logloss: 0.314825\n",
      "[200]\tvalid_0's binary_logloss: 0.299293\tvalid_1's binary_logloss: 0.31408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313762:  25%|##5       | 5/20 [05:05<15:04, 60.29s/it]\u001b[32m[I 2022-12-19 17:41:58,545]\u001b[0m Trial 44 finished with value: 0.3140030268582677 and parameters: {'lambda_l1': 0.009928937073206363, 'lambda_l2': 0.00616608493241032}. Best is trial 43 with value: 0.31376214896246907.\u001b[0m\n",
      "regularization_factors, val_score: 0.313762:  25%|##5       | 5/20 [05:05<15:04, 60.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.303904\tvalid_1's binary_logloss: 0.314003\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31202\tvalid_1's binary_logloss: 0.31487\n",
      "[200]\tvalid_0's binary_logloss: 0.299279\tvalid_1's binary_logloss: 0.314216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313762:  30%|###       | 6/20 [06:08<14:17, 61.28s/it]\u001b[32m[I 2022-12-19 17:43:01,752]\u001b[0m Trial 45 finished with value: 0.31396695309499484 and parameters: {'lambda_l1': 5.1843806260957353e-08, 'lambda_l2': 6.900146978683727e-08}. Best is trial 43 with value: 0.31376214896246907.\u001b[0m\n",
      "regularization_factors, val_score: 0.313762:  30%|###       | 6/20 [06:08<14:17, 61.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.303725\tvalid_1's binary_logloss: 0.313967\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31201\tvalid_1's binary_logloss: 0.31475\n",
      "[200]\tvalid_0's binary_logloss: 0.299374\tvalid_1's binary_logloss: 0.314203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.313762:  35%|###5      | 7/20 [07:19<13:59, 64.60s/it]\u001b[32m[I 2022-12-19 17:44:13,178]\u001b[0m Trial 46 finished with value: 0.31402846928630923 and parameters: {'lambda_l1': 0.1956434907221628, 'lambda_l2': 5.492595819809903e-08}. Best is trial 43 with value: 0.31376214896246907.\u001b[0m\n",
      "regularization_factors, val_score: 0.313762:  35%|###5      | 7/20 [07:19<13:59, 64.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's binary_logloss: 0.303778\tvalid_1's binary_logloss: 0.314028\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.313891\tvalid_1's binary_logloss: 0.314975\n",
      "[200]\tvalid_0's binary_logloss: 0.303582\tvalid_1's binary_logloss: 0.313343\n",
      "[300]\tvalid_0's binary_logloss: 0.296219\tvalid_1's binary_logloss: 0.312997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312997:  40%|####      | 8/20 [08:36<13:41, 68.47s/it]\u001b[32m[I 2022-12-19 17:45:29,932]\u001b[0m Trial 47 finished with value: 0.3129966608016809 and parameters: {'lambda_l1': 7.353231270905428, 'lambda_l2': 1.4215744803475422e-08}. Best is trial 47 with value: 0.3129966608016809.\u001b[0m\n",
      "regularization_factors, val_score: 0.312997:  40%|####      | 8/20 [08:36<13:41, 68.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's binary_logloss: 0.289689\tvalid_1's binary_logloss: 0.313192\n",
      "Early stopping, best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.296219\tvalid_1's binary_logloss: 0.312997\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31202\tvalid_1's binary_logloss: 0.314871\n",
      "[200]\tvalid_0's binary_logloss: 0.299279\tvalid_1's binary_logloss: 0.314217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312997:  45%|####5     | 9/20 [09:39<12:13, 66.68s/it]\u001b[32m[I 2022-12-19 17:46:32,683]\u001b[0m Trial 48 finished with value: 0.31396919629016956 and parameters: {'lambda_l1': 1.213888229966823e-08, 'lambda_l2': 4.758369516707276e-07}. Best is trial 47 with value: 0.3129966608016809.\u001b[0m\n",
      "regularization_factors, val_score: 0.312997:  45%|####5     | 9/20 [09:39<12:13, 66.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.303725\tvalid_1's binary_logloss: 0.313969\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.3128\tvalid_1's binary_logloss: 0.31469\n",
      "[200]\tvalid_0's binary_logloss: 0.30181\tvalid_1's binary_logloss: 0.313544\n",
      "[300]\tvalid_0's binary_logloss: 0.29329\tvalid_1's binary_logloss: 0.313384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312997:  50%|#####     | 10/20 [10:57<11:42, 70.25s/it]\u001b[32m[I 2022-12-19 17:47:50,910]\u001b[0m Trial 49 finished with value: 0.3133338696307463 and parameters: {'lambda_l1': 7.201250827221431e-08, 'lambda_l2': 3.6519821798098326}. Best is trial 47 with value: 0.3129966608016809.\u001b[0m\n",
      "regularization_factors, val_score: 0.312997:  50%|#####     | 10/20 [10:57<11:42, 70.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's binary_logloss: 0.295838\tvalid_1's binary_logloss: 0.313334\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31202\tvalid_1's binary_logloss: 0.314875\n",
      "[200]\tvalid_0's binary_logloss: 0.299279\tvalid_1's binary_logloss: 0.314218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312997:  55%|#####5    | 11/20 [11:45<09:31, 63.47s/it]\u001b[32m[I 2022-12-19 17:48:39,026]\u001b[0m Trial 50 finished with value: 0.31397168306542417 and parameters: {'lambda_l1': 4.390740638769894e-06, 'lambda_l2': 3.84875516774167e-05}. Best is trial 47 with value: 0.3129966608016809.\u001b[0m\n",
      "regularization_factors, val_score: 0.312997:  55%|#####5    | 11/20 [11:45<09:31, 63.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.303725\tvalid_1's binary_logloss: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.313292\tvalid_1's binary_logloss: 0.314766\n",
      "[200]\tvalid_0's binary_logloss: 0.302799\tvalid_1's binary_logloss: 0.313399\n",
      "[300]\tvalid_0's binary_logloss: 0.295407\tvalid_1's binary_logloss: 0.313225\n",
      "[400]\tvalid_0's binary_logloss: 0.288433\tvalid_1's binary_logloss: 0.313297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312997:  60%|######    | 12/20 [13:07<09:11, 68.91s/it]\u001b[32m[I 2022-12-19 17:50:00,380]\u001b[0m Trial 51 finished with value: 0.3131916773590166 and parameters: {'lambda_l1': 1.603070657539653e-05, 'lambda_l2': 9.876476938887235}. Best is trial 47 with value: 0.3129966608016809.\u001b[0m\n",
      "regularization_factors, val_score: 0.312997:  60%|######    | 12/20 [13:07<09:11, 68.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's binary_logloss: 0.29488\tvalid_1's binary_logloss: 0.313192\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311988\tvalid_1's binary_logloss: 0.314816\n",
      "[200]\tvalid_0's binary_logloss: 0.299121\tvalid_1's binary_logloss: 0.314118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312997:  65%|######5   | 13/20 [13:53<07:14, 62.10s/it]\u001b[32m[I 2022-12-19 17:50:46,795]\u001b[0m Trial 52 finished with value: 0.3140602399935975 and parameters: {'lambda_l1': 1.2815066043332124e-05, 'lambda_l2': 0.007709268969040953}. Best is trial 47 with value: 0.3129966608016809.\u001b[0m\n",
      "regularization_factors, val_score: 0.312997:  65%|######5   | 13/20 [13:53<07:14, 62.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.303832\tvalid_1's binary_logloss: 0.31406\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.3143\tvalid_1's binary_logloss: 0.315076\n",
      "[200]\tvalid_0's binary_logloss: 0.304372\tvalid_1's binary_logloss: 0.31335\n",
      "[300]\tvalid_0's binary_logloss: 0.297558\tvalid_1's binary_logloss: 0.31299\n",
      "[400]\tvalid_0's binary_logloss: 0.291679\tvalid_1's binary_logloss: 0.313028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312968:  70%|#######   | 14/20 [15:19<06:55, 69.26s/it]\u001b[32m[I 2022-12-19 17:52:12,621]\u001b[0m Trial 53 finished with value: 0.3129677327362491 and parameters: {'lambda_l1': 9.670167387226824, 'lambda_l2': 0.10110656486437304}. Best is trial 53 with value: 0.3129677327362491.\u001b[0m\n",
      "regularization_factors, val_score: 0.312968:  70%|#######   | 14/20 [15:19<06:55, 69.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's binary_logloss: 0.296596\tvalid_1's binary_logloss: 0.312968\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314172\tvalid_1's binary_logloss: 0.314957\n",
      "[200]\tvalid_0's binary_logloss: 0.304234\tvalid_1's binary_logloss: 0.313269\n",
      "[300]\tvalid_0's binary_logloss: 0.297064\tvalid_1's binary_logloss: 0.312981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312954:  75%|#######5  | 15/20 [16:46<06:14, 74.82s/it]\u001b[32m[I 2022-12-19 17:53:40,304]\u001b[0m Trial 54 finished with value: 0.31295433286411417 and parameters: {'lambda_l1': 8.709050252544463, 'lambda_l2': 0.06935262036337767}. Best is trial 54 with value: 0.31295433286411417.\u001b[0m\n",
      "regularization_factors, val_score: 0.312954:  75%|#######5  | 15/20 [16:46<06:14, 74.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's binary_logloss: 0.297361\tvalid_1's binary_logloss: 0.312954\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314273\tvalid_1's binary_logloss: 0.315056\n",
      "[200]\tvalid_0's binary_logloss: 0.30421\tvalid_1's binary_logloss: 0.313239\n",
      "[300]\tvalid_0's binary_logloss: 0.297301\tvalid_1's binary_logloss: 0.313022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312954:  80%|########  | 16/20 [18:15<05:15, 78.81s/it]\u001b[32m[I 2022-12-19 17:55:08,380]\u001b[0m Trial 55 finished with value: 0.3129814804678256 and parameters: {'lambda_l1': 9.22417313101035, 'lambda_l2': 0.08155359255532917}. Best is trial 54 with value: 0.31295433286411417.\u001b[0m\n",
      "regularization_factors, val_score: 0.312954:  80%|########  | 16/20 [18:15<05:15, 78.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's binary_logloss: 0.298418\tvalid_1's binary_logloss: 0.312981\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312334\tvalid_1's binary_logloss: 0.314652\n",
      "[200]\tvalid_0's binary_logloss: 0.300088\tvalid_1's binary_logloss: 0.313706\n",
      "[300]\tvalid_0's binary_logloss: 0.290446\tvalid_1's binary_logloss: 0.313885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312954:  85%|########5 | 17/20 [19:28<03:51, 77.12s/it]\u001b[32m[I 2022-12-19 17:56:21,568]\u001b[0m Trial 56 finished with value: 0.3136669663175538 and parameters: {'lambda_l1': 0.7603087625038644, 'lambda_l2': 0.13372708031956493}. Best is trial 54 with value: 0.31295433286411417.\u001b[0m\n",
      "regularization_factors, val_score: 0.312954:  85%|########5 | 17/20 [19:28<03:51, 77.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.298873\tvalid_1's binary_logloss: 0.313667\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311969\tvalid_1's binary_logloss: 0.314778\n",
      "[200]\tvalid_0's binary_logloss: 0.299049\tvalid_1's binary_logloss: 0.314042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312954:  90%|######### | 18/20 [20:24<02:21, 70.94s/it]\u001b[32m[I 2022-12-19 17:57:18,120]\u001b[0m Trial 57 finished with value: 0.3139939855758138 and parameters: {'lambda_l1': 0.02928157468977586, 'lambda_l2': 0.0024069203556790647}. Best is trial 54 with value: 0.31295433286411417.\u001b[0m\n",
      "regularization_factors, val_score: 0.312954:  90%|######### | 18/20 [20:24<02:21, 70.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.299812\tvalid_1's binary_logloss: 0.313994\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.312698\tvalid_1's binary_logloss: 0.314652\n",
      "[200]\tvalid_0's binary_logloss: 0.300875\tvalid_1's binary_logloss: 0.313322\n",
      "[300]\tvalid_0's binary_logloss: 0.291574\tvalid_1's binary_logloss: 0.313427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312954:  95%|#########5| 19/20 [21:33<01:10, 70.24s/it]\u001b[32m[I 2022-12-19 17:58:26,730]\u001b[0m Trial 58 finished with value: 0.31325382717924616 and parameters: {'lambda_l1': 1.6465876562002384, 'lambda_l2': 0.2054690304393859}. Best is trial 54 with value: 0.31295433286411417.\u001b[0m\n",
      "regularization_factors, val_score: 0.312954:  95%|#########5| 19/20 [21:33<01:10, 70.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's binary_logloss: 0.297214\tvalid_1's binary_logloss: 0.313254\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.311968\tvalid_1's binary_logloss: 0.314765\n",
      "[200]\tvalid_0's binary_logloss: 0.299394\tvalid_1's binary_logloss: 0.314275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.312954: 100%|##########| 20/20 [22:22<00:00, 64.00s/it]\u001b[32m[I 2022-12-19 17:59:16,201]\u001b[0m Trial 59 finished with value: 0.31403507216808946 and parameters: {'lambda_l1': 0.0051072482098435444, 'lambda_l2': 7.517873030722912e-06}. Best is trial 54 with value: 0.31295433286411417.\u001b[0m\n",
      "regularization_factors, val_score: 0.312954: 100%|##########| 20/20 [22:22<00:00, 67.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.303921\tvalid_1's binary_logloss: 0.314035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.312954:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.3141\tvalid_1's binary_logloss: 0.314994\n",
      "[200]\tvalid_0's binary_logloss: 0.304132\tvalid_1's binary_logloss: 0.313307\n",
      "[300]\tvalid_0's binary_logloss: 0.297112\tvalid_1's binary_logloss: 0.312975\n",
      "[400]\tvalid_0's binary_logloss: 0.290791\tvalid_1's binary_logloss: 0.312967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.312947:  20%|##        | 1/5 [01:37<06:30, 97.58s/it]\u001b[32m[I 2022-12-19 18:00:53,788]\u001b[0m Trial 60 finished with value: 0.3129470569243807 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.3129470569243807.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.312947:  20%|##        | 1/5 [01:37<06:30, 97.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[383]\tvalid_0's binary_logloss: 0.291818\tvalid_1's binary_logloss: 0.312947\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314125\tvalid_1's binary_logloss: 0.314917\n",
      "[200]\tvalid_0's binary_logloss: 0.304153\tvalid_1's binary_logloss: 0.313159\n",
      "[300]\tvalid_0's binary_logloss: 0.297132\tvalid_1's binary_logloss: 0.312901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.312871:  40%|####      | 2/5 [02:58<04:23, 88.00s/it]\u001b[32m[I 2022-12-19 18:02:15,076]\u001b[0m Trial 61 finished with value: 0.31287099603796187 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.31287099603796187.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.312871:  40%|####      | 2/5 [02:58<04:23, 88.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's binary_logloss: 0.297392\tvalid_1's binary_logloss: 0.312871\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314125\tvalid_1's binary_logloss: 0.314907\n",
      "[200]\tvalid_0's binary_logloss: 0.304048\tvalid_1's binary_logloss: 0.313196\n",
      "[300]\tvalid_0's binary_logloss: 0.297147\tvalid_1's binary_logloss: 0.312921\n",
      "[400]\tvalid_0's binary_logloss: 0.291095\tvalid_1's binary_logloss: 0.312938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.312824:  60%|######    | 3/5 [04:36<03:04, 92.19s/it]\u001b[32m[I 2022-12-19 18:03:52,255]\u001b[0m Trial 62 finished with value: 0.3128240741607626 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.3128240741607626.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.312824:  60%|######    | 3/5 [04:36<03:04, 92.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's binary_logloss: 0.294508\tvalid_1's binary_logloss: 0.312824\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.314197\tvalid_1's binary_logloss: 0.31493\n",
      "[200]\tvalid_0's binary_logloss: 0.304167\tvalid_1's binary_logloss: 0.313267\n",
      "[300]\tvalid_0's binary_logloss: 0.297185\tvalid_1's binary_logloss: 0.312954\n",
      "[400]\tvalid_0's binary_logloss: 0.290881\tvalid_1's binary_logloss: 0.312946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.312824:  80%|########  | 4/5 [06:05<01:31, 91.10s/it]\u001b[32m[I 2022-12-19 18:05:21,696]\u001b[0m Trial 63 finished with value: 0.3128811798920368 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.3128240741607626.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.312824:  80%|########  | 4/5 [06:05<01:31, 91.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's binary_logloss: 0.29608\tvalid_1's binary_logloss: 0.312881\n",
      "[LightGBM] [Info] Number of positive: 833450, number of negative: 833450\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1666900, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.31417\tvalid_1's binary_logloss: 0.315078\n",
      "[200]\tvalid_0's binary_logloss: 0.304039\tvalid_1's binary_logloss: 0.313274\n",
      "[300]\tvalid_0's binary_logloss: 0.296868\tvalid_1's binary_logloss: 0.312965\n",
      "[400]\tvalid_0's binary_logloss: 0.290459\tvalid_1's binary_logloss: 0.313013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.312824: 100%|##########| 5/5 [07:38<00:00, 91.65s/it]\u001b[32m[I 2022-12-19 18:06:54,324]\u001b[0m Trial 64 finished with value: 0.31293301725586564 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 0.3128240741607626.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.312824: 100%|##########| 5/5 [07:38<00:00, 91.62s/it]\n",
      "7:12:54.851949 \t carts best_params\n",
      "7:12:54.853070 \t {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 8.709050252544463, 'lambda_l2': 0.06935262036337767, 'num_leaves': 252, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 5, 'num_iterations': 2000000, 'early_stopping_round': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's binary_logloss: 0.294531\tvalid_1's binary_logloss: 0.312933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-19 18:06:58,937]\u001b[0m A new study created in memory with name: no-name-854b3aa0-702b-41f4-b3e4-fd908e328330\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.291329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.200276\tvalid_1's binary_logloss: 0.184669\n",
      "[200]\tvalid_0's binary_logloss: 0.195393\tvalid_1's binary_logloss: 0.182932\n",
      "[300]\tvalid_0's binary_logloss: 0.192484\tvalid_1's binary_logloss: 0.182537\n",
      "[400]\tvalid_0's binary_logloss: 0.189883\tvalid_1's binary_logloss: 0.18241\n",
      "[500]\tvalid_0's binary_logloss: 0.187612\tvalid_1's binary_logloss: 0.18234\n",
      "[600]\tvalid_0's binary_logloss: 0.18554\tvalid_1's binary_logloss: 0.182324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182309:  14%|#4        | 1/7 [00:50<05:04, 50.75s/it]\u001b[32m[I 2022-12-19 18:07:49,692]\u001b[0m Trial 0 finished with value: 0.18230911130844832 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.18230911130844832.\u001b[0m\n",
      "feature_fraction, val_score: 0.182309:  14%|#4        | 1/7 [00:50<05:04, 50.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[520]\tvalid_0's binary_logloss: 0.187159\tvalid_1's binary_logloss: 0.182309\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.199917\tvalid_1's binary_logloss: 0.184558\n",
      "[200]\tvalid_0's binary_logloss: 0.195005\tvalid_1's binary_logloss: 0.182886\n",
      "[300]\tvalid_0's binary_logloss: 0.192006\tvalid_1's binary_logloss: 0.182505\n",
      "[400]\tvalid_0's binary_logloss: 0.189444\tvalid_1's binary_logloss: 0.182377\n",
      "[500]\tvalid_0's binary_logloss: 0.187029\tvalid_1's binary_logloss: 0.182295\n",
      "[600]\tvalid_0's binary_logloss: 0.184889\tvalid_1's binary_logloss: 0.182309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182276:  29%|##8       | 2/7 [01:49<04:36, 55.21s/it]\u001b[32m[I 2022-12-19 18:08:48,027]\u001b[0m Trial 1 finished with value: 0.18227556484732874 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.18227556484732874.\u001b[0m\n",
      "feature_fraction, val_score: 0.182276:  29%|##8       | 2/7 [01:49<04:36, 55.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[527]\tvalid_0's binary_logloss: 0.186417\tvalid_1's binary_logloss: 0.182276\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.200912\tvalid_1's binary_logloss: 0.185125\n",
      "[200]\tvalid_0's binary_logloss: 0.195824\tvalid_1's binary_logloss: 0.183015\n",
      "[300]\tvalid_0's binary_logloss: 0.193001\tvalid_1's binary_logloss: 0.182615\n",
      "[400]\tvalid_0's binary_logloss: 0.190633\tvalid_1's binary_logloss: 0.182404\n",
      "[500]\tvalid_0's binary_logloss: 0.188486\tvalid_1's binary_logloss: 0.182362\n",
      "[600]\tvalid_0's binary_logloss: 0.186264\tvalid_1's binary_logloss: 0.182349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182276:  43%|####2     | 3/7 [02:55<04:01, 60.45s/it]\u001b[32m[I 2022-12-19 18:09:54,708]\u001b[0m Trial 2 finished with value: 0.18231075249872872 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.18227556484732874.\u001b[0m\n",
      "feature_fraction, val_score: 0.182276:  43%|####2     | 3/7 [02:55<04:01, 60.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's binary_logloss: 0.187544\tvalid_1's binary_logloss: 0.182311\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.199987\tvalid_1's binary_logloss: 0.18459\n",
      "[200]\tvalid_0's binary_logloss: 0.195083\tvalid_1's binary_logloss: 0.182911\n",
      "[300]\tvalid_0's binary_logloss: 0.191966\tvalid_1's binary_logloss: 0.182569\n",
      "[400]\tvalid_0's binary_logloss: 0.189325\tvalid_1's binary_logloss: 0.182437\n",
      "[500]\tvalid_0's binary_logloss: 0.186949\tvalid_1's binary_logloss: 0.182402\n",
      "[600]\tvalid_0's binary_logloss: 0.184696\tvalid_1's binary_logloss: 0.182382\n",
      "[700]\tvalid_0's binary_logloss: 0.182665\tvalid_1's binary_logloss: 0.18237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182276:  57%|#####7    | 4/7 [03:59<03:04, 61.64s/it]\u001b[32m[I 2022-12-19 18:10:58,167]\u001b[0m Trial 3 finished with value: 0.18234361852044903 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.18227556484732874.\u001b[0m\n",
      "feature_fraction, val_score: 0.182276:  57%|#####7    | 4/7 [03:59<03:04, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[623]\tvalid_0's binary_logloss: 0.184213\tvalid_1's binary_logloss: 0.182344\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.199958\tvalid_1's binary_logloss: 0.184644\n",
      "[200]\tvalid_0's binary_logloss: 0.195066\tvalid_1's binary_logloss: 0.183107\n",
      "[300]\tvalid_0's binary_logloss: 0.19191\tvalid_1's binary_logloss: 0.182743\n",
      "[400]\tvalid_0's binary_logloss: 0.189251\tvalid_1's binary_logloss: 0.182551\n",
      "[500]\tvalid_0's binary_logloss: 0.186887\tvalid_1's binary_logloss: 0.182466\n",
      "[600]\tvalid_0's binary_logloss: 0.184683\tvalid_1's binary_logloss: 0.182459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182276:  71%|#######1  | 5/7 [04:45<01:52, 56.08s/it]\u001b[32m[I 2022-12-19 18:11:44,398]\u001b[0m Trial 4 finished with value: 0.1824162617374371 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.18227556484732874.\u001b[0m\n",
      "feature_fraction, val_score: 0.182276:  71%|#######1  | 5/7 [04:45<01:52, 56.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[523]\tvalid_0's binary_logloss: 0.186296\tvalid_1's binary_logloss: 0.182416\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.200112\tvalid_1's binary_logloss: 0.184694\n",
      "[200]\tvalid_0's binary_logloss: 0.195229\tvalid_1's binary_logloss: 0.182964\n",
      "[300]\tvalid_0's binary_logloss: 0.192288\tvalid_1's binary_logloss: 0.18272\n",
      "[400]\tvalid_0's binary_logloss: 0.18965\tvalid_1's binary_logloss: 0.182507\n",
      "[500]\tvalid_0's binary_logloss: 0.18719\tvalid_1's binary_logloss: 0.182441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182276:  86%|########5 | 6/7 [05:27<00:51, 51.27s/it]\u001b[32m[I 2022-12-19 18:12:26,340]\u001b[0m Trial 5 finished with value: 0.182432760412256 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.18227556484732874.\u001b[0m\n",
      "feature_fraction, val_score: 0.182276:  86%|########5 | 6/7 [05:27<00:51, 51.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[455]\tvalid_0's binary_logloss: 0.188227\tvalid_1's binary_logloss: 0.182433\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.20052\tvalid_1's binary_logloss: 0.184944\n",
      "[200]\tvalid_0's binary_logloss: 0.195605\tvalid_1's binary_logloss: 0.183025\n",
      "[300]\tvalid_0's binary_logloss: 0.192687\tvalid_1's binary_logloss: 0.182535\n",
      "[400]\tvalid_0's binary_logloss: 0.190257\tvalid_1's binary_logloss: 0.182316\n",
      "[500]\tvalid_0's binary_logloss: 0.18819\tvalid_1's binary_logloss: 0.182303\n",
      "[600]\tvalid_0's binary_logloss: 0.186118\tvalid_1's binary_logloss: 0.182237\n",
      "[700]\tvalid_0's binary_logloss: 0.184138\tvalid_1's binary_logloss: 0.182254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.182211: 100%|##########| 7/7 [06:34<00:00, 56.60s/it]\u001b[32m[I 2022-12-19 18:13:33,896]\u001b[0m Trial 6 finished with value: 0.1822112288338476 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.1822112288338476.\u001b[0m\n",
      "feature_fraction, val_score: 0.182211: 100%|##########| 7/7 [06:34<00:00, 56.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[607]\tvalid_0's binary_logloss: 0.185943\tvalid_1's binary_logloss: 0.182211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.182211:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.190995\tvalid_1's binary_logloss: 0.182228\n",
      "[200]\tvalid_0's binary_logloss: 0.181408\tvalid_1's binary_logloss: 0.182366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181867:   5%|5         | 1/20 [00:43<13:46, 43.49s/it]\u001b[32m[I 2022-12-19 18:14:17,390]\u001b[0m Trial 7 finished with value: 0.18186666886057978 and parameters: {'num_leaves': 117}. Best is trial 7 with value: 0.18186666886057978.\u001b[0m\n",
      "num_leaves, val_score: 0.181867:   5%|5         | 1/20 [00:43<13:46, 43.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.186697\tvalid_1's binary_logloss: 0.181867\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.185384\tvalid_1's binary_logloss: 0.181823\n",
      "[200]\tvalid_0's binary_logloss: 0.172488\tvalid_1's binary_logloss: 0.18254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181780:  10%|#         | 2/20 [01:17<11:21, 37.85s/it]\u001b[32m[I 2022-12-19 18:14:51,296]\u001b[0m Trial 8 finished with value: 0.1817795235288829 and parameters: {'num_leaves': 192}. Best is trial 8 with value: 0.1817795235288829.\u001b[0m\n",
      "num_leaves, val_score: 0.181780:  10%|#         | 2/20 [01:17<11:21, 37.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's binary_logloss: 0.181759\tvalid_1's binary_logloss: 0.18178\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.21521\tvalid_1's binary_logloss: 0.193851\n",
      "[200]\tvalid_0's binary_logloss: 0.207832\tvalid_1's binary_logloss: 0.188915\n",
      "[300]\tvalid_0's binary_logloss: 0.20488\tvalid_1's binary_logloss: 0.187159\n",
      "[400]\tvalid_0's binary_logloss: 0.203041\tvalid_1's binary_logloss: 0.186088\n",
      "[500]\tvalid_0's binary_logloss: 0.201734\tvalid_1's binary_logloss: 0.185254\n",
      "[600]\tvalid_0's binary_logloss: 0.200725\tvalid_1's binary_logloss: 0.18479\n",
      "[700]\tvalid_0's binary_logloss: 0.19994\tvalid_1's binary_logloss: 0.184471\n",
      "[800]\tvalid_0's binary_logloss: 0.199263\tvalid_1's binary_logloss: 0.184186\n",
      "[900]\tvalid_0's binary_logloss: 0.19853\tvalid_1's binary_logloss: 0.18387\n",
      "[1000]\tvalid_0's binary_logloss: 0.197937\tvalid_1's binary_logloss: 0.183695\n",
      "[1100]\tvalid_0's binary_logloss: 0.197393\tvalid_1's binary_logloss: 0.183495\n",
      "[1200]\tvalid_0's binary_logloss: 0.196841\tvalid_1's binary_logloss: 0.18329\n",
      "[1300]\tvalid_0's binary_logloss: 0.19638\tvalid_1's binary_logloss: 0.183111\n",
      "[1400]\tvalid_0's binary_logloss: 0.195914\tvalid_1's binary_logloss: 0.182992\n",
      "[1500]\tvalid_0's binary_logloss: 0.195459\tvalid_1's binary_logloss: 0.182844\n",
      "[1600]\tvalid_0's binary_logloss: 0.195103\tvalid_1's binary_logloss: 0.182797\n",
      "[1700]\tvalid_0's binary_logloss: 0.194721\tvalid_1's binary_logloss: 0.182731\n",
      "[1800]\tvalid_0's binary_logloss: 0.194338\tvalid_1's binary_logloss: 0.182669\n",
      "[1900]\tvalid_0's binary_logloss: 0.193955\tvalid_1's binary_logloss: 0.182582\n",
      "[2000]\tvalid_0's binary_logloss: 0.193605\tvalid_1's binary_logloss: 0.182512\n",
      "[2100]\tvalid_0's binary_logloss: 0.193265\tvalid_1's binary_logloss: 0.182462\n",
      "[2200]\tvalid_0's binary_logloss: 0.192924\tvalid_1's binary_logloss: 0.182394\n",
      "[2300]\tvalid_0's binary_logloss: 0.192607\tvalid_1's binary_logloss: 0.182348\n",
      "[2400]\tvalid_0's binary_logloss: 0.19231\tvalid_1's binary_logloss: 0.18232\n",
      "[2500]\tvalid_0's binary_logloss: 0.191966\tvalid_1's binary_logloss: 0.182252\n",
      "[2600]\tvalid_0's binary_logloss: 0.191703\tvalid_1's binary_logloss: 0.182265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181780:  15%|#5        | 3/20 [03:33<23:23, 82.56s/it]\u001b[32m[I 2022-12-19 18:17:07,066]\u001b[0m Trial 9 finished with value: 0.18224704938686884 and parameters: {'num_leaves': 6}. Best is trial 8 with value: 0.1817795235288829.\u001b[0m\n",
      "num_leaves, val_score: 0.181780:  15%|#5        | 3/20 [03:33<23:23, 82.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2522]\tvalid_0's binary_logloss: 0.191905\tvalid_1's binary_logloss: 0.182247\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187044\tvalid_1's binary_logloss: 0.181943\n",
      "[200]\tvalid_0's binary_logloss: 0.174885\tvalid_1's binary_logloss: 0.182567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181780:  20%|##        | 4/20 [04:20<18:19, 68.74s/it]\u001b[32m[I 2022-12-19 18:17:54,619]\u001b[0m Trial 10 finished with value: 0.1818863819632433 and parameters: {'num_leaves': 170}. Best is trial 8 with value: 0.1817795235288829.\u001b[0m\n",
      "num_leaves, val_score: 0.181780:  20%|##        | 4/20 [04:20<18:19, 68.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.182631\tvalid_1's binary_logloss: 0.181886\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.188141\tvalid_1's binary_logloss: 0.181963\n",
      "[200]\tvalid_0's binary_logloss: 0.176695\tvalid_1's binary_logloss: 0.182399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181780:  25%|##5       | 5/20 [04:53<13:54, 55.65s/it]\u001b[32m[I 2022-12-19 18:18:27,047]\u001b[0m Trial 11 finished with value: 0.1817965983929578 and parameters: {'num_leaves': 155}. Best is trial 8 with value: 0.1817795235288829.\u001b[0m\n",
      "num_leaves, val_score: 0.181780:  25%|##5       | 5/20 [04:53<13:54, 55.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.184376\tvalid_1's binary_logloss: 0.181797\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189252\tvalid_1's binary_logloss: 0.182004\n",
      "[200]\tvalid_0's binary_logloss: 0.178558\tvalid_1's binary_logloss: 0.182343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181780:  30%|###       | 6/20 [05:25<11:08, 47.78s/it]\u001b[32m[I 2022-12-19 18:18:59,560]\u001b[0m Trial 12 finished with value: 0.18192436423690117 and parameters: {'num_leaves': 140}. Best is trial 8 with value: 0.1817795235288829.\u001b[0m\n",
      "num_leaves, val_score: 0.181780:  30%|###       | 6/20 [05:25<11:08, 47.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.18649\tvalid_1's binary_logloss: 0.181924\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.182761\tvalid_1's binary_logloss: 0.181678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  35%|###5      | 7/20 [06:00<09:27, 43.66s/it]\u001b[32m[I 2022-12-19 18:19:34,743]\u001b[0m Trial 13 finished with value: 0.18164948768220782 and parameters: {'num_leaves': 230}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  35%|###5      | 7/20 [06:00<09:27, 43.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.168007\tvalid_1's binary_logloss: 0.182598\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.182558\tvalid_1's binary_logloss: 0.181649\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.195741\tvalid_1's binary_logloss: 0.182965\n",
      "[200]\tvalid_0's binary_logloss: 0.189352\tvalid_1's binary_logloss: 0.182116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  40%|####      | 8/20 [06:34<08:04, 40.34s/it]\u001b[32m[I 2022-12-19 18:20:07,983]\u001b[0m Trial 14 finished with value: 0.182107208031328 and parameters: {'num_leaves': 65}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  40%|####      | 8/20 [06:34<08:04, 40.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.189459\tvalid_1's binary_logloss: 0.182107\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.19367\tvalid_1's binary_logloss: 0.182513\n",
      "[200]\tvalid_0's binary_logloss: 0.185999\tvalid_1's binary_logloss: 0.182138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  45%|####5     | 9/20 [07:05<06:52, 37.51s/it]\u001b[32m[I 2022-12-19 18:20:39,274]\u001b[0m Trial 15 finished with value: 0.182014491261157 and parameters: {'num_leaves': 87}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  45%|####5     | 9/20 [07:05<06:52, 37.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.189704\tvalid_1's binary_logloss: 0.182014\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.182199\tvalid_1's binary_logloss: 0.181668\n",
      "[200]\tvalid_0's binary_logloss: 0.167317\tvalid_1's binary_logloss: 0.182733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  50%|#####     | 10/20 [07:41<06:12, 37.21s/it]\u001b[32m[I 2022-12-19 18:21:15,799]\u001b[0m Trial 16 finished with value: 0.1816578344241276 and parameters: {'num_leaves': 239}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  50%|#####     | 10/20 [07:41<06:12, 37.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.181442\tvalid_1's binary_logloss: 0.181658\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.324592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.18146\tvalid_1's binary_logloss: 0.181682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  55%|#####5    | 11/20 [08:36<06:22, 42.54s/it]\u001b[32m[I 2022-12-19 18:22:10,420]\u001b[0m Trial 17 finished with value: 0.1816818436188322 and parameters: {'num_leaves': 249}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  55%|#####5    | 11/20 [08:36<06:22, 42.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.166241\tvalid_1's binary_logloss: 0.182785\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.18146\tvalid_1's binary_logloss: 0.181682\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.181937\tvalid_1's binary_logloss: 0.181673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  60%|######    | 12/20 [09:10<05:19, 39.91s/it]\u001b[32m[I 2022-12-19 18:22:44,316]\u001b[0m Trial 18 finished with value: 0.1816542149244154 and parameters: {'num_leaves': 243}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  60%|######    | 12/20 [09:10<05:19, 39.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.182297\tvalid_1's binary_logloss: 0.181654\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.184339\tvalid_1's binary_logloss: 0.181772\n",
      "[200]\tvalid_0's binary_logloss: 0.170792\tvalid_1's binary_logloss: 0.182753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  65%|######5   | 13/20 [09:43<04:25, 37.92s/it]\u001b[32m[I 2022-12-19 18:23:17,646]\u001b[0m Trial 19 finished with value: 0.18173576228058658 and parameters: {'num_leaves': 208}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  65%|######5   | 13/20 [09:43<04:25, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.183244\tvalid_1's binary_logloss: 0.181736\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.183811\tvalid_1's binary_logloss: 0.1818\n",
      "[200]\tvalid_0's binary_logloss: 0.169778\tvalid_1's binary_logloss: 0.182616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  70%|#######   | 14/20 [10:16<03:38, 36.39s/it]\u001b[32m[I 2022-12-19 18:23:50,497]\u001b[0m Trial 20 finished with value: 0.18178127221726062 and parameters: {'num_leaves': 217}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  70%|#######   | 14/20 [10:16<03:38, 36.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.182792\tvalid_1's binary_logloss: 0.181781\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.181203\tvalid_1's binary_logloss: 0.181675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  75%|#######5  | 15/20 [10:50<02:57, 35.60s/it]\u001b[32m[I 2022-12-19 18:24:24,264]\u001b[0m Trial 21 finished with value: 0.18166396525625966 and parameters: {'num_leaves': 255}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  75%|#######5  | 15/20 [10:50<02:57, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.165931\tvalid_1's binary_logloss: 0.182961\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.181019\tvalid_1's binary_logloss: 0.181664\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.185901\tvalid_1's binary_logloss: 0.181785\n",
      "[200]\tvalid_0's binary_logloss: 0.1732\tvalid_1's binary_logloss: 0.182801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  80%|########  | 16/20 [11:23<02:19, 34.84s/it]\u001b[32m[I 2022-12-19 18:24:57,348]\u001b[0m Trial 22 finished with value: 0.18175835288752776 and parameters: {'num_leaves': 186}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  80%|########  | 16/20 [11:23<02:19, 34.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's binary_logloss: 0.183394\tvalid_1's binary_logloss: 0.181758\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.18338\tvalid_1's binary_logloss: 0.181721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  85%|########5 | 17/20 [11:54<01:41, 33.85s/it]\u001b[32m[I 2022-12-19 18:25:28,894]\u001b[0m Trial 23 finished with value: 0.18171550867501282 and parameters: {'num_leaves': 221}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  85%|########5 | 17/20 [11:54<01:41, 33.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.183722\tvalid_1's binary_logloss: 0.181716\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.191953\tvalid_1's binary_logloss: 0.182318\n",
      "[200]\tvalid_0's binary_logloss: 0.18295\tvalid_1's binary_logloss: 0.182233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  90%|######### | 18/20 [12:26<01:06, 33.23s/it]\u001b[32m[I 2022-12-19 18:26:00,675]\u001b[0m Trial 24 finished with value: 0.1819577834188788 and parameters: {'num_leaves': 108}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  90%|######### | 18/20 [12:26<01:06, 33.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.186683\tvalid_1's binary_logloss: 0.181958\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.198625\tvalid_1's binary_logloss: 0.183926\n",
      "[200]\tvalid_0's binary_logloss: 0.193487\tvalid_1's binary_logloss: 0.18254\n",
      "[300]\tvalid_0's binary_logloss: 0.19011\tvalid_1's binary_logloss: 0.182362\n",
      "[400]\tvalid_0's binary_logloss: 0.186956\tvalid_1's binary_logloss: 0.182197\n",
      "[500]\tvalid_0's binary_logloss: 0.184169\tvalid_1's binary_logloss: 0.182154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181649:  95%|#########5| 19/20 [13:12<00:36, 36.96s/it]\u001b[32m[I 2022-12-19 18:26:46,323]\u001b[0m Trial 25 finished with value: 0.18211691529897184 and parameters: {'num_leaves': 42}. Best is trial 13 with value: 0.18164948768220782.\u001b[0m\n",
      "num_leaves, val_score: 0.181649:  95%|#########5| 19/20 [13:12<00:36, 36.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's binary_logloss: 0.185489\tvalid_1's binary_logloss: 0.182117\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186786\tvalid_1's binary_logloss: 0.181701\n",
      "[200]\tvalid_0's binary_logloss: 0.174526\tvalid_1's binary_logloss: 0.182569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.181617: 100%|##########| 20/20 [13:56<00:00, 39.24s/it]\u001b[32m[I 2022-12-19 18:27:30,866]\u001b[0m Trial 26 finished with value: 0.18161671119445152 and parameters: {'num_leaves': 174}. Best is trial 26 with value: 0.18161671119445152.\u001b[0m\n",
      "num_leaves, val_score: 0.181617: 100%|##########| 20/20 [13:56<00:00, 41.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.184116\tvalid_1's binary_logloss: 0.181617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187153\tvalid_1's binary_logloss: 0.182148\n",
      "[200]\tvalid_0's binary_logloss: 0.174432\tvalid_1's binary_logloss: 0.182664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  10%|#         | 1/10 [00:31<04:41, 31.29s/it]\u001b[32m[I 2022-12-19 18:28:02,166]\u001b[0m Trial 27 finished with value: 0.18206865597894695 and parameters: {'bagging_fraction': 0.7255310042857592, 'bagging_freq': 3}. Best is trial 27 with value: 0.18206865597894695.\u001b[0m\n",
      "bagging, val_score: 0.181617:  10%|#         | 1/10 [00:31<04:41, 31.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.185511\tvalid_1's binary_logloss: 0.182069\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186898\tvalid_1's binary_logloss: 0.181871\n",
      "[200]\tvalid_0's binary_logloss: 0.17434\tvalid_1's binary_logloss: 0.182546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  20%|##        | 2/10 [01:05<04:22, 32.82s/it]\u001b[32m[I 2022-12-19 18:28:36,051]\u001b[0m Trial 28 finished with value: 0.18172465151591688 and parameters: {'bagging_fraction': 0.9639103364964102, 'bagging_freq': 6}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  20%|##        | 2/10 [01:05<04:22, 32.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.184112\tvalid_1's binary_logloss: 0.181725\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187101\tvalid_1's binary_logloss: 0.182305\n",
      "[200]\tvalid_0's binary_logloss: 0.174836\tvalid_1's binary_logloss: 0.182274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  30%|###       | 3/10 [01:43<04:08, 35.48s/it]\u001b[32m[I 2022-12-19 18:29:14,692]\u001b[0m Trial 29 finished with value: 0.182100517277138 and parameters: {'bagging_fraction': 0.7496155815505636, 'bagging_freq': 6}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  30%|###       | 3/10 [01:43<04:08, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's binary_logloss: 0.177157\tvalid_1's binary_logloss: 0.182101\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187499\tvalid_1's binary_logloss: 0.182652\n",
      "[200]\tvalid_0's binary_logloss: 0.175256\tvalid_1's binary_logloss: 0.183097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  40%|####      | 4/10 [02:37<04:15, 42.51s/it]\u001b[32m[I 2022-12-19 18:30:07,993]\u001b[0m Trial 30 finished with value: 0.18225719498436874 and parameters: {'bagging_fraction': 0.579852293758293, 'bagging_freq': 2}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  40%|####      | 4/10 [02:37<04:15, 42.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.180837\tvalid_1's binary_logloss: 0.182257\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187124\tvalid_1's binary_logloss: 0.182377\n",
      "[200]\tvalid_0's binary_logloss: 0.174537\tvalid_1's binary_logloss: 0.182669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  50%|#####     | 5/10 [03:09<03:13, 38.69s/it]\u001b[32m[I 2022-12-19 18:30:39,905]\u001b[0m Trial 31 finished with value: 0.18225135775439966 and parameters: {'bagging_fraction': 0.7714344958485893, 'bagging_freq': 7}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  50%|#####     | 5/10 [03:09<03:13, 38.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.186272\tvalid_1's binary_logloss: 0.182251\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.306314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187098\tvalid_1's binary_logloss: 0.182233\n",
      "[200]\tvalid_0's binary_logloss: 0.174604\tvalid_1's binary_logloss: 0.182556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  60%|######    | 6/10 [03:41<02:26, 36.60s/it]\u001b[32m[I 2022-12-19 18:31:12,446]\u001b[0m Trial 32 finished with value: 0.1820696370265999 and parameters: {'bagging_fraction': 0.6964995982819635, 'bagging_freq': 1}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  60%|######    | 6/10 [03:41<02:26, 36.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.180802\tvalid_1's binary_logloss: 0.18207\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186978\tvalid_1's binary_logloss: 0.182285\n",
      "[200]\tvalid_0's binary_logloss: 0.174433\tvalid_1's binary_logloss: 0.182512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  70%|#######   | 7/10 [04:17<01:49, 36.40s/it]\u001b[32m[I 2022-12-19 18:31:48,441]\u001b[0m Trial 33 finished with value: 0.1819612762030842 and parameters: {'bagging_fraction': 0.7989743358958461, 'bagging_freq': 2}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  70%|#######   | 7/10 [04:17<01:49, 36.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.181682\tvalid_1's binary_logloss: 0.181961\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186855\tvalid_1's binary_logloss: 0.181899\n",
      "[200]\tvalid_0's binary_logloss: 0.174509\tvalid_1's binary_logloss: 0.182234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  80%|########  | 8/10 [05:12<01:24, 42.37s/it]\u001b[32m[I 2022-12-19 18:32:43,589]\u001b[0m Trial 34 finished with value: 0.18177949669161864 and parameters: {'bagging_fraction': 0.8816715690296912, 'bagging_freq': 6}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  80%|########  | 8/10 [05:12<01:24, 42.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.184882\tvalid_1's binary_logloss: 0.181779\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187216\tvalid_1's binary_logloss: 0.182427\n",
      "[200]\tvalid_0's binary_logloss: 0.17451\tvalid_1's binary_logloss: 0.183143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617:  90%|######### | 9/10 [05:48<00:40, 40.20s/it]\u001b[32m[I 2022-12-19 18:33:19,021]\u001b[0m Trial 35 finished with value: 0.18221039349233098 and parameters: {'bagging_fraction': 0.7425821077479848, 'bagging_freq': 5}. Best is trial 28 with value: 0.18172465151591688.\u001b[0m\n",
      "bagging, val_score: 0.181617:  90%|######### | 9/10 [05:48<00:40, 40.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.180379\tvalid_1's binary_logloss: 0.18221\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186989\tvalid_1's binary_logloss: 0.181988\n",
      "[200]\tvalid_0's binary_logloss: 0.174469\tvalid_1's binary_logloss: 0.182607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.181617: 100%|##########| 10/10 [06:21<00:00, 38.24s/it]\u001b[32m[I 2022-12-19 18:33:52,866]\u001b[0m Trial 36 finished with value: 0.1816954254762784 and parameters: {'bagging_fraction': 0.8838446470699506, 'bagging_freq': 4}. Best is trial 36 with value: 0.1816954254762784.\u001b[0m\n",
      "bagging, val_score: 0.181617: 100%|##########| 10/10 [06:21<00:00, 38.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.184288\tvalid_1's binary_logloss: 0.181695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186565\tvalid_1's binary_logloss: 0.181964\n",
      "[200]\tvalid_0's binary_logloss: 0.174219\tvalid_1's binary_logloss: 0.182563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617:  17%|#6        | 1/6 [00:32<02:40, 32.05s/it]\u001b[32m[I 2022-12-19 18:34:24,926]\u001b[0m Trial 37 finished with value: 0.18193908399960484 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.18193908399960484.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.181617:  17%|#6        | 1/6 [00:32<02:40, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.185851\tvalid_1's binary_logloss: 0.181939\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187135\tvalid_1's binary_logloss: 0.181968\n",
      "[200]\tvalid_0's binary_logloss: 0.174993\tvalid_1's binary_logloss: 0.182517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617:  33%|###3      | 2/6 [01:06<02:14, 33.67s/it]\u001b[32m[I 2022-12-19 18:34:59,729]\u001b[0m Trial 38 finished with value: 0.18182226090836312 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 38 with value: 0.18182226090836312.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.181617:  33%|###3      | 2/6 [01:06<02:14, 33.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.183048\tvalid_1's binary_logloss: 0.181822\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186786\tvalid_1's binary_logloss: 0.181701\n",
      "[200]\tvalid_0's binary_logloss: 0.174526\tvalid_1's binary_logloss: 0.182569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617:  50%|#####     | 3/6 [01:41<01:41, 33.99s/it]\u001b[32m[I 2022-12-19 18:35:34,108]\u001b[0m Trial 39 finished with value: 0.18161671119445155 and parameters: {'feature_fraction': 0.516}. Best is trial 39 with value: 0.18161671119445155.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.181617:  50%|#####     | 3/6 [01:41<01:41, 33.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.184116\tvalid_1's binary_logloss: 0.181617\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186926\tvalid_1's binary_logloss: 0.181816\n",
      "[200]\tvalid_0's binary_logloss: 0.174761\tvalid_1's binary_logloss: 0.182475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617:  67%|######6   | 4/6 [02:13<01:06, 33.19s/it]\u001b[32m[I 2022-12-19 18:36:06,059]\u001b[0m Trial 40 finished with value: 0.18176797714926826 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.18161671119445155.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.181617:  67%|######6   | 4/6 [02:13<01:06, 33.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.186263\tvalid_1's binary_logloss: 0.181768\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186191\tvalid_1's binary_logloss: 0.181786\n",
      "[200]\tvalid_0's binary_logloss: 0.173918\tvalid_1's binary_logloss: 0.182386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617:  83%|########3 | 5/6 [02:47<00:33, 33.48s/it]\u001b[32m[I 2022-12-19 18:36:40,051]\u001b[0m Trial 41 finished with value: 0.18175274735094005 and parameters: {'feature_fraction': 0.58}. Best is trial 39 with value: 0.18161671119445155.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.181617:  83%|########3 | 5/6 [02:47<00:33, 33.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.18484\tvalid_1's binary_logloss: 0.181753\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.18751\tvalid_1's binary_logloss: 0.18201\n",
      "[200]\tvalid_0's binary_logloss: 0.175327\tvalid_1's binary_logloss: 0.182307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.181617: 100%|##########| 6/6 [03:21<00:00, 33.65s/it]\u001b[32m[I 2022-12-19 18:37:14,039]\u001b[0m Trial 42 finished with value: 0.18182656064499567 and parameters: {'feature_fraction': 0.42}. Best is trial 39 with value: 0.18161671119445155.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.181617: 100%|##########| 6/6 [03:21<00:00, 33.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.182256\tvalid_1's binary_logloss: 0.181827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.181617:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186751\tvalid_1's binary_logloss: 0.181822\n",
      "[200]\tvalid_0's binary_logloss: 0.174358\tvalid_1's binary_logloss: 0.182472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.181617:   5%|5         | 1/20 [00:34<10:47, 34.08s/it]\u001b[32m[I 2022-12-19 18:37:48,128]\u001b[0m Trial 43 finished with value: 0.18173502484891205 and parameters: {'lambda_l1': 1.0517175566970303e-08, 'lambda_l2': 0.0002604881418307845}. Best is trial 43 with value: 0.18173502484891205.\u001b[0m\n",
      "regularization_factors, val_score: 0.181617:   5%|5         | 1/20 [00:34<10:47, 34.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.184851\tvalid_1's binary_logloss: 0.181735\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187571\tvalid_1's binary_logloss: 0.181584\n",
      "[200]\tvalid_0's binary_logloss: 0.176273\tvalid_1's binary_logloss: 0.181267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.181125:  10%|#         | 2/20 [01:14<11:22, 37.92s/it]\u001b[32m[I 2022-12-19 18:38:28,741]\u001b[0m Trial 44 finished with value: 0.18112485563705344 and parameters: {'lambda_l1': 1.2183252511671503, 'lambda_l2': 9.765669047810648e-05}. Best is trial 44 with value: 0.18112485563705344.\u001b[0m\n",
      "regularization_factors, val_score: 0.181125:  10%|#         | 2/20 [01:14<11:22, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.180518\tvalid_1's binary_logloss: 0.181125\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186763\tvalid_1's binary_logloss: 0.181771\n",
      "[200]\tvalid_0's binary_logloss: 0.174625\tvalid_1's binary_logloss: 0.182652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.181125:  15%|#5        | 3/20 [02:04<12:14, 43.22s/it]\u001b[32m[I 2022-12-19 18:39:18,264]\u001b[0m Trial 45 finished with value: 0.18168707702447526 and parameters: {'lambda_l1': 1.8689119609982685e-08, 'lambda_l2': 0.00010315226614077517}. Best is trial 44 with value: 0.18112485563705344.\u001b[0m\n",
      "regularization_factors, val_score: 0.181125:  15%|#5        | 3/20 [02:04<12:14, 43.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.186106\tvalid_1's binary_logloss: 0.181687\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189596\tvalid_1's binary_logloss: 0.181752\n",
      "[200]\tvalid_0's binary_logloss: 0.180951\tvalid_1's binary_logloss: 0.180674\n",
      "[300]\tvalid_0's binary_logloss: 0.174781\tvalid_1's binary_logloss: 0.180742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  20%|##        | 4/20 [03:00<12:51, 48.22s/it]\u001b[32m[I 2022-12-19 18:40:14,159]\u001b[0m Trial 46 finished with value: 0.18065406612116156 and parameters: {'lambda_l1': 8.141298529200014, 'lambda_l2': 1.0402550921323746e-08}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  20%|##        | 4/20 [03:00<12:51, 48.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's binary_logloss: 0.177417\tvalid_1's binary_logloss: 0.180654\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186786\tvalid_1's binary_logloss: 0.181703\n",
      "[200]\tvalid_0's binary_logloss: 0.174367\tvalid_1's binary_logloss: 0.182384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  25%|##5       | 5/20 [03:39<11:16, 45.13s/it]\u001b[32m[I 2022-12-19 18:40:53,807]\u001b[0m Trial 47 finished with value: 0.18161863478414456 and parameters: {'lambda_l1': 2.4951565501465913e-06, 'lambda_l2': 1.5608249231888732e-05}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  25%|##5       | 5/20 [03:39<11:16, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.184116\tvalid_1's binary_logloss: 0.181619\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187565\tvalid_1's binary_logloss: 0.181629\n",
      "[200]\tvalid_0's binary_logloss: 0.176344\tvalid_1's binary_logloss: 0.181367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  30%|###       | 6/20 [04:19<10:04, 43.19s/it]\u001b[32m[I 2022-12-19 18:41:33,229]\u001b[0m Trial 48 finished with value: 0.18132326724792572 and parameters: {'lambda_l1': 1.3942278577390959, 'lambda_l2': 1.7963528786313752e-06}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  30%|###       | 6/20 [04:19<10:04, 43.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.181426\tvalid_1's binary_logloss: 0.181323\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.188225\tvalid_1's binary_logloss: 0.181505\n",
      "[200]\tvalid_0's binary_logloss: 0.178606\tvalid_1's binary_logloss: 0.180857\n",
      "[300]\tvalid_0's binary_logloss: 0.170981\tvalid_1's binary_logloss: 0.180794\n",
      "[400]\tvalid_0's binary_logloss: 0.163919\tvalid_1's binary_logloss: 0.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  35%|###5      | 7/20 [05:16<10:20, 47.70s/it]\u001b[32m[I 2022-12-19 18:42:30,220]\u001b[0m Trial 49 finished with value: 0.18075243722378917 and parameters: {'lambda_l1': 0.0007744299883741888, 'lambda_l2': 3.1923077046449113}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  35%|###5      | 7/20 [05:16<10:20, 47.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's binary_logloss: 0.169417\tvalid_1's binary_logloss: 0.180752\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186786\tvalid_1's binary_logloss: 0.181701\n",
      "[200]\tvalid_0's binary_logloss: 0.174526\tvalid_1's binary_logloss: 0.182578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  40%|####      | 8/20 [06:12<10:06, 50.57s/it]\u001b[32m[I 2022-12-19 18:43:26,939]\u001b[0m Trial 50 finished with value: 0.1816167675583003 and parameters: {'lambda_l1': 1.1493437805038235e-05, 'lambda_l2': 1.263609216587495e-06}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  40%|####      | 8/20 [06:12<10:06, 50.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.184116\tvalid_1's binary_logloss: 0.181617\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186671\tvalid_1's binary_logloss: 0.181746\n",
      "[200]\tvalid_0's binary_logloss: 0.17433\tvalid_1's binary_logloss: 0.182125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  45%|####5     | 9/20 [06:51<08:35, 46.86s/it]\u001b[32m[I 2022-12-19 18:44:05,642]\u001b[0m Trial 51 finished with value: 0.18165872692508708 and parameters: {'lambda_l1': 0.0012580925555325335, 'lambda_l2': 0.011963370908213559}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  45%|####5     | 9/20 [06:51<08:35, 46.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.181262\tvalid_1's binary_logloss: 0.181659\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186786\tvalid_1's binary_logloss: 0.181702\n",
      "[200]\tvalid_0's binary_logloss: 0.174385\tvalid_1's binary_logloss: 0.182407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  50%|#####     | 10/20 [07:44<08:06, 48.68s/it]\u001b[32m[I 2022-12-19 18:44:58,405]\u001b[0m Trial 52 finished with value: 0.1816182602083105 and parameters: {'lambda_l1': 1.6319214174338393e-08, 'lambda_l2': 5.512238951678942e-06}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  50%|#####     | 10/20 [07:44<08:06, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.184116\tvalid_1's binary_logloss: 0.181618\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186843\tvalid_1's binary_logloss: 0.181955\n",
      "[200]\tvalid_0's binary_logloss: 0.174425\tvalid_1's binary_logloss: 0.18253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  55%|#####5    | 11/20 [08:19<06:39, 44.40s/it]\u001b[32m[I 2022-12-19 18:45:33,091]\u001b[0m Trial 53 finished with value: 0.1818723977966915 and parameters: {'lambda_l1': 0.029694834047269303, 'lambda_l2': 8.04158485439512e-08}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  55%|#####5    | 11/20 [08:19<06:39, 44.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.183498\tvalid_1's binary_logloss: 0.181872\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187431\tvalid_1's binary_logloss: 0.181622\n",
      "[200]\tvalid_0's binary_logloss: 0.176401\tvalid_1's binary_logloss: 0.181272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180654:  60%|######    | 12/20 [09:00<05:48, 43.60s/it]\u001b[32m[I 2022-12-19 18:46:14,856]\u001b[0m Trial 54 finished with value: 0.18125502637361576 and parameters: {'lambda_l1': 0.01376701478134663, 'lambda_l2': 0.4460823506633803}. Best is trial 46 with value: 0.18065406612116156.\u001b[0m\n",
      "regularization_factors, val_score: 0.180654:  60%|######    | 12/20 [09:00<05:48, 43.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's binary_logloss: 0.178561\tvalid_1's binary_logloss: 0.181255\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.190156\tvalid_1's binary_logloss: 0.181942\n",
      "[200]\tvalid_0's binary_logloss: 0.181765\tvalid_1's binary_logloss: 0.180791\n",
      "[300]\tvalid_0's binary_logloss: 0.175871\tvalid_1's binary_logloss: 0.180662\n",
      "[400]\tvalid_0's binary_logloss: 0.170921\tvalid_1's binary_logloss: 0.180613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180564:  65%|######5   | 13/20 [10:25<06:33, 56.17s/it]\u001b[32m[I 2022-12-19 18:47:39,954]\u001b[0m Trial 55 finished with value: 0.1805640436077211 and parameters: {'lambda_l1': 8.006226026761107, 'lambda_l2': 8.110883686017706}. Best is trial 55 with value: 0.1805640436077211.\u001b[0m\n",
      "regularization_factors, val_score: 0.180564:  65%|######5   | 13/20 [10:25<06:33, 56.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's binary_logloss: 0.171956\tvalid_1's binary_logloss: 0.180564\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.188289\tvalid_1's binary_logloss: 0.181525\n",
      "[200]\tvalid_0's binary_logloss: 0.178024\tvalid_1's binary_logloss: 0.180974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180564:  70%|#######   | 14/20 [11:29<05:49, 58.31s/it]\u001b[32m[I 2022-12-19 18:48:43,223]\u001b[0m Trial 56 finished with value: 0.1809494817316087 and parameters: {'lambda_l1': 2.724019300088046, 'lambda_l2': 0.05845815568232744}. Best is trial 55 with value: 0.1805640436077211.\u001b[0m\n",
      "regularization_factors, val_score: 0.180564:  70%|#######   | 14/20 [11:29<05:49, 58.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.17844\tvalid_1's binary_logloss: 0.180949\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189859\tvalid_1's binary_logloss: 0.181724\n",
      "[200]\tvalid_0's binary_logloss: 0.181464\tvalid_1's binary_logloss: 0.180703\n",
      "[300]\tvalid_0's binary_logloss: 0.175502\tvalid_1's binary_logloss: 0.180587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180530:  75%|#######5  | 15/20 [12:42<05:14, 62.88s/it]\u001b[32m[I 2022-12-19 18:49:56,680]\u001b[0m Trial 57 finished with value: 0.18053046729592745 and parameters: {'lambda_l1': 9.356310279757256, 'lambda_l2': 1.3120983078968551e-08}. Best is trial 57 with value: 0.18053046729592745.\u001b[0m\n",
      "regularization_factors, val_score: 0.180530:  75%|#######5  | 15/20 [12:42<05:14, 62.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's binary_logloss: 0.177839\tvalid_1's binary_logloss: 0.18053\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186805\tvalid_1's binary_logloss: 0.181732\n",
      "[200]\tvalid_0's binary_logloss: 0.174473\tvalid_1's binary_logloss: 0.182322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180530:  80%|########  | 16/20 [13:20<03:40, 55.20s/it]\u001b[32m[I 2022-12-19 18:50:34,064]\u001b[0m Trial 58 finished with value: 0.18169282334387465 and parameters: {'lambda_l1': 0.0817073170343569, 'lambda_l2': 0.00487924099698664}. Best is trial 57 with value: 0.18053046729592745.\u001b[0m\n",
      "regularization_factors, val_score: 0.180530:  80%|########  | 16/20 [13:20<03:40, 55.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.186154\tvalid_1's binary_logloss: 0.181693\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.188672\tvalid_1's binary_logloss: 0.181548\n",
      "[200]\tvalid_0's binary_logloss: 0.179778\tvalid_1's binary_logloss: 0.180941\n",
      "[300]\tvalid_0's binary_logloss: 0.172477\tvalid_1's binary_logloss: 0.180824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180530:  85%|########5 | 17/20 [14:16<02:46, 55.48s/it]\u001b[32m[I 2022-12-19 18:51:30,200]\u001b[0m Trial 59 finished with value: 0.180782678920817 and parameters: {'lambda_l1': 0.1879320681513902, 'lambda_l2': 7.674484609533152}. Best is trial 57 with value: 0.18053046729592745.\u001b[0m\n",
      "regularization_factors, val_score: 0.180530:  85%|########5 | 17/20 [14:16<02:46, 55.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's binary_logloss: 0.173741\tvalid_1's binary_logloss: 0.180783\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186786\tvalid_1's binary_logloss: 0.181701\n",
      "[200]\tvalid_0's binary_logloss: 0.17446\tvalid_1's binary_logloss: 0.182459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180530:  90%|######### | 18/20 [14:53<01:39, 49.97s/it]\u001b[32m[I 2022-12-19 18:52:07,341]\u001b[0m Trial 60 finished with value: 0.18161729816506406 and parameters: {'lambda_l1': 4.4843480819212926e-05, 'lambda_l2': 1.3660338805446877e-07}. Best is trial 57 with value: 0.18053046729592745.\u001b[0m\n",
      "regularization_factors, val_score: 0.180530:  90%|######### | 18/20 [14:53<01:39, 49.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.184116\tvalid_1's binary_logloss: 0.181617\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.186784\tvalid_1's binary_logloss: 0.181765\n",
      "[200]\tvalid_0's binary_logloss: 0.174545\tvalid_1's binary_logloss: 0.182355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180530:  95%|#########5| 19/20 [15:27<00:45, 45.21s/it]\u001b[32m[I 2022-12-19 18:52:41,444]\u001b[0m Trial 61 finished with value: 0.18171042006268695 and parameters: {'lambda_l1': 0.0071399198681174085, 'lambda_l2': 0.005073766352438688}. Best is trial 57 with value: 0.18053046729592745.\u001b[0m\n",
      "regularization_factors, val_score: 0.180530:  95%|#########5| 19/20 [15:27<00:45, 45.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.184395\tvalid_1's binary_logloss: 0.18171\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.187387\tvalid_1's binary_logloss: 0.181593\n",
      "[200]\tvalid_0's binary_logloss: 0.17617\tvalid_1's binary_logloss: 0.181259\n",
      "[300]\tvalid_0's binary_logloss: 0.167155\tvalid_1's binary_logloss: 0.181505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.180530: 100%|##########| 20/20 [16:13<00:00, 45.39s/it]\u001b[32m[I 2022-12-19 18:53:27,277]\u001b[0m Trial 62 finished with value: 0.1812423920339893 and parameters: {'lambda_l1': 0.3088097094367038, 'lambda_l2': 0.26493860576954065}. Best is trial 57 with value: 0.18053046729592745.\u001b[0m\n",
      "regularization_factors, val_score: 0.180530: 100%|##########| 20/20 [16:13<00:00, 48.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.174295\tvalid_1's binary_logloss: 0.181242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.180530:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189815\tvalid_1's binary_logloss: 0.181891\n",
      "[200]\tvalid_0's binary_logloss: 0.181422\tvalid_1's binary_logloss: 0.180796\n",
      "[300]\tvalid_0's binary_logloss: 0.175322\tvalid_1's binary_logloss: 0.180728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.180530:  20%|##        | 1/5 [01:07<04:28, 67.17s/it]\u001b[32m[I 2022-12-19 18:54:34,453]\u001b[0m Trial 63 finished with value: 0.18066011069612092 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.18066011069612092.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.180530:  20%|##        | 1/5 [01:07<04:28, 67.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's binary_logloss: 0.178462\tvalid_1's binary_logloss: 0.18066\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189888\tvalid_1's binary_logloss: 0.181922\n",
      "[200]\tvalid_0's binary_logloss: 0.181551\tvalid_1's binary_logloss: 0.180834\n",
      "[300]\tvalid_0's binary_logloss: 0.175606\tvalid_1's binary_logloss: 0.180712\n",
      "[400]\tvalid_0's binary_logloss: 0.170267\tvalid_1's binary_logloss: 0.180765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.180530:  40%|####      | 2/5 [02:20<03:32, 70.78s/it]\u001b[32m[I 2022-12-19 18:55:47,760]\u001b[0m Trial 64 finished with value: 0.18060298425737062 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.18060298425737062.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.180530:  40%|####      | 2/5 [02:20<03:32, 70.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's binary_logloss: 0.173955\tvalid_1's binary_logloss: 0.180603\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189828\tvalid_1's binary_logloss: 0.181768\n",
      "[200]\tvalid_0's binary_logloss: 0.181324\tvalid_1's binary_logloss: 0.180857\n",
      "[300]\tvalid_0's binary_logloss: 0.175142\tvalid_1's binary_logloss: 0.18082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.180530:  60%|######    | 3/5 [03:19<02:10, 65.50s/it]\u001b[32m[I 2022-12-19 18:56:46,968]\u001b[0m Trial 65 finished with value: 0.18076765010568535 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.18060298425737062.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.180530:  60%|######    | 3/5 [03:19<02:10, 65.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's binary_logloss: 0.177191\tvalid_1's binary_logloss: 0.180768\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189872\tvalid_1's binary_logloss: 0.181862\n",
      "[200]\tvalid_0's binary_logloss: 0.181418\tvalid_1's binary_logloss: 0.18086\n",
      "[300]\tvalid_0's binary_logloss: 0.175312\tvalid_1's binary_logloss: 0.180778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.180530:  80%|########  | 4/5 [04:19<01:03, 63.37s/it]\u001b[32m[I 2022-12-19 18:57:47,088]\u001b[0m Trial 66 finished with value: 0.18068405079836244 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.18060298425737062.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.180530:  80%|########  | 4/5 [04:19<01:03, 63.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's binary_logloss: 0.176715\tvalid_1's binary_logloss: 0.180684\n",
      "[LightGBM] [Info] Number of positive: 577974, number of negative: 577974\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1155948, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.189882\tvalid_1's binary_logloss: 0.181901\n",
      "[200]\tvalid_0's binary_logloss: 0.181487\tvalid_1's binary_logloss: 0.180804\n",
      "[300]\tvalid_0's binary_logloss: 0.175401\tvalid_1's binary_logloss: 0.180595\n",
      "[400]\tvalid_0's binary_logloss: 0.170118\tvalid_1's binary_logloss: 0.180733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.180530: 100%|##########| 5/5 [05:26<00:00, 64.45s/it]\u001b[32m[I 2022-12-19 18:58:53,447]\u001b[0m Trial 67 finished with value: 0.18057046113738995 and parameters: {'min_child_samples': 25}. Best is trial 67 with value: 0.18057046113738995.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.180530: 100%|##########| 5/5 [05:26<00:00, 65.23s/it]\n",
      "8:04:53.971827 \t orders best_params\n",
      "8:04:53.972905 \t {'objective': 'binary', 'boosting': 'gbdt', 'learning_rate': 0.1, 'metric': 'binary_logloss', 'seed': 42, 'feature_pre_filter': False, 'lambda_l1': 9.356310279757256, 'lambda_l2': 1.3120983078968551e-08, 'num_leaves': 174, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 2000000, 'early_stopping_round': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's binary_logloss: 0.173936\tvalid_1's binary_logloss: 0.18057\n"
     ]
    }
   ],
   "source": [
    "for type_ in [\"clicks\", \"carts\", \"orders\"]:\n",
    "    train = pd.read_pickle(cfg.output_dir + f\"exp049/cache/{type_}_train.pkl\")\n",
    "    valid = pd.read_pickle(cfg.output_dir + f\"exp049/cache/{type_}_valid.pkl\")\n",
    "    target = \"labels\"\n",
    "    not_use_cols = [\"session\", \"aid\", target]\n",
    "    features = [c for c in train.columns if c not in not_use_cols]\n",
    "    \n",
    "    tr_x, tr_y = train[features], train[target]\n",
    "    vl_x, vl_y = valid[features], valid[target]\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "    model = optuna_lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                             num_boost_round=2000000, early_stopping_rounds=100, verbose_eval=100)\n",
    "    logger.info(f\"{type_} best_params\")\n",
    "    logger.info(model.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
