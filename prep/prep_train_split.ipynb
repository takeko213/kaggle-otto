{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_split\n",
    "学習データからテストデータを模した検証用データを生成する\n",
    "* trainデータを1weekごとに分割\n",
    "* 各セッションごとランダムに分割し、trainとtestに分ける\n",
    "* testからlabelデータを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "sys.path.append(os.getenv('UTILS_PATH'))\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "PREP_DIR = os.getenv(\"PREP_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_sessions = pd.read_pickle(PREP_DIR + \"train_sessions.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1weekごと分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_start = \"2022-07-31 22:00:00\"\n",
    "w2_start = \"2022-08-07 22:00:00\"\n",
    "w3_start = \"2022-08-14 22:00:00\"\n",
    "w4_start = \"2022-08-21 22:00:00\"\n",
    "\n",
    "dt = pd.to_datetime(org_sessions[\"ts\"], unit=\"ms\")\n",
    "week1_sessions = org_sessions[dt < w2_start].copy()\n",
    "week2_sessions = org_sessions[(dt >= w2_start) & (dt < w3_start)].copy()\n",
    "week3_sessions = org_sessions[(dt >= w3_start) & (dt < w4_start)].copy()\n",
    "week4_sessions = org_sessions[dt >= w4_start].copy()\n",
    "\n",
    "week1_sessions = week1_sessions.reset_index(drop=True)\n",
    "week2_sessions = week2_sessions.reset_index(drop=True)\n",
    "week3_sessions = week3_sessions.reset_index(drop=True)\n",
    "week4_sessions = week4_sessions.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week1 :  2022-07-31 22:00:00.025000 - 2022-08-07 21:59:59.968000\n",
      "week2 :  2022-08-07 22:00:00.009000 - 2022-08-14 21:59:59.998000\n",
      "week3 :  2022-08-14 22:00:00.009000 - 2022-08-21 21:59:59.994000\n",
      "week4 :  2022-08-21 22:00:00.002000 - 2022-08-28 21:59:59.984000\n"
     ]
    }
   ],
   "source": [
    "print(\"week1 : \", pd.to_datetime(week1_sessions[\"ts\"].min(), unit=\"ms\"), \"-\" ,pd.to_datetime(week1_sessions[\"ts\"].max(), unit=\"ms\"))\n",
    "print(\"week2 : \", pd.to_datetime(week2_sessions[\"ts\"].min(), unit=\"ms\"), \"-\" ,pd.to_datetime(week2_sessions[\"ts\"].max(), unit=\"ms\"))\n",
    "print(\"week3 : \", pd.to_datetime(week3_sessions[\"ts\"].min(), unit=\"ms\"), \"-\" ,pd.to_datetime(week3_sessions[\"ts\"].max(), unit=\"ms\"))\n",
    "print(\"week4 : \", pd.to_datetime(week4_sessions[\"ts\"].min(), unit=\"ms\"), \"-\" ,pd.to_datetime(week4_sessions[\"ts\"].max(), unit=\"ms\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train,test,labelsを作成し出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(sessions):\n",
    "    \"\"\"\n",
    "    各セッションごとランダムに分割し、trainとtestに分ける\n",
    "    \"\"\"\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for _, session in tqdm(sessions.groupby(\"session\")):\n",
    "        session_len = len(session)\n",
    "        # １レコードしかない場合、trainとtestを作れないのでスキップする\n",
    "        if session_len == 1:\n",
    "            continue\n",
    "\n",
    "        split_point = random.randint(1, session_len-1)\n",
    "        train_idx.extend(list(session.iloc[:split_point].index))\n",
    "        test_idx.extend(list(session.iloc[split_point:].index))\n",
    "    \n",
    "    train_sessions = sessions.loc[train_idx].copy()\n",
    "    test_sessions = sessions.loc[test_idx].copy()\n",
    "\n",
    "    train_sessions = train_sessions.reset_index(drop=True)\n",
    "    test_sessions = test_sessions.reset_index(drop=True)\n",
    "\n",
    "    return train_sessions, test_sessions\n",
    "\n",
    "def make_labels(sessions):\n",
    "    labels = pd.DataFrame(sessions[\"session\"].unique(), columns=[\"session\"])\n",
    "\n",
    "    clicks_labels = sessions[sessions[\"type\"]==\"clicks\"].groupby(\"session\").head(1)[[\"session\", \"aid\"]]\n",
    "    clicks_labels = clicks_labels.rename(columns={\"aid\":\"clicks_labels\"})\n",
    "    labels = labels.merge(clicks_labels, how=\"left\", on=\"session\")\n",
    "\n",
    "    carts_labels = sessions[sessions[\"type\"]==\"carts\"].drop_duplicates(subset=[\"session\", \"aid\"]).groupby(\"session\")[\"aid\"].apply(list).reset_index()\n",
    "    carts_labels = carts_labels.rename(columns={\"aid\":\"carts_labels\"})\n",
    "    labels = labels.merge(carts_labels, how=\"left\", on=\"session\")\n",
    "\n",
    "    orders_labels = sessions[sessions[\"type\"]==\"orders\"].drop_duplicates(subset=[\"session\", \"aid\"]).groupby(\"session\")[\"aid\"].apply(list).reset_index()\n",
    "    orders_labels = orders_labels.rename(columns={\"aid\":\"orders_labels\"})\n",
    "    labels = labels.merge(orders_labels, how=\"left\", on=\"session\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "def make_train_test_labels(session, suffix):\n",
    "    train_sessions, test_sessions = split_train_test(session)\n",
    "    labels = make_labels(test_sessions)\n",
    "\n",
    "    train_sessions.to_pickle(PREP_DIR + f\"train_sessions_{suffix}.pkl\")\n",
    "    test_sessions.to_pickle(PREP_DIR + f\"test_sessions_{suffix}.pkl\")\n",
    "    labels.to_pickle(PREP_DIR + f\"labels_{suffix}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5348783/5348783 [02:57<00:00, 30092.81it/s]\n",
      "100%|██████████| 5683320/5683320 [03:02<00:00, 31187.29it/s]\n",
      "100%|██████████| 5704612/5704612 [03:01<00:00, 31348.02it/s]\n",
      "100%|██████████| 5323084/5323084 [02:52<00:00, 30832.20it/s]\n"
     ]
    }
   ],
   "source": [
    "make_train_test_labels(week1_sessions, \"week1\")\n",
    "make_train_test_labels(week2_sessions, \"week2\")\n",
    "make_train_test_labels(week3_sessions, \"week3\")\n",
    "make_train_test_labels(week4_sessions, \"week4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
